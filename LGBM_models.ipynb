{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook trains various LGBM Models for each of the six outcomes.\n",
    "## It also trains models with both class weights, and with no class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, r2_score, mean_squared_error\n",
    "# ....\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# import lightgbm as lgb \n",
    "\n",
    "from lightgbm import LGBMRegressor,LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing \n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "with open('cleaned_data_label_encoding.pickle', 'rb') as handle:\n",
    "    background_imputed_tot = pickle.load(handle)\n",
    "    \n",
    "with open('X_train_label_encoding.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "\n",
    "with open('X_CV_label_encoding.pickle', 'rb') as handle:\n",
    "    X_CV = pickle.load(handle)\n",
    "\n",
    "with open('x_test_label_encoding.pickle', 'rb') as handle:\n",
    "    x_test = pickle.load(handle)\n",
    "    \n",
    "with open('x_leaderboard_label_encoding.pickle', 'rb') as handle:\n",
    "    x_leaderboard = pickle.load(handle)\n",
    "    \n",
    "with open('y_train_label_encoding.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "    \n",
    "with open('y_CV_label_encoding.pickle', 'rb') as handle:\n",
    "    y_CV = pickle.load(handle)\n",
    "    \n",
    "background = pd.read_csv('FFChallenge_v5/background.csv', sep=',', header=0,index_col=0,low_memory=False)\n",
    "# train.csv contains 2,121 rows (one per child in the training set) and 7 columns.\n",
    "train = pd.read_csv('FFChallenge_v5/train.csv', sep=',', header=0, index_col=0,low_memory=False)\n",
    "########### Holdout dataset for internal testing only\n",
    "test = pd.read_csv('test.csv',header=0, index_col=0,low_memory=False)\n",
    "leaderboard = pd.read_csv('leaderboard.csv', header=0, index_col=0,low_memory=False)\n",
    "leaderboard = leaderboard.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of continuous columns 601\n"
     ]
    }
   ],
   "source": [
    "# Final stats and useful variables associated with each column\n",
    "\n",
    "numerical_columns = [c for c,v in background_imputed_tot.dtypes.iteritems() if v in [np.float,np.int,np.int64]]\n",
    "non_numerical_columns = [c for c,v in background_imputed_tot.dtypes.iteritems() if v not in [np.float,np.int,np.int64]]\n",
    "\n",
    "\n",
    "# The categorical columns are the intersection of both the non_numerical columns and the ones that have less than 15 distinct levels\n",
    "# categorical_cols_lst = list(set(categorical_bools.columns).union(set(non_numerical_columns)))\n",
    "\n",
    "continuous_cols_lst = list()\n",
    "continuous_cols_lst = background_imputed_tot.T.loc[(background_imputed_tot.apply(pd.Series.nunique) >= 15).values==True].index.to_list()\n",
    "\n",
    "non_continuous_lst = set(background_imputed_tot.columns.tolist())-set(continuous_cols_lst)\n",
    "\n",
    "\n",
    "print('Number of continuous columns %s' % len(continuous_cols_lst))\n",
    "# background = background[numerical_columns]\n",
    "# background.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Following cell trains three LGBM models: GBDT, DART and GOSS using no class weights. The models trained with class weights are provided in cells below this one\n",
    "### The hyperparameters of each model are tuned using 20 iterations of bayesian optimization, with repeated cross validation and repeated stratified cross validation with 3 folds and 2 repeats.\n",
    "### Early stopping is used to help minimize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  gbdt  --------------\n",
      "\n",
      "\n",
      "gpa\n",
      "gpa\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.3847114  -0.39860344 -0.3823323  -0.36396924 -0.40016859 -0.40008174]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.3883  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.39797068 -0.39114754 -0.38533161 -0.37535318 -0.39039006 -0.41225703]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.3921  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.40053479 -0.41253653 -0.37121799 -0.38323532 -0.42760679 -0.43307693]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4047  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.41277187 -0.40508921 -0.38866495 -0.37160879 -0.42051041 -0.4260785 ]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.4041  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.40395616 -0.39681685 -0.39263432 -0.37857203 -0.3956307  -0.39192879]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.3933  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.39730015 -0.3895289  -0.37615133 -0.37854492 -0.40111424 -0.40608311]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.3915  \u001b[0m | \u001b[0m 0.7304  \u001b[0m | \u001b[0m 0.0886  \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 50.87   \u001b[0m | \u001b[0m 564.0   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.9716  \u001b[0m |\n",
      "[-0.40004354 -0.40083778 -0.38501613 -0.36833464 -0.39696987 -0.39592183]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.3912  \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 33.22   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 25.95   \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.8471  \u001b[0m |\n",
      "[-0.40670529 -0.38358517 -0.37642142 -0.36689707 -0.38966851 -0.38835535]\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.3853  \u001b[0m | \u001b[95m 0.5792  \u001b[0m | \u001b[95m 0.05888 \u001b[0m | \u001b[95m 13.41   \u001b[0m | \u001b[95m 33.19   \u001b[0m | \u001b[95m 227.7   \u001b[0m | \u001b[95m 85.05   \u001b[0m | \u001b[95m 15.06   \u001b[0m | \u001b[95m 0.007282\u001b[0m | \u001b[95m 0.9673  \u001b[0m | \u001b[95m 0.7998  \u001b[0m |\n",
      "[-0.41884869 -0.3888209  -0.38307004 -0.37732951 -0.40821201 -0.40692976]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3972  \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 0.1251  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 35.67   \u001b[0m | \u001b[0m 225.3   \u001b[0m | \u001b[0m 89.75   \u001b[0m | \u001b[0m 9.125   \u001b[0m | \u001b[0m 0.5762  \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 0.9434  \u001b[0m |\n",
      "[-0.3982192  -0.41629312 -0.39174044 -0.3835274  -0.39483439 -0.42115562]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.401   \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 47.61   \u001b[0m | \u001b[0m 568.1   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.6486  \u001b[0m |\n",
      "[-0.41620651 -0.4393103  -0.39722875 -0.41652258 -0.42753241 -0.41316515]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.4183  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "[-0.40119472 -0.37808403 -0.37016325 -0.37160287 -0.37639667 -0.40419261]\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.3836  \u001b[0m | \u001b[95m 0.74    \u001b[0m | \u001b[95m 0.09247 \u001b[0m | \u001b[95m 4.982   \u001b[0m | \u001b[95m 180.9   \u001b[0m | \u001b[95m 277.0   \u001b[0m | \u001b[95m 184.5   \u001b[0m | \u001b[95m 25.02   \u001b[0m | \u001b[95m 0.4763  \u001b[0m | \u001b[95m 0.03582 \u001b[0m | \u001b[95m 0.6237  \u001b[0m |\n",
      "[-0.39601703 -0.38351658 -0.3774029  -0.36329266 -0.39523939 -0.40342912]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3865  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "[-0.38432431 -0.37834866 -0.37278388 -0.35697297 -0.38818103 -0.39417715]\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.3791  \u001b[0m | \u001b[95m 0.9909  \u001b[0m | \u001b[95m 0.02365 \u001b[0m | \u001b[95m 1.034   \u001b[0m | \u001b[95m 26.65   \u001b[0m | \u001b[95m 462.4   \u001b[0m | \u001b[95m 165.0   \u001b[0m | \u001b[95m 28.78   \u001b[0m | \u001b[95m 0.5494  \u001b[0m | \u001b[95m 0.8478  \u001b[0m | \u001b[95m 0.7359  \u001b[0m |\n",
      "[-0.41999782 -0.38902205 -0.37648164 -0.37818299 -0.37926338 -0.41199704]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.3925  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "[-0.4238606  -0.40857137 -0.37921832 -0.40420408 -0.42033908 -0.44450319]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.4134  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "[-0.38340269 -0.3733857  -0.36519043 -0.35439087 -0.38361989 -0.39210861]\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m-0.3753  \u001b[0m | \u001b[95m 0.6996  \u001b[0m | \u001b[95m 0.06931 \u001b[0m | \u001b[95m 1.744   \u001b[0m | \u001b[95m 142.1   \u001b[0m | \u001b[95m 125.3   \u001b[0m | \u001b[95m 77.45   \u001b[0m | \u001b[95m 22.79   \u001b[0m | \u001b[95m 0.9274  \u001b[0m | \u001b[95m 0.8041  \u001b[0m | \u001b[95m 0.5405  \u001b[0m |\n",
      "[-0.38844017 -0.38430386 -0.36316556 -0.35033334 -0.36883641 -0.39102904]\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-0.3744  \u001b[0m | \u001b[95m 0.7936  \u001b[0m | \u001b[95m 0.1276  \u001b[0m | \u001b[95m 11.92   \u001b[0m | \u001b[95m 198.9   \u001b[0m | \u001b[95m 362.6   \u001b[0m | \u001b[95m 76.97   \u001b[0m | \u001b[95m 25.06   \u001b[0m | \u001b[95m 0.3706  \u001b[0m | \u001b[95m 0.9528  \u001b[0m | \u001b[95m 0.5669  \u001b[0m |\n",
      "[-0.38654666 -0.3795369  -0.36152046 -0.35073228 -0.37019975 -0.38793801]\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.3727  \u001b[0m | \u001b[95m 0.7399  \u001b[0m | \u001b[95m 0.1068  \u001b[0m | \u001b[95m 13.41   \u001b[0m | \u001b[95m 198.1   \u001b[0m | \u001b[95m 557.8   \u001b[0m | \u001b[95m 60.09   \u001b[0m | \u001b[95m 3.761   \u001b[0m | \u001b[95m 0.8829  \u001b[0m | \u001b[95m 0.8813  \u001b[0m | \u001b[95m 0.6729  \u001b[0m |\n",
      "[-0.42238806 -0.40354017 -0.38236072 -0.39529612 -0.38228649 -0.43175868]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.4029  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.3727456764293143, 'params': {'colsample_bytree': 0.7398968716730849, 'learning_rate': 0.10678784816079744, 'max_depth': 13.409437116387124, 'min_child_samples': 198.11964503407125, 'n_estimators': 557.8252433624695, 'num_iteration': 60.08977143824658, 'num_leaves': 3.760850240445394, 'reg_alpha': 0.8829335074620949, 'reg_lambda': 0.8812788175692582, 'subsample': 0.6728848240913614}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=60, num_iteration=60 will be ignored. Current value: num_iterations=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.419105\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.415402\n",
      "[3]\tvalid_0's l2: 0.408967\n",
      "[4]\tvalid_0's l2: 0.404659\n",
      "[5]\tvalid_0's l2: 0.402966\n",
      "[6]\tvalid_0's l2: 0.401038\n",
      "[7]\tvalid_0's l2: 0.398723\n",
      "[8]\tvalid_0's l2: 0.39693\n",
      "[9]\tvalid_0's l2: 0.394334\n",
      "[10]\tvalid_0's l2: 0.392788\n",
      "[11]\tvalid_0's l2: 0.391387\n",
      "[12]\tvalid_0's l2: 0.392798\n",
      "[13]\tvalid_0's l2: 0.391322\n",
      "[14]\tvalid_0's l2: 0.391016\n",
      "[15]\tvalid_0's l2: 0.390686\n",
      "[16]\tvalid_0's l2: 0.390656\n",
      "[17]\tvalid_0's l2: 0.388981\n",
      "[18]\tvalid_0's l2: 0.388777\n",
      "[19]\tvalid_0's l2: 0.387407\n",
      "[20]\tvalid_0's l2: 0.38591\n",
      "[21]\tvalid_0's l2: 0.386525\n",
      "[22]\tvalid_0's l2: 0.386503\n",
      "[23]\tvalid_0's l2: 0.384589\n",
      "[24]\tvalid_0's l2: 0.382543\n",
      "[25]\tvalid_0's l2: 0.383436\n",
      "[26]\tvalid_0's l2: 0.382759\n",
      "[27]\tvalid_0's l2: 0.382086\n",
      "[28]\tvalid_0's l2: 0.382311\n",
      "[29]\tvalid_0's l2: 0.38188\n",
      "[30]\tvalid_0's l2: 0.381776\n",
      "[31]\tvalid_0's l2: 0.38086\n",
      "[32]\tvalid_0's l2: 0.378829\n",
      "[33]\tvalid_0's l2: 0.378894\n",
      "[34]\tvalid_0's l2: 0.379418\n",
      "[35]\tvalid_0's l2: 0.37833\n",
      "[36]\tvalid_0's l2: 0.377178\n",
      "[37]\tvalid_0's l2: 0.378022\n",
      "[38]\tvalid_0's l2: 0.377467\n",
      "[39]\tvalid_0's l2: 0.379131\n",
      "[40]\tvalid_0's l2: 0.37787\n",
      "[41]\tvalid_0's l2: 0.376603\n",
      "[42]\tvalid_0's l2: 0.377204\n",
      "[43]\tvalid_0's l2: 0.37674\n",
      "[44]\tvalid_0's l2: 0.375358\n",
      "[45]\tvalid_0's l2: 0.374921\n",
      "[46]\tvalid_0's l2: 0.375182\n",
      "[47]\tvalid_0's l2: 0.375471\n",
      "[48]\tvalid_0's l2: 0.374556\n",
      "[49]\tvalid_0's l2: 0.374488\n",
      "[50]\tvalid_0's l2: 0.374249\n",
      "[51]\tvalid_0's l2: 0.373957\n",
      "[52]\tvalid_0's l2: 0.373707\n",
      "[53]\tvalid_0's l2: 0.373851\n",
      "[54]\tvalid_0's l2: 0.373124\n",
      "[55]\tvalid_0's l2: 0.373089\n",
      "[56]\tvalid_0's l2: 0.372979\n",
      "[57]\tvalid_0's l2: 0.372818\n",
      "[58]\tvalid_0's l2: 0.373202\n",
      "[59]\tvalid_0's l2: 0.372465\n",
      "[60]\tvalid_0's l2: 0.373116\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[59]\tvalid_0's l2: 0.372465\n",
      "---- Train error ----\n",
      "0.29030569988404675\n",
      "---- CV error ----\n",
      "0.372464982037302\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.03320976871944492\n",
      "mse = 0.37764382969532606\n",
      "grit\n",
      "grit\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.23350609 -0.22051752 -0.28278961 -0.24507516 -0.2585942  -0.2206679 ]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2435  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.22848913 -0.22289717 -0.2897307  -0.25076751 -0.25310594 -0.22767587]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2454  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.25559661 -0.232209   -0.28954433 -0.24752788 -0.26450956 -0.23536463]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2541  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.24101108 -0.23079731 -0.2913519  -0.25127845 -0.26347864 -0.23249448]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2517  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.2508299  -0.22377181 -0.28401005 -0.24903036 -0.254027   -0.2272159 ]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2481  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.24475397 -0.23109954 -0.28544961 -0.24439634 -0.26522137 -0.22267833]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2489  \u001b[0m | \u001b[0m 0.7304  \u001b[0m | \u001b[0m 0.0886  \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 50.87   \u001b[0m | \u001b[0m 564.0   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.9716  \u001b[0m |\n",
      "[-0.24045506 -0.21461084 -0.28122556 -0.23011203 -0.25760048 -0.21660901]\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.2401  \u001b[0m | \u001b[95m 0.8387  \u001b[0m | \u001b[95m 0.1723  \u001b[0m | \u001b[95m 7.045   \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 94.36   \u001b[0m | \u001b[95m 53.73   \u001b[0m | \u001b[95m 22.49   \u001b[0m | \u001b[95m 0.6974  \u001b[0m | \u001b[95m 0.462   \u001b[0m | \u001b[95m 0.9106  \u001b[0m |\n",
      "[-0.22453101 -0.21419588 -0.2780481  -0.24012351 -0.25327058 -0.21664257]\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.2378  \u001b[0m | \u001b[95m 0.7016  \u001b[0m | \u001b[95m 0.0116  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 859.6   \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 0.2637  \u001b[0m | \u001b[95m 0.8152  \u001b[0m | \u001b[95m 0.8523  \u001b[0m |\n",
      "[-0.22956626 -0.21985357 -0.27667179 -0.24462302 -0.25233414 -0.22833419]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2419  \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "[-0.22915825 -0.21311037 -0.27653748 -0.23306795 -0.25023433 -0.2167876 ]\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.2365  \u001b[0m | \u001b[95m 0.9133  \u001b[0m | \u001b[95m 0.04154 \u001b[0m | \u001b[95m 12.2    \u001b[0m | \u001b[95m 152.8   \u001b[0m | \u001b[95m 859.9   \u001b[0m | \u001b[95m 88.78   \u001b[0m | \u001b[95m 19.04   \u001b[0m | \u001b[95m 0.267   \u001b[0m | \u001b[95m 0.7124  \u001b[0m | \u001b[95m 0.7969  \u001b[0m |\n",
      "[-0.23593588 -0.21495081 -0.27948558 -0.23422375 -0.25117588 -0.21490076]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2384  \u001b[0m | \u001b[0m 0.5707  \u001b[0m | \u001b[0m 0.08506 \u001b[0m | \u001b[0m 6.39    \u001b[0m | \u001b[0m 176.9   \u001b[0m | \u001b[0m 865.5   \u001b[0m | \u001b[0m 99.0    \u001b[0m | \u001b[0m 29.78   \u001b[0m | \u001b[0m 0.6516  \u001b[0m | \u001b[0m 0.9325  \u001b[0m | \u001b[0m 0.9606  \u001b[0m |\n",
      "[-0.22558933 -0.2158657  -0.28006977 -0.24494728 -0.25313766 -0.21856499]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2397  \u001b[0m | \u001b[0m 0.9802  \u001b[0m | \u001b[0m 0.01295 \u001b[0m | \u001b[0m 1.06    \u001b[0m | \u001b[0m 172.2   \u001b[0m | \u001b[0m 850.2   \u001b[0m | \u001b[0m 56.35   \u001b[0m | \u001b[0m 28.79   \u001b[0m | \u001b[0m 0.7903  \u001b[0m | \u001b[0m 0.8866  \u001b[0m | \u001b[0m 0.7976  \u001b[0m |\n",
      "[-0.23311311 -0.21570996 -0.27994035 -0.23036599 -0.25313877 -0.21885638]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2385  \u001b[0m | \u001b[0m 0.8922  \u001b[0m | \u001b[0m 0.09261 \u001b[0m | \u001b[0m 12.44   \u001b[0m | \u001b[0m 150.5   \u001b[0m | \u001b[0m 893.0   \u001b[0m | \u001b[0m 69.12   \u001b[0m | \u001b[0m 25.88   \u001b[0m | \u001b[0m 0.6216  \u001b[0m | \u001b[0m 0.4013  \u001b[0m | \u001b[0m 0.5546  \u001b[0m |\n",
      "[-0.23493569 -0.21661274 -0.27450053 -0.2334156  -0.2589544  -0.2162996 ]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2391  \u001b[0m | \u001b[0m 0.9946  \u001b[0m | \u001b[0m 0.09285 \u001b[0m | \u001b[0m 5.894   \u001b[0m | \u001b[0m 114.8   \u001b[0m | \u001b[0m 833.9   \u001b[0m | \u001b[0m 68.91   \u001b[0m | \u001b[0m 26.67   \u001b[0m | \u001b[0m 0.8184  \u001b[0m | \u001b[0m 0.7497  \u001b[0m | \u001b[0m 0.8025  \u001b[0m |\n",
      "[-0.23394233 -0.21566241 -0.2778602  -0.23414352 -0.2513429  -0.21514928]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.238   \u001b[0m | \u001b[0m 0.6571  \u001b[0m | \u001b[0m 0.05213 \u001b[0m | \u001b[0m 14.33   \u001b[0m | \u001b[0m 169.5   \u001b[0m | \u001b[0m 810.3   \u001b[0m | \u001b[0m 96.43   \u001b[0m | \u001b[0m 29.09   \u001b[0m | \u001b[0m 0.6061  \u001b[0m | \u001b[0m 0.9131  \u001b[0m | \u001b[0m 0.6146  \u001b[0m |\n",
      "[-0.22764441 -0.21537482 -0.27995574 -0.23199619 -0.25396259 -0.21712992]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2377  \u001b[0m | \u001b[0m 0.831   \u001b[0m | \u001b[0m 0.05237 \u001b[0m | \u001b[0m 12.12   \u001b[0m | \u001b[0m 121.7   \u001b[0m | \u001b[0m 758.4   \u001b[0m | \u001b[0m 90.5    \u001b[0m | \u001b[0m 27.4    \u001b[0m | \u001b[0m 0.3266  \u001b[0m | \u001b[0m 0.5568  \u001b[0m | \u001b[0m 0.994   \u001b[0m |\n",
      "[-0.23485277 -0.21445524 -0.28143142 -0.23674876 -0.25582111 -0.22480276]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2414  \u001b[0m | \u001b[0m 0.8476  \u001b[0m | \u001b[0m 0.06993 \u001b[0m | \u001b[0m 11.18   \u001b[0m | \u001b[0m 118.0   \u001b[0m | \u001b[0m 785.8   \u001b[0m | \u001b[0m 146.9   \u001b[0m | \u001b[0m 28.32   \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 0.4344  \u001b[0m | \u001b[0m 0.9916  \u001b[0m |\n",
      "[-0.24587537 -0.22292728 -0.28675485 -0.23688496 -0.2573207  -0.21937598]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2449  \u001b[0m | \u001b[0m 0.7305  \u001b[0m | \u001b[0m 0.1808  \u001b[0m | \u001b[0m 5.387   \u001b[0m | \u001b[0m 149.6   \u001b[0m | \u001b[0m 896.3   \u001b[0m | \u001b[0m 69.18   \u001b[0m | \u001b[0m 23.8    \u001b[0m | \u001b[0m 0.9122  \u001b[0m | \u001b[0m 0.2154  \u001b[0m | \u001b[0m 0.9902  \u001b[0m |\n",
      "[-0.2450981  -0.21653364 -0.28017388 -0.23621549 -0.26257681 -0.22629514]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2445  \u001b[0m | \u001b[0m 0.5893  \u001b[0m | \u001b[0m 0.1619  \u001b[0m | \u001b[0m 12.97   \u001b[0m | \u001b[0m 154.2   \u001b[0m | \u001b[0m 861.1   \u001b[0m | \u001b[0m 99.56   \u001b[0m | \u001b[0m 23.98   \u001b[0m | \u001b[0m 0.9112  \u001b[0m | \u001b[0m 0.09602 \u001b[0m | \u001b[0m 0.5735  \u001b[0m |\n",
      "[-0.2586475  -0.22000704 -0.28441577 -0.24336007 -0.26879487 -0.22986693]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2508  \u001b[0m | \u001b[0m 0.9195  \u001b[0m | \u001b[0m 0.1985  \u001b[0m | \u001b[0m 12.09   \u001b[0m | \u001b[0m 163.8   \u001b[0m | \u001b[0m 820.0   \u001b[0m | \u001b[0m 91.22   \u001b[0m | \u001b[0m 28.69   \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.331   \u001b[0m | \u001b[0m 0.876   \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.23648266178905264, 'params': {'colsample_bytree': 0.9132892382915498, 'learning_rate': 0.041541412742969484, 'max_depth': 12.195901161053115, 'min_child_samples': 152.7726377296513, 'n_estimators': 859.9334475776739, 'num_iteration': 88.78203329874162, 'num_leaves': 19.04234771364986, 'reg_alpha': 0.26702028195934124, 'reg_lambda': 0.7123936095308667, 'subsample': 0.7969102431959707}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=88, num_iteration=88 will be ignored. Current value: num_iterations=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.212476\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.211777\n",
      "[3]\tvalid_0's l2: 0.211368\n",
      "[4]\tvalid_0's l2: 0.211052\n",
      "[5]\tvalid_0's l2: 0.210399\n",
      "[6]\tvalid_0's l2: 0.209799\n",
      "[7]\tvalid_0's l2: 0.209816\n",
      "[8]\tvalid_0's l2: 0.209972\n",
      "[9]\tvalid_0's l2: 0.209968\n",
      "[10]\tvalid_0's l2: 0.210099\n",
      "[11]\tvalid_0's l2: 0.209387\n",
      "[12]\tvalid_0's l2: 0.209259\n",
      "[13]\tvalid_0's l2: 0.208825\n",
      "[14]\tvalid_0's l2: 0.208828\n",
      "[15]\tvalid_0's l2: 0.208333\n",
      "[16]\tvalid_0's l2: 0.208057\n",
      "[17]\tvalid_0's l2: 0.207857\n",
      "[18]\tvalid_0's l2: 0.207707\n",
      "[19]\tvalid_0's l2: 0.20791\n",
      "[20]\tvalid_0's l2: 0.207568\n",
      "[21]\tvalid_0's l2: 0.2075\n",
      "[22]\tvalid_0's l2: 0.206995\n",
      "[23]\tvalid_0's l2: 0.207\n",
      "[24]\tvalid_0's l2: 0.206607\n",
      "[25]\tvalid_0's l2: 0.206815\n",
      "[26]\tvalid_0's l2: 0.20697\n",
      "[27]\tvalid_0's l2: 0.207017\n",
      "[28]\tvalid_0's l2: 0.206559\n",
      "[29]\tvalid_0's l2: 0.206209\n",
      "[30]\tvalid_0's l2: 0.205807\n",
      "[31]\tvalid_0's l2: 0.205823\n",
      "[32]\tvalid_0's l2: 0.205571\n",
      "[33]\tvalid_0's l2: 0.205346\n",
      "[34]\tvalid_0's l2: 0.205418\n",
      "[35]\tvalid_0's l2: 0.205006\n",
      "[36]\tvalid_0's l2: 0.204883\n",
      "[37]\tvalid_0's l2: 0.204602\n",
      "[38]\tvalid_0's l2: 0.204339\n",
      "[39]\tvalid_0's l2: 0.20458\n",
      "[40]\tvalid_0's l2: 0.204568\n",
      "[41]\tvalid_0's l2: 0.204536\n",
      "[42]\tvalid_0's l2: 0.204538\n",
      "[43]\tvalid_0's l2: 0.20427\n",
      "[44]\tvalid_0's l2: 0.204253\n",
      "[45]\tvalid_0's l2: 0.20417\n",
      "[46]\tvalid_0's l2: 0.204112\n",
      "[47]\tvalid_0's l2: 0.203874\n",
      "[48]\tvalid_0's l2: 0.203888\n",
      "[49]\tvalid_0's l2: 0.203894\n",
      "[50]\tvalid_0's l2: 0.203605\n",
      "[51]\tvalid_0's l2: 0.203385\n",
      "[52]\tvalid_0's l2: 0.20335\n",
      "[53]\tvalid_0's l2: 0.203152\n",
      "[54]\tvalid_0's l2: 0.202918\n",
      "[55]\tvalid_0's l2: 0.202511\n",
      "[56]\tvalid_0's l2: 0.20241\n",
      "[57]\tvalid_0's l2: 0.201917\n",
      "[58]\tvalid_0's l2: 0.201511\n",
      "[59]\tvalid_0's l2: 0.201308\n",
      "[60]\tvalid_0's l2: 0.201399\n",
      "[61]\tvalid_0's l2: 0.201646\n",
      "[62]\tvalid_0's l2: 0.201833\n",
      "[63]\tvalid_0's l2: 0.20148\n",
      "[64]\tvalid_0's l2: 0.201503\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l2: 0.201308\n",
      "---- Train error ----\n",
      "0.18895675514292837\n",
      "---- CV error ----\n",
      "0.20130779139390467\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.011934464323772431\n",
      "mse = 0.21711522212374287\n",
      "materialHardship\n",
      "materialHardship\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.02211642 -0.01847149 -0.02308999 -0.02196262 -0.02330468 -0.02006385]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.0215  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.02220062 -0.01941004 -0.02333738 -0.02216581 -0.02219224 -0.02006031]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.02156 \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.02217559 -0.01951286 -0.02358198 -0.02363295 -0.02275672 -0.0220309 ]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.02228 \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.02404376 -0.02135937 -0.02402583 -0.02340983 -0.02331374 -0.02183024]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.023   \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.02177526 -0.02056822 -0.02288003 -0.02267546 -0.02284554 -0.02093832]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.02195 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.02188662 -0.02041286 -0.02414354 -0.02313463 -0.02324456 -0.02100693]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.0223  \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "[-0.02215112 -0.01873729 -0.02310929 -0.02095151 -0.02304394 -0.02091811]\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.02149 \u001b[0m | \u001b[95m 0.8387  \u001b[0m | \u001b[95m 0.1723  \u001b[0m | \u001b[95m 7.045   \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 94.36   \u001b[0m | \u001b[95m 53.73   \u001b[0m | \u001b[95m 22.49   \u001b[0m | \u001b[95m 0.6974  \u001b[0m | \u001b[95m 0.462   \u001b[0m | \u001b[95m 0.9106  \u001b[0m |\n",
      "[-0.02389277 -0.01957616 -0.02386945 -0.02201238 -0.02505186 -0.02144016]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.02264 \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "[-0.0219766  -0.01861859 -0.02316602 -0.02112908 -0.02340179 -0.02039306]\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.02145 \u001b[0m | \u001b[95m 0.8052  \u001b[0m | \u001b[95m 0.07623 \u001b[0m | \u001b[95m 11.45   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 449.5   \u001b[0m | \u001b[95m 54.49   \u001b[0m | \u001b[95m 21.34   \u001b[0m | \u001b[95m 0.6751  \u001b[0m | \u001b[95m 0.2528  \u001b[0m | \u001b[95m 0.9977  \u001b[0m |\n",
      "[-0.02307765 -0.01882578 -0.02338133 -0.0207297  -0.02384732 -0.0206187 ]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.02175 \u001b[0m | \u001b[0m 0.802   \u001b[0m | \u001b[0m 0.04288 \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 165.6   \u001b[0m | \u001b[0m 97.91   \u001b[0m | \u001b[0m 55.54   \u001b[0m | \u001b[0m 19.29   \u001b[0m | \u001b[0m 0.9966  \u001b[0m | \u001b[0m 0.1609  \u001b[0m | \u001b[0m 0.8448  \u001b[0m |\n",
      "[-0.02307086 -0.02250527 -0.02404972 -0.02286779 -0.02479637 -0.02151396]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.02313 \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "[-0.02212508 -0.01900529 -0.02315861 -0.0206317  -0.02258495 -0.02082495]\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.02139 \u001b[0m | \u001b[95m 0.8466  \u001b[0m | \u001b[95m 0.1683  \u001b[0m | \u001b[95m 8.344   \u001b[0m | \u001b[95m 164.0   \u001b[0m | \u001b[95m 93.94   \u001b[0m | \u001b[95m 55.18   \u001b[0m | \u001b[95m 29.45   \u001b[0m | \u001b[95m 0.9618  \u001b[0m | \u001b[95m 0.4996  \u001b[0m | \u001b[95m 0.6311  \u001b[0m |\n",
      "[-0.02325333 -0.01875565 -0.02335906 -0.02077786 -0.02392001 -0.0206349 ]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.02178 \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 0.04673 \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 161.9   \u001b[0m | \u001b[0m 92.26   \u001b[0m | \u001b[0m 51.57   \u001b[0m | \u001b[0m 26.51   \u001b[0m | \u001b[0m 0.662   \u001b[0m | \u001b[0m 0.1365  \u001b[0m | \u001b[0m 0.7009  \u001b[0m |\n",
      "[-0.02252569 -0.0183635  -0.02298485 -0.02066188 -0.02330334 -0.02030637]\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.02136 \u001b[0m | \u001b[95m 0.7531  \u001b[0m | \u001b[95m 0.06981 \u001b[0m | \u001b[95m 2.48    \u001b[0m | \u001b[95m 160.2   \u001b[0m | \u001b[95m 95.87   \u001b[0m | \u001b[95m 59.1    \u001b[0m | \u001b[95m 28.86   \u001b[0m | \u001b[95m 0.8467  \u001b[0m | \u001b[95m 0.8583  \u001b[0m | \u001b[95m 0.6448  \u001b[0m |\n",
      "[-0.02200946 -0.01917252 -0.02229158 -0.02149752 -0.02329997 -0.01964427]\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.02132 \u001b[0m | \u001b[95m 0.6936  \u001b[0m | \u001b[95m 0.04227 \u001b[0m | \u001b[95m 2.666   \u001b[0m | \u001b[95m 35.2    \u001b[0m | \u001b[95m 307.7   \u001b[0m | \u001b[95m 158.9   \u001b[0m | \u001b[95m 26.02   \u001b[0m | \u001b[95m 0.369   \u001b[0m | \u001b[95m 0.46    \u001b[0m | \u001b[95m 0.6586  \u001b[0m |\n",
      "[-0.02230067 -0.01823795 -0.02276533 -0.02050897 -0.02307816 -0.020441  ]\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.02122 \u001b[0m | \u001b[95m 0.8701  \u001b[0m | \u001b[95m 0.0878  \u001b[0m | \u001b[95m 1.445   \u001b[0m | \u001b[95m 162.2   \u001b[0m | \u001b[95m 98.49   \u001b[0m | \u001b[95m 64.99   \u001b[0m | \u001b[95m 23.51   \u001b[0m | \u001b[95m 0.1237  \u001b[0m | \u001b[95m 0.7728  \u001b[0m | \u001b[95m 0.6999  \u001b[0m |\n",
      "[-0.02166411 -0.0183951  -0.02324807 -0.02073051 -0.02301899 -0.02059035]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.02127 \u001b[0m | \u001b[0m 0.8483  \u001b[0m | \u001b[0m 0.1109  \u001b[0m | \u001b[0m 2.417   \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 90.57   \u001b[0m | \u001b[0m 69.48   \u001b[0m | \u001b[0m 29.67   \u001b[0m | \u001b[0m 0.6562  \u001b[0m | \u001b[0m 0.9512  \u001b[0m | \u001b[0m 0.5303  \u001b[0m |\n",
      "[-0.02183543 -0.0198766  -0.02214088 -0.02354669 -0.02359087 -0.02050836]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.02192 \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 0.1365  \u001b[0m | \u001b[0m 12.87   \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 442.3   \u001b[0m | \u001b[0m 52.68   \u001b[0m | \u001b[0m 22.32   \u001b[0m | \u001b[0m 0.5271  \u001b[0m | \u001b[0m 0.6366  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "[-0.02201591 -0.01985137 -0.02337641 -0.02195567 -0.02241595 -0.019891  ]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.02158 \u001b[0m | \u001b[0m 0.8978  \u001b[0m | \u001b[0m 0.1646  \u001b[0m | \u001b[0m 1.931   \u001b[0m | \u001b[0m 37.81   \u001b[0m | \u001b[0m 313.5   \u001b[0m | \u001b[0m 149.5   \u001b[0m | \u001b[0m 26.85   \u001b[0m | \u001b[0m 0.6709  \u001b[0m | \u001b[0m 0.06265 \u001b[0m | \u001b[0m 0.7739  \u001b[0m |\n",
      "[-0.02209909 -0.01832519 -0.02324461 -0.02057626 -0.02325641 -0.02036329]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.02131 \u001b[0m | \u001b[0m 0.8245  \u001b[0m | \u001b[0m 0.09499 \u001b[0m | \u001b[0m 5.092   \u001b[0m | \u001b[0m 173.4   \u001b[0m | \u001b[0m 87.27   \u001b[0m | \u001b[0m 65.33   \u001b[0m | \u001b[0m 16.96   \u001b[0m | \u001b[0m 0.2003  \u001b[0m | \u001b[0m 0.3071  \u001b[0m | \u001b[0m 0.9733  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.021222014521504944, 'params': {'colsample_bytree': 0.870087646745415, 'learning_rate': 0.08780305417214739, 'max_depth': 1.4446361334131277, 'min_child_samples': 162.1921262604683, 'n_estimators': 98.49301073857738, 'num_iteration': 64.98843023386696, 'num_leaves': 23.50614461363032, 'reg_alpha': 0.12374297523349731, 'reg_lambda': 0.7728406389312494, 'subsample': 0.6998596711582784}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=64, num_iteration=64 will be ignored. Current value: num_iterations=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0190597\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.0187939\n",
      "[3]\tvalid_0's l2: 0.0186081\n",
      "[4]\tvalid_0's l2: 0.0183899\n",
      "[5]\tvalid_0's l2: 0.0183485\n",
      "[6]\tvalid_0's l2: 0.0181893\n",
      "[7]\tvalid_0's l2: 0.0180134\n",
      "[8]\tvalid_0's l2: 0.0178934\n",
      "[9]\tvalid_0's l2: 0.0178138\n",
      "[10]\tvalid_0's l2: 0.017667\n",
      "[11]\tvalid_0's l2: 0.0175781\n",
      "[12]\tvalid_0's l2: 0.0174312\n",
      "[13]\tvalid_0's l2: 0.0173771\n",
      "[14]\tvalid_0's l2: 0.0173545\n",
      "[15]\tvalid_0's l2: 0.0172519\n",
      "[16]\tvalid_0's l2: 0.0172454\n",
      "[17]\tvalid_0's l2: 0.0171779\n",
      "[18]\tvalid_0's l2: 0.0171454\n",
      "[19]\tvalid_0's l2: 0.0170911\n",
      "[20]\tvalid_0's l2: 0.0170512\n",
      "[21]\tvalid_0's l2: 0.0170351\n",
      "[22]\tvalid_0's l2: 0.016939\n",
      "[23]\tvalid_0's l2: 0.0168566\n",
      "[24]\tvalid_0's l2: 0.0168647\n",
      "[25]\tvalid_0's l2: 0.0168849\n",
      "[26]\tvalid_0's l2: 0.0168973\n",
      "[27]\tvalid_0's l2: 0.016867\n",
      "[28]\tvalid_0's l2: 0.0168643\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's l2: 0.0168566\n",
      "---- Train error ----\n",
      "0.02119034994777951\n",
      "---- CV error ----\n",
      "0.016856590640396924\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.0877930002312326\n",
      "mse = 0.02609444653819857\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.05822 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.05631 \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.05877 \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.06076 \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.05914 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.05944 \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.05857 \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 33.22   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 25.95   \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.8471  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.05745 \u001b[0m | \u001b[0m 0.9711  \u001b[0m | \u001b[0m 0.02912 \u001b[0m | \u001b[0m 12.07   \u001b[0m | \u001b[0m 45.49   \u001b[0m | \u001b[0m 570.9   \u001b[0m | \u001b[0m 140.4   \u001b[0m | \u001b[0m 22.95   \u001b[0m | \u001b[0m 0.08744 \u001b[0m | \u001b[0m 0.5617  \u001b[0m | \u001b[0m 0.906   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.05798 \u001b[0m | \u001b[0m 0.6623  \u001b[0m | \u001b[0m 0.03664 \u001b[0m | \u001b[0m 5.056   \u001b[0m | \u001b[0m 45.42   \u001b[0m | \u001b[0m 578.4   \u001b[0m | \u001b[0m 148.4   \u001b[0m | \u001b[0m 27.92   \u001b[0m | \u001b[0m 0.2247  \u001b[0m | \u001b[0m 0.3581  \u001b[0m | \u001b[0m 0.7762  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.05754 \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 176.8   \u001b[0m | \u001b[0m 702.2   \u001b[0m | \u001b[0m 99.75   \u001b[0m | \u001b[0m 4.208   \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.5864  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.05961 \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 574.3   \u001b[0m | \u001b[0m 167.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 0.02429 \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.05864 \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.09247 \u001b[0m | \u001b[0m 4.982   \u001b[0m | \u001b[0m 180.9   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 25.02   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.0583  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.05513 \u001b[0m | \u001b[95m 0.9909  \u001b[0m | \u001b[95m 0.02365 \u001b[0m | \u001b[95m 1.034   \u001b[0m | \u001b[95m 26.65   \u001b[0m | \u001b[95m 462.4   \u001b[0m | \u001b[95m 165.0   \u001b[0m | \u001b[95m 28.78   \u001b[0m | \u001b[95m 0.5494  \u001b[0m | \u001b[95m 0.8478  \u001b[0m | \u001b[95m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.05755 \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.06011 \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.05536 \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.05739 \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.05701 \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.05951 \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.05513042585444584, 'params': {'colsample_bytree': 0.9908779252093576, 'learning_rate': 0.023645155499684205, 'max_depth': 1.0335726409193164, 'min_child_samples': 26.65287918702078, 'n_estimators': 462.40934047085034, 'num_iteration': 164.99276961578056, 'num_leaves': 28.778683765753836, 'reg_alpha': 0.5493720730451696, 'reg_lambda': 0.8477561259821585, 'subsample': 0.7358780888368514}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=164, num_iteration=164 will be ignored. Current value: num_iterations=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0493167\tvalid_0's binary_logloss: 0.204192\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.0491804\tvalid_0's binary_logloss: 0.203051\n",
      "[3]\tvalid_0's l2: 0.0490497\tvalid_0's binary_logloss: 0.201982\n",
      "[4]\tvalid_0's l2: 0.0489424\tvalid_0's binary_logloss: 0.201125\n",
      "[5]\tvalid_0's l2: 0.0488177\tvalid_0's binary_logloss: 0.200141\n",
      "[6]\tvalid_0's l2: 0.0487153\tvalid_0's binary_logloss: 0.199355\n",
      "[7]\tvalid_0's l2: 0.0485965\tvalid_0's binary_logloss: 0.198449\n",
      "[8]\tvalid_0's l2: 0.0484988\tvalid_0's binary_logloss: 0.197727\n",
      "[9]\tvalid_0's l2: 0.0483856\tvalid_0's binary_logloss: 0.19689\n",
      "[10]\tvalid_0's l2: 0.0482926\tvalid_0's binary_logloss: 0.196225\n",
      "[11]\tvalid_0's l2: 0.0481849\tvalid_0's binary_logloss: 0.19545\n",
      "[12]\tvalid_0's l2: 0.0480964\tvalid_0's binary_logloss: 0.194837\n",
      "[13]\tvalid_0's l2: 0.0479939\tvalid_0's binary_logloss: 0.194119\n",
      "[14]\tvalid_0's l2: 0.0478957\tvalid_0's binary_logloss: 0.193438\n",
      "[15]\tvalid_0's l2: 0.0478123\tvalid_0's binary_logloss: 0.192884\n",
      "[16]\tvalid_0's l2: 0.0477924\tvalid_0's binary_logloss: 0.192813\n",
      "[17]\tvalid_0's l2: 0.0477123\tvalid_0's binary_logloss: 0.192292\n",
      "[18]\tvalid_0's l2: 0.0476201\tvalid_0's binary_logloss: 0.191677\n",
      "[19]\tvalid_0's l2: 0.0476018\tvalid_0's binary_logloss: 0.191624\n",
      "[20]\tvalid_0's l2: 0.0475857\tvalid_0's binary_logloss: 0.191565\n",
      "[21]\tvalid_0's l2: 0.0474975\tvalid_0's binary_logloss: 0.190988\n",
      "[22]\tvalid_0's l2: 0.0474217\tvalid_0's binary_logloss: 0.190519\n",
      "[23]\tvalid_0's l2: 0.0474392\tvalid_0's binary_logloss: 0.190647\n",
      "[24]\tvalid_0's l2: 0.0474245\tvalid_0's binary_logloss: 0.1906\n",
      "[25]\tvalid_0's l2: 0.0474077\tvalid_0's binary_logloss: 0.190563\n",
      "[26]\tvalid_0's l2: 0.0473736\tvalid_0's binary_logloss: 0.190379\n",
      "[27]\tvalid_0's l2: 0.0473004\tvalid_0's binary_logloss: 0.18994\n",
      "[28]\tvalid_0's l2: 0.0473188\tvalid_0's binary_logloss: 0.190069\n",
      "[29]\tvalid_0's l2: 0.047292\tvalid_0's binary_logloss: 0.189865\n",
      "[30]\tvalid_0's l2: 0.0472792\tvalid_0's binary_logloss: 0.189829\n",
      "[31]\tvalid_0's l2: 0.0472673\tvalid_0's binary_logloss: 0.189799\n",
      "[32]\tvalid_0's l2: 0.0471853\tvalid_0's binary_logloss: 0.189287\n",
      "[33]\tvalid_0's l2: 0.0471685\tvalid_0's binary_logloss: 0.189144\n",
      "[34]\tvalid_0's l2: 0.047121\tvalid_0's binary_logloss: 0.188862\n",
      "[35]\tvalid_0's l2: 0.04714\tvalid_0's binary_logloss: 0.188993\n",
      "[36]\tvalid_0's l2: 0.0471287\tvalid_0's binary_logloss: 0.188968\n",
      "[37]\tvalid_0's l2: 0.0470969\tvalid_0's binary_logloss: 0.18881\n",
      "[38]\tvalid_0's l2: 0.0470744\tvalid_0's binary_logloss: 0.188629\n",
      "[39]\tvalid_0's l2: 0.0470045\tvalid_0's binary_logloss: 0.188233\n",
      "[40]\tvalid_0's l2: 0.046994\tvalid_0's binary_logloss: 0.188216\n",
      "[41]\tvalid_0's l2: 0.0470141\tvalid_0's binary_logloss: 0.188348\n",
      "[42]\tvalid_0's l2: 0.0470007\tvalid_0's binary_logloss: 0.188223\n",
      "[43]\tvalid_0's l2: 0.0469917\tvalid_0's binary_logloss: 0.188208\n",
      "[44]\tvalid_0's l2: 0.046978\tvalid_0's binary_logloss: 0.188192\n",
      "[45]\tvalid_0's l2: 0.0469488\tvalid_0's binary_logloss: 0.188056\n",
      "[46]\tvalid_0's l2: 0.0468905\tvalid_0's binary_logloss: 0.187701\n",
      "[47]\tvalid_0's l2: 0.046816\tvalid_0's binary_logloss: 0.187254\n",
      "[48]\tvalid_0's l2: 0.0468389\tvalid_0's binary_logloss: 0.187389\n",
      "[49]\tvalid_0's l2: 0.0468283\tvalid_0's binary_logloss: 0.187307\n",
      "[50]\tvalid_0's l2: 0.0468204\tvalid_0's binary_logloss: 0.1873\n",
      "[51]\tvalid_0's l2: 0.0468201\tvalid_0's binary_logloss: 0.187263\n",
      "[52]\tvalid_0's l2: 0.0468457\tvalid_0's binary_logloss: 0.187323\n",
      "[53]\tvalid_0's l2: 0.0467787\tvalid_0's binary_logloss: 0.186964\n",
      "[54]\tvalid_0's l2: 0.046762\tvalid_0's binary_logloss: 0.186811\n",
      "[55]\tvalid_0's l2: 0.0467618\tvalid_0's binary_logloss: 0.186816\n",
      "[56]\tvalid_0's l2: 0.0467832\tvalid_0's binary_logloss: 0.186946\n",
      "[57]\tvalid_0's l2: 0.0467371\tvalid_0's binary_logloss: 0.186706\n",
      "[58]\tvalid_0's l2: 0.0467309\tvalid_0's binary_logloss: 0.186706\n",
      "[59]\tvalid_0's l2: 0.0467242\tvalid_0's binary_logloss: 0.186707\n",
      "[60]\tvalid_0's l2: 0.046698\tvalid_0's binary_logloss: 0.186595\n",
      "[61]\tvalid_0's l2: 0.0466892\tvalid_0's binary_logloss: 0.186523\n",
      "[62]\tvalid_0's l2: 0.04668\tvalid_0's binary_logloss: 0.186419\n",
      "[63]\tvalid_0's l2: 0.0466806\tvalid_0's binary_logloss: 0.186429\n",
      "[64]\tvalid_0's l2: 0.0466277\tvalid_0's binary_logloss: 0.186114\n",
      "[65]\tvalid_0's l2: 0.0465625\tvalid_0's binary_logloss: 0.185781\n",
      "[66]\tvalid_0's l2: 0.0465852\tvalid_0's binary_logloss: 0.185909\n",
      "[67]\tvalid_0's l2: 0.0465724\tvalid_0's binary_logloss: 0.185776\n",
      "[68]\tvalid_0's l2: 0.0465999\tvalid_0's binary_logloss: 0.185844\n",
      "[69]\tvalid_0's l2: 0.0465947\tvalid_0's binary_logloss: 0.185851\n",
      "[70]\tvalid_0's l2: 0.0465965\tvalid_0's binary_logloss: 0.185868\n",
      "[71]\tvalid_0's l2: 0.0465126\tvalid_0's binary_logloss: 0.185392\n",
      "[72]\tvalid_0's l2: 0.046506\tvalid_0's binary_logloss: 0.18533\n",
      "[73]\tvalid_0's l2: 0.0465307\tvalid_0's binary_logloss: 0.185462\n",
      "[74]\tvalid_0's l2: 0.0465205\tvalid_0's binary_logloss: 0.185463\n",
      "[75]\tvalid_0's l2: 0.0464974\tvalid_0's binary_logloss: 0.18537\n",
      "[76]\tvalid_0's l2: 0.0464943\tvalid_0's binary_logloss: 0.185337\n",
      "[77]\tvalid_0's l2: 0.0464915\tvalid_0's binary_logloss: 0.185348\n",
      "[78]\tvalid_0's l2: 0.046428\tvalid_0's binary_logloss: 0.185037\n",
      "[79]\tvalid_0's l2: 0.0464519\tvalid_0's binary_logloss: 0.185166\n",
      "[80]\tvalid_0's l2: 0.0464611\tvalid_0's binary_logloss: 0.185253\n",
      "[81]\tvalid_0's l2: 0.0464639\tvalid_0's binary_logloss: 0.185275\n",
      "[82]\tvalid_0's l2: 0.0464187\tvalid_0's binary_logloss: 0.185068\n",
      "[83]\tvalid_0's l2: 0.0464142\tvalid_0's binary_logloss: 0.185082\n",
      "[84]\tvalid_0's l2: 0.0463652\tvalid_0's binary_logloss: 0.184803\n",
      "[85]\tvalid_0's l2: 0.0463947\tvalid_0's binary_logloss: 0.184876\n",
      "[86]\tvalid_0's l2: 0.0463858\tvalid_0's binary_logloss: 0.184766\n",
      "[87]\tvalid_0's l2: 0.0463813\tvalid_0's binary_logloss: 0.184716\n",
      "[88]\tvalid_0's l2: 0.0463211\tvalid_0's binary_logloss: 0.184366\n",
      "[89]\tvalid_0's l2: 0.0463291\tvalid_0's binary_logloss: 0.184392\n",
      "[90]\tvalid_0's l2: 0.0463278\tvalid_0's binary_logloss: 0.184309\n",
      "[91]\tvalid_0's l2: 0.0463316\tvalid_0's binary_logloss: 0.184336\n",
      "[92]\tvalid_0's l2: 0.0462524\tvalid_0's binary_logloss: 0.183911\n",
      "[93]\tvalid_0's l2: 0.0462384\tvalid_0's binary_logloss: 0.183787\n",
      "[94]\tvalid_0's l2: 0.046248\tvalid_0's binary_logloss: 0.183876\n",
      "[95]\tvalid_0's l2: 0.0462441\tvalid_0's binary_logloss: 0.183897\n",
      "[96]\tvalid_0's l2: 0.0462401\tvalid_0's binary_logloss: 0.183808\n",
      "[97]\tvalid_0's l2: 0.0462648\tvalid_0's binary_logloss: 0.183935\n",
      "[98]\tvalid_0's l2: 0.0462676\tvalid_0's binary_logloss: 0.183917\n",
      "[99]\tvalid_0's l2: 0.0462487\tvalid_0's binary_logloss: 0.183844\n",
      "[100]\tvalid_0's l2: 0.0462553\tvalid_0's binary_logloss: 0.18383\n",
      "[101]\tvalid_0's l2: 0.0461963\tvalid_0's binary_logloss: 0.183551\n",
      "[102]\tvalid_0's l2: 0.0462003\tvalid_0's binary_logloss: 0.183582\n",
      "[103]\tvalid_0's l2: 0.0461879\tvalid_0's binary_logloss: 0.18355\n",
      "[104]\tvalid_0's l2: 0.046186\tvalid_0's binary_logloss: 0.183509\n",
      "[105]\tvalid_0's l2: 0.0461137\tvalid_0's binary_logloss: 0.183137\n",
      "[106]\tvalid_0's l2: 0.046102\tvalid_0's binary_logloss: 0.183026\n",
      "[107]\tvalid_0's l2: 0.0460981\tvalid_0's binary_logloss: 0.182995\n",
      "[108]\tvalid_0's l2: 0.0460754\tvalid_0's binary_logloss: 0.182903\n",
      "[109]\tvalid_0's l2: 0.0460862\tvalid_0's binary_logloss: 0.182992\n",
      "[110]\tvalid_0's l2: 0.046054\tvalid_0's binary_logloss: 0.182851\n",
      "[111]\tvalid_0's l2: 0.0460511\tvalid_0's binary_logloss: 0.182877\n",
      "[112]\tvalid_0's l2: 0.0460595\tvalid_0's binary_logloss: 0.182907\n",
      "[113]\tvalid_0's l2: 0.046038\tvalid_0's binary_logloss: 0.182793\n",
      "[114]\tvalid_0's l2: 0.0460333\tvalid_0's binary_logloss: 0.182703\n",
      "[115]\tvalid_0's l2: 0.0460349\tvalid_0's binary_logloss: 0.182724\n",
      "[116]\tvalid_0's l2: 0.0460396\tvalid_0's binary_logloss: 0.18276\n",
      "[117]\tvalid_0's l2: 0.0460656\tvalid_0's binary_logloss: 0.182886\n",
      "[118]\tvalid_0's l2: 0.0460714\tvalid_0's binary_logloss: 0.18288\n",
      "[119]\tvalid_0's l2: 0.0459961\tvalid_0's binary_logloss: 0.182498\n",
      "[120]\tvalid_0's l2: 0.0459391\tvalid_0's binary_logloss: 0.182242\n",
      "[121]\tvalid_0's l2: 0.0459291\tvalid_0's binary_logloss: 0.182141\n",
      "[122]\tvalid_0's l2: 0.0459085\tvalid_0's binary_logloss: 0.182059\n",
      "[123]\tvalid_0's l2: 0.0459055\tvalid_0's binary_logloss: 0.181982\n",
      "[124]\tvalid_0's l2: 0.0458939\tvalid_0's binary_logloss: 0.181958\n",
      "[125]\tvalid_0's l2: 0.0458731\tvalid_0's binary_logloss: 0.181849\n",
      "[126]\tvalid_0's l2: 0.0458746\tvalid_0's binary_logloss: 0.181783\n",
      "[127]\tvalid_0's l2: 0.0458861\tvalid_0's binary_logloss: 0.18187\n",
      "[128]\tvalid_0's l2: 0.0458799\tvalid_0's binary_logloss: 0.181796\n",
      "[129]\tvalid_0's l2: 0.0458795\tvalid_0's binary_logloss: 0.181763\n",
      "[130]\tvalid_0's l2: 0.0458765\tvalid_0's binary_logloss: 0.181739\n",
      "[131]\tvalid_0's l2: 0.0458469\tvalid_0's binary_logloss: 0.18161\n",
      "[132]\tvalid_0's l2: 0.0458525\tvalid_0's binary_logloss: 0.18165\n",
      "[133]\tvalid_0's l2: 0.0458372\tvalid_0's binary_logloss: 0.181595\n",
      "[134]\tvalid_0's l2: 0.0458357\tvalid_0's binary_logloss: 0.181625\n",
      "[135]\tvalid_0's l2: 0.0458691\tvalid_0's binary_logloss: 0.181705\n",
      "[136]\tvalid_0's l2: 0.0458968\tvalid_0's binary_logloss: 0.18183\n",
      "[137]\tvalid_0's l2: 0.0458552\tvalid_0's binary_logloss: 0.181666\n",
      "[138]\tvalid_0's l2: 0.0458485\tvalid_0's binary_logloss: 0.181567\n",
      "[139]\tvalid_0's l2: 0.0458409\tvalid_0's binary_logloss: 0.181478\n",
      "[140]\tvalid_0's l2: 0.0458203\tvalid_0's binary_logloss: 0.181376\n",
      "[141]\tvalid_0's l2: 0.0458009\tvalid_0's binary_logloss: 0.181301\n",
      "[142]\tvalid_0's l2: 0.0458089\tvalid_0's binary_logloss: 0.181305\n",
      "[143]\tvalid_0's l2: 0.0457719\tvalid_0's binary_logloss: 0.181109\n",
      "[144]\tvalid_0's l2: 0.0457838\tvalid_0's binary_logloss: 0.181196\n",
      "[145]\tvalid_0's l2: 0.0457153\tvalid_0's binary_logloss: 0.180869\n",
      "[146]\tvalid_0's l2: 0.0457214\tvalid_0's binary_logloss: 0.180912\n",
      "[147]\tvalid_0's l2: 0.04568\tvalid_0's binary_logloss: 0.180692\n",
      "[148]\tvalid_0's l2: 0.0456898\tvalid_0's binary_logloss: 0.180725\n",
      "[149]\tvalid_0's l2: 0.0456366\tvalid_0's binary_logloss: 0.180497\n",
      "[150]\tvalid_0's l2: 0.0456348\tvalid_0's binary_logloss: 0.180479\n",
      "[151]\tvalid_0's l2: 0.0456257\tvalid_0's binary_logloss: 0.180463\n",
      "[152]\tvalid_0's l2: 0.0456255\tvalid_0's binary_logloss: 0.180498\n",
      "[153]\tvalid_0's l2: 0.045598\tvalid_0's binary_logloss: 0.18038\n",
      "[154]\tvalid_0's l2: 0.0455976\tvalid_0's binary_logloss: 0.180355\n",
      "[155]\tvalid_0's l2: 0.0455936\tvalid_0's binary_logloss: 0.180292\n",
      "[156]\tvalid_0's l2: 0.0455725\tvalid_0's binary_logloss: 0.180197\n",
      "[157]\tvalid_0's l2: 0.0455546\tvalid_0's binary_logloss: 0.180129\n",
      "[158]\tvalid_0's l2: 0.0455542\tvalid_0's binary_logloss: 0.180061\n",
      "[159]\tvalid_0's l2: 0.0455486\tvalid_0's binary_logloss: 0.17998\n",
      "[160]\tvalid_0's l2: 0.0454771\tvalid_0's binary_logloss: 0.179645\n",
      "[161]\tvalid_0's l2: 0.0454841\tvalid_0's binary_logloss: 0.179692\n",
      "[162]\tvalid_0's l2: 0.0455129\tvalid_0's binary_logloss: 0.179817\n",
      "[163]\tvalid_0's l2: 0.0454774\tvalid_0's binary_logloss: 0.179634\n",
      "[164]\tvalid_0's l2: 0.0454893\tvalid_0's binary_logloss: 0.17972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[160]\tvalid_0's l2: 0.0454771\tvalid_0's binary_logloss: 0.179645\n",
      "---- Train error ----\n",
      "0.048465668568594966\n",
      "---- CV error ----\n",
      "0.04547708442887985\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.05180439037745488\n",
      "mse = 0.050633443020071826\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1774  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1757  \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.188   \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.198   \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1849  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1943  \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1893  \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 33.22   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 25.95   \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.8471  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1671  \u001b[0m | \u001b[95m 0.7016  \u001b[0m | \u001b[95m 0.0116  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 859.6   \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 0.2637  \u001b[0m | \u001b[95m 0.8152  \u001b[0m | \u001b[95m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1796  \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1724  \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 176.8   \u001b[0m | \u001b[0m 702.2   \u001b[0m | \u001b[0m 99.75   \u001b[0m | \u001b[0m 4.208   \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.5864  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1828  \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 574.3   \u001b[0m | \u001b[0m 167.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 0.02429 \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1748  \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.09247 \u001b[0m | \u001b[0m 4.982   \u001b[0m | \u001b[0m 180.9   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 25.02   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1799  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1683  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1763  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1971  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.169   \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1721  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1699  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1801  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.1671479653853819, 'params': {'colsample_bytree': 0.701576615034939, 'learning_rate': 0.011603206455630607, 'max_depth': 14.164722134140465, 'min_child_samples': 149.74628670951, 'n_estimators': 859.6058494461143, 'num_iteration': 91.9167642600271, 'num_leaves': 13.974128231816456, 'reg_alpha': 0.263747610013786, 'reg_lambda': 0.8151771432994619, 'subsample': 0.852344846924755}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=91, num_iteration=91 will be ignored. Current value: num_iterations=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.154564\tvalid_0's binary_logloss: 0.488133\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.154606\tvalid_0's binary_logloss: 0.488256\n",
      "[3]\tvalid_0's l2: 0.154621\tvalid_0's binary_logloss: 0.488299\n",
      "[4]\tvalid_0's l2: 0.154631\tvalid_0's binary_logloss: 0.488329\n",
      "[5]\tvalid_0's l2: 0.154676\tvalid_0's binary_logloss: 0.488464\n",
      "[6]\tvalid_0's l2: 0.154621\tvalid_0's binary_logloss: 0.4883\n",
      "[7]\tvalid_0's l2: 0.15464\tvalid_0's binary_logloss: 0.488353\n",
      "[8]\tvalid_0's l2: 0.154655\tvalid_0's binary_logloss: 0.488397\n",
      "[9]\tvalid_0's l2: 0.154704\tvalid_0's binary_logloss: 0.488538\n",
      "[10]\tvalid_0's l2: 0.154755\tvalid_0's binary_logloss: 0.488683\n",
      "[11]\tvalid_0's l2: 0.154749\tvalid_0's binary_logloss: 0.488661\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l2: 0.154564\tvalid_0's binary_logloss: 0.488133\n",
      "---- Train error ----\n",
      "0.16775670167059656\n",
      "---- CV error ----\n",
      "0.15456409151019343\n",
      "---- leaderboard stats ----\n",
      "r2 = -0.0004677795201850632\n",
      "mse = 0.17419679113048317\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1818  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1831  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1975  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2044  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1927  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2011  \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1947  \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 33.22   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 25.95   \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.8471  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1772  \u001b[0m | \u001b[95m 0.7016  \u001b[0m | \u001b[95m 0.0116  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 859.6   \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 0.2637  \u001b[0m | \u001b[95m 0.8152  \u001b[0m | \u001b[95m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1856  \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.183   \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 176.8   \u001b[0m | \u001b[0m 702.2   \u001b[0m | \u001b[0m 99.75   \u001b[0m | \u001b[0m 4.208   \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.5864  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1931  \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 574.3   \u001b[0m | \u001b[0m 167.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 0.02429 \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.186   \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.09247 \u001b[0m | \u001b[0m 4.982   \u001b[0m | \u001b[0m 180.9   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 25.02   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1837  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1741  \u001b[0m | \u001b[95m 0.9909  \u001b[0m | \u001b[95m 0.02365 \u001b[0m | \u001b[95m 1.034   \u001b[0m | \u001b[95m 26.65   \u001b[0m | \u001b[95m 462.4   \u001b[0m | \u001b[95m 165.0   \u001b[0m | \u001b[95m 28.78   \u001b[0m | \u001b[95m 0.5494  \u001b[0m | \u001b[95m 0.8478  \u001b[0m | \u001b[95m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1866  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2024  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1766  \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1811  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1796  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1925  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.17411290036004115, 'params': {'colsample_bytree': 0.9908779252093576, 'learning_rate': 0.023645155499684205, 'max_depth': 1.0335726409193164, 'min_child_samples': 26.65287918702078, 'n_estimators': 462.40934047085034, 'num_iteration': 164.99276961578056, 'num_leaves': 28.778683765753836, 'reg_alpha': 0.5493720730451696, 'reg_lambda': 0.8477561259821585, 'subsample': 0.7358780888368514}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=164, num_iteration=164 will be ignored. Current value: num_iterations=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.174338\tvalid_0's binary_logloss: 0.533093\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.174207\tvalid_0's binary_logloss: 0.532732\n",
      "[3]\tvalid_0's l2: 0.174085\tvalid_0's binary_logloss: 0.532397\n",
      "[4]\tvalid_0's l2: 0.17397\tvalid_0's binary_logloss: 0.532085\n",
      "[5]\tvalid_0's l2: 0.173863\tvalid_0's binary_logloss: 0.531794\n",
      "[6]\tvalid_0's l2: 0.173764\tvalid_0's binary_logloss: 0.531524\n",
      "[7]\tvalid_0's l2: 0.173532\tvalid_0's binary_logloss: 0.530895\n",
      "[8]\tvalid_0's l2: 0.173439\tvalid_0's binary_logloss: 0.530645\n",
      "[9]\tvalid_0's l2: 0.173212\tvalid_0's binary_logloss: 0.530018\n",
      "[10]\tvalid_0's l2: 0.17299\tvalid_0's binary_logloss: 0.529425\n",
      "[11]\tvalid_0's l2: 0.17295\tvalid_0's binary_logloss: 0.529313\n",
      "[12]\tvalid_0's l2: 0.172866\tvalid_0's binary_logloss: 0.529087\n",
      "[13]\tvalid_0's l2: 0.172651\tvalid_0's binary_logloss: 0.528496\n",
      "[14]\tvalid_0's l2: 0.172438\tvalid_0's binary_logloss: 0.527938\n",
      "[15]\tvalid_0's l2: 0.172403\tvalid_0's binary_logloss: 0.527839\n",
      "[16]\tvalid_0's l2: 0.172328\tvalid_0's binary_logloss: 0.527636\n",
      "[17]\tvalid_0's l2: 0.172124\tvalid_0's binary_logloss: 0.527078\n",
      "[18]\tvalid_0's l2: 0.17192\tvalid_0's binary_logloss: 0.526552\n",
      "[19]\tvalid_0's l2: 0.171723\tvalid_0's binary_logloss: 0.525994\n",
      "[20]\tvalid_0's l2: 0.171528\tvalid_0's binary_logloss: 0.525466\n",
      "[21]\tvalid_0's l2: 0.171333\tvalid_0's binary_logloss: 0.524969\n",
      "[22]\tvalid_0's l2: 0.171303\tvalid_0's binary_logloss: 0.524882\n",
      "[23]\tvalid_0's l2: 0.171117\tvalid_0's binary_logloss: 0.524353\n",
      "[24]\tvalid_0's l2: 0.171053\tvalid_0's binary_logloss: 0.52418\n",
      "[25]\tvalid_0's l2: 0.170782\tvalid_0's binary_logloss: 0.523434\n",
      "[26]\tvalid_0's l2: 0.1706\tvalid_0's binary_logloss: 0.522941\n",
      "[27]\tvalid_0's l2: 0.170413\tvalid_0's binary_logloss: 0.522474\n",
      "[28]\tvalid_0's l2: 0.17024\tvalid_0's binary_logloss: 0.521977\n",
      "[29]\tvalid_0's l2: 0.169982\tvalid_0's binary_logloss: 0.521273\n",
      "[30]\tvalid_0's l2: 0.169957\tvalid_0's binary_logloss: 0.521201\n",
      "[31]\tvalid_0's l2: 0.169784\tvalid_0's binary_logloss: 0.520736\n",
      "[32]\tvalid_0's l2: 0.169606\tvalid_0's binary_logloss: 0.520297\n",
      "[33]\tvalid_0's l2: 0.169555\tvalid_0's binary_logloss: 0.520153\n",
      "[34]\tvalid_0's l2: 0.169462\tvalid_0's binary_logloss: 0.519922\n",
      "[35]\tvalid_0's l2: 0.169219\tvalid_0's binary_logloss: 0.519263\n",
      "[36]\tvalid_0's l2: 0.169055\tvalid_0's binary_logloss: 0.518826\n",
      "[37]\tvalid_0's l2: 0.168883\tvalid_0's binary_logloss: 0.518411\n",
      "[38]\tvalid_0's l2: 0.168728\tvalid_0's binary_logloss: 0.517958\n",
      "[39]\tvalid_0's l2: 0.168709\tvalid_0's binary_logloss: 0.5179\n",
      "[40]\tvalid_0's l2: 0.168667\tvalid_0's binary_logloss: 0.517778\n",
      "[41]\tvalid_0's l2: 0.168512\tvalid_0's binary_logloss: 0.517367\n",
      "[42]\tvalid_0's l2: 0.168349\tvalid_0's binary_logloss: 0.516976\n",
      "[43]\tvalid_0's l2: 0.168121\tvalid_0's binary_logloss: 0.516364\n",
      "[44]\tvalid_0's l2: 0.168039\tvalid_0's binary_logloss: 0.516159\n",
      "[45]\tvalid_0's l2: 0.167897\tvalid_0's binary_logloss: 0.51574\n",
      "[46]\tvalid_0's l2: 0.167762\tvalid_0's binary_logloss: 0.515396\n",
      "[47]\tvalid_0's l2: 0.167605\tvalid_0's binary_logloss: 0.515028\n",
      "[48]\tvalid_0's l2: 0.167459\tvalid_0's binary_logloss: 0.514641\n",
      "[49]\tvalid_0's l2: 0.167339\tvalid_0's binary_logloss: 0.514318\n",
      "[50]\tvalid_0's l2: 0.167124\tvalid_0's binary_logloss: 0.513745\n",
      "[51]\tvalid_0's l2: 0.167049\tvalid_0's binary_logloss: 0.51356\n",
      "[52]\tvalid_0's l2: 0.166899\tvalid_0's binary_logloss: 0.513212\n",
      "[53]\tvalid_0's l2: 0.166769\tvalid_0's binary_logloss: 0.512824\n",
      "[54]\tvalid_0's l2: 0.166631\tvalid_0's binary_logloss: 0.51246\n",
      "[55]\tvalid_0's l2: 0.166618\tvalid_0's binary_logloss: 0.512416\n",
      "[56]\tvalid_0's l2: 0.166505\tvalid_0's binary_logloss: 0.512113\n",
      "[57]\tvalid_0's l2: 0.16638\tvalid_0's binary_logloss: 0.511798\n",
      "[58]\tvalid_0's l2: 0.16635\tvalid_0's binary_logloss: 0.511707\n",
      "[59]\tvalid_0's l2: 0.166207\tvalid_0's binary_logloss: 0.51138\n",
      "[60]\tvalid_0's l2: 0.166007\tvalid_0's binary_logloss: 0.510849\n",
      "[61]\tvalid_0's l2: 0.16594\tvalid_0's binary_logloss: 0.510688\n",
      "[62]\tvalid_0's l2: 0.165811\tvalid_0's binary_logloss: 0.510348\n",
      "[63]\tvalid_0's l2: 0.165706\tvalid_0's binary_logloss: 0.510065\n",
      "[64]\tvalid_0's l2: 0.16559\tvalid_0's binary_logloss: 0.509711\n",
      "[65]\tvalid_0's l2: 0.165473\tvalid_0's binary_logloss: 0.509421\n",
      "[66]\tvalid_0's l2: 0.165336\tvalid_0's binary_logloss: 0.509112\n",
      "[67]\tvalid_0's l2: 0.165327\tvalid_0's binary_logloss: 0.509077\n",
      "[68]\tvalid_0's l2: 0.165139\tvalid_0's binary_logloss: 0.508581\n",
      "[69]\tvalid_0's l2: 0.165018\tvalid_0's binary_logloss: 0.508263\n",
      "[70]\tvalid_0's l2: 0.164919\tvalid_0's binary_logloss: 0.507998\n",
      "[71]\tvalid_0's l2: 0.16486\tvalid_0's binary_logloss: 0.507855\n",
      "[72]\tvalid_0's l2: 0.164729\tvalid_0's binary_logloss: 0.507564\n",
      "[73]\tvalid_0's l2: 0.164619\tvalid_0's binary_logloss: 0.507294\n",
      "[74]\tvalid_0's l2: 0.164598\tvalid_0's binary_logloss: 0.507225\n",
      "[75]\tvalid_0's l2: 0.164494\tvalid_0's binary_logloss: 0.506902\n",
      "[76]\tvalid_0's l2: 0.164381\tvalid_0's binary_logloss: 0.506605\n",
      "[77]\tvalid_0's l2: 0.16435\tvalid_0's binary_logloss: 0.506499\n",
      "[78]\tvalid_0's l2: 0.164258\tvalid_0's binary_logloss: 0.506252\n",
      "[79]\tvalid_0's l2: 0.164084\tvalid_0's binary_logloss: 0.505794\n",
      "[80]\tvalid_0's l2: 0.163959\tvalid_0's binary_logloss: 0.505519\n",
      "[81]\tvalid_0's l2: 0.163954\tvalid_0's binary_logloss: 0.505493\n",
      "[82]\tvalid_0's l2: 0.163852\tvalid_0's binary_logloss: 0.505242\n",
      "[83]\tvalid_0's l2: 0.163745\tvalid_0's binary_logloss: 0.504961\n",
      "[84]\tvalid_0's l2: 0.163693\tvalid_0's binary_logloss: 0.50484\n",
      "[85]\tvalid_0's l2: 0.163607\tvalid_0's binary_logloss: 0.504608\n",
      "[86]\tvalid_0's l2: 0.163487\tvalid_0's binary_logloss: 0.504348\n",
      "[87]\tvalid_0's l2: 0.163323\tvalid_0's binary_logloss: 0.503916\n",
      "[88]\tvalid_0's l2: 0.163296\tvalid_0's binary_logloss: 0.503822\n",
      "[89]\tvalid_0's l2: 0.163195\tvalid_0's binary_logloss: 0.503555\n",
      "[90]\tvalid_0's l2: 0.163105\tvalid_0's binary_logloss: 0.503266\n",
      "[91]\tvalid_0's l2: 0.163024\tvalid_0's binary_logloss: 0.503048\n",
      "[92]\tvalid_0's l2: 0.162911\tvalid_0's binary_logloss: 0.502802\n",
      "[93]\tvalid_0's l2: 0.162816\tvalid_0's binary_logloss: 0.502573\n",
      "[94]\tvalid_0's l2: 0.162768\tvalid_0's binary_logloss: 0.502436\n",
      "[95]\tvalid_0's l2: 0.162789\tvalid_0's binary_logloss: 0.502477\n",
      "[96]\tvalid_0's l2: 0.162801\tvalid_0's binary_logloss: 0.502494\n",
      "[97]\tvalid_0's l2: 0.162647\tvalid_0's binary_logloss: 0.502088\n",
      "[98]\tvalid_0's l2: 0.16274\tvalid_0's binary_logloss: 0.502328\n",
      "[99]\tvalid_0's l2: 0.162666\tvalid_0's binary_logloss: 0.502115\n",
      "[100]\tvalid_0's l2: 0.162572\tvalid_0's binary_logloss: 0.501865\n",
      "[101]\tvalid_0's l2: 0.162549\tvalid_0's binary_logloss: 0.501781\n",
      "[102]\tvalid_0's l2: 0.162503\tvalid_0's binary_logloss: 0.501652\n",
      "[103]\tvalid_0's l2: 0.162394\tvalid_0's binary_logloss: 0.50142\n",
      "[104]\tvalid_0's l2: 0.16232\tvalid_0's binary_logloss: 0.501217\n",
      "[105]\tvalid_0's l2: 0.162275\tvalid_0's binary_logloss: 0.501116\n",
      "[106]\tvalid_0's l2: 0.162367\tvalid_0's binary_logloss: 0.501355\n",
      "[107]\tvalid_0's l2: 0.162357\tvalid_0's binary_logloss: 0.501313\n",
      "[108]\tvalid_0's l2: 0.162287\tvalid_0's binary_logloss: 0.501109\n",
      "[109]\tvalid_0's l2: 0.162199\tvalid_0's binary_logloss: 0.500898\n",
      "[110]\tvalid_0's l2: 0.162198\tvalid_0's binary_logloss: 0.500873\n",
      "[111]\tvalid_0's l2: 0.162221\tvalid_0's binary_logloss: 0.500918\n",
      "[112]\tvalid_0's l2: 0.162178\tvalid_0's binary_logloss: 0.500798\n",
      "[113]\tvalid_0's l2: 0.162035\tvalid_0's binary_logloss: 0.500418\n",
      "[114]\tvalid_0's l2: 0.161931\tvalid_0's binary_logloss: 0.500198\n",
      "[115]\tvalid_0's l2: 0.161844\tvalid_0's binary_logloss: 0.499965\n",
      "[116]\tvalid_0's l2: 0.161823\tvalid_0's binary_logloss: 0.499889\n",
      "[117]\tvalid_0's l2: 0.161916\tvalid_0's binary_logloss: 0.500126\n",
      "[118]\tvalid_0's l2: 0.161849\tvalid_0's binary_logloss: 0.499931\n",
      "[119]\tvalid_0's l2: 0.16178\tvalid_0's binary_logloss: 0.499744\n",
      "[120]\tvalid_0's l2: 0.16174\tvalid_0's binary_logloss: 0.499632\n",
      "[121]\tvalid_0's l2: 0.161754\tvalid_0's binary_logloss: 0.499653\n",
      "[122]\tvalid_0's l2: 0.161755\tvalid_0's binary_logloss: 0.499634\n",
      "[123]\tvalid_0's l2: 0.161674\tvalid_0's binary_logloss: 0.499413\n",
      "[124]\tvalid_0's l2: 0.161765\tvalid_0's binary_logloss: 0.499648\n",
      "[125]\tvalid_0's l2: 0.161666\tvalid_0's binary_logloss: 0.499438\n",
      "[126]\tvalid_0's l2: 0.16153\tvalid_0's binary_logloss: 0.499079\n",
      "[127]\tvalid_0's l2: 0.161466\tvalid_0's binary_logloss: 0.498891\n",
      "[128]\tvalid_0's l2: 0.161385\tvalid_0's binary_logloss: 0.498697\n",
      "[129]\tvalid_0's l2: 0.161367\tvalid_0's binary_logloss: 0.498628\n",
      "[130]\tvalid_0's l2: 0.16133\tvalid_0's binary_logloss: 0.498523\n",
      "[131]\tvalid_0's l2: 0.161354\tvalid_0's binary_logloss: 0.498571\n",
      "[132]\tvalid_0's l2: 0.161375\tvalid_0's binary_logloss: 0.498639\n",
      "[133]\tvalid_0's l2: 0.161399\tvalid_0's binary_logloss: 0.49869\n",
      "[134]\tvalid_0's l2: 0.161336\tvalid_0's binary_logloss: 0.498515\n",
      "[135]\tvalid_0's l2: 0.161338\tvalid_0's binary_logloss: 0.498501\n",
      "[136]\tvalid_0's l2: 0.161299\tvalid_0's binary_logloss: 0.498415\n",
      "[137]\tvalid_0's l2: 0.16139\tvalid_0's binary_logloss: 0.498647\n",
      "[138]\tvalid_0's l2: 0.161314\tvalid_0's binary_logloss: 0.498439\n",
      "[139]\tvalid_0's l2: 0.161219\tvalid_0's binary_logloss: 0.49824\n",
      "[140]\tvalid_0's l2: 0.161159\tvalid_0's binary_logloss: 0.498062\n",
      "[141]\tvalid_0's l2: 0.16114\tvalid_0's binary_logloss: 0.498028\n",
      "[142]\tvalid_0's l2: 0.161102\tvalid_0's binary_logloss: 0.497913\n",
      "[143]\tvalid_0's l2: 0.161067\tvalid_0's binary_logloss: 0.497817\n",
      "[144]\tvalid_0's l2: 0.161049\tvalid_0's binary_logloss: 0.497782\n",
      "[145]\tvalid_0's l2: 0.161071\tvalid_0's binary_logloss: 0.497851\n",
      "[146]\tvalid_0's l2: 0.160944\tvalid_0's binary_logloss: 0.497513\n",
      "[147]\tvalid_0's l2: 0.161034\tvalid_0's binary_logloss: 0.497743\n",
      "[148]\tvalid_0's l2: 0.161043\tvalid_0's binary_logloss: 0.497771\n",
      "[149]\tvalid_0's l2: 0.160968\tvalid_0's binary_logloss: 0.497591\n",
      "[150]\tvalid_0's l2: 0.160918\tvalid_0's binary_logloss: 0.497451\n",
      "[151]\tvalid_0's l2: 0.160976\tvalid_0's binary_logloss: 0.497619\n",
      "[152]\tvalid_0's l2: 0.160972\tvalid_0's binary_logloss: 0.497593\n",
      "[153]\tvalid_0's l2: 0.160975\tvalid_0's binary_logloss: 0.49758\n",
      "[154]\tvalid_0's l2: 0.160918\tvalid_0's binary_logloss: 0.497409\n",
      "[155]\tvalid_0's l2: 0.160941\tvalid_0's binary_logloss: 0.497481\n",
      "[156]\tvalid_0's l2: 0.160882\tvalid_0's binary_logloss: 0.497319\n",
      "[157]\tvalid_0's l2: 0.160866\tvalid_0's binary_logloss: 0.49729\n",
      "[158]\tvalid_0's l2: 0.160774\tvalid_0's binary_logloss: 0.497102\n",
      "[159]\tvalid_0's l2: 0.160798\tvalid_0's binary_logloss: 0.497152\n",
      "[160]\tvalid_0's l2: 0.160729\tvalid_0's binary_logloss: 0.496958\n",
      "[161]\tvalid_0's l2: 0.160712\tvalid_0's binary_logloss: 0.49693\n",
      "[162]\tvalid_0's l2: 0.160747\tvalid_0's binary_logloss: 0.497012\n",
      "[163]\tvalid_0's l2: 0.160715\tvalid_0's binary_logloss: 0.496924\n",
      "[164]\tvalid_0's l2: 0.160728\tvalid_0's binary_logloss: 0.496958\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[161]\tvalid_0's l2: 0.160712\tvalid_0's binary_logloss: 0.49693\n",
      "---- Train error ----\n",
      "0.16273395200618593\n",
      "---- CV error ----\n",
      "0.16071176629842998\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.005094507079100641\n",
      "mse = 0.19940966236005536\n",
      "0:02:59.562216\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "-------------  dart  --------------\n",
      "\n",
      "\n",
      "gpa\n",
      "gpa\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.76899524 -9.76722571 -9.17649742 -9.04798613 -0.73552262 -9.42597921]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-6.487   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-8.65802164 -8.81092192 -8.38006231 -8.46565255 -0.41945257 -8.6477768 ]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.23    \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[ -8.09607736 -10.50469223  -3.36748686  -9.18526941  -3.71007007\n",
      "  -2.06679856]\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-6.155   \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "[ -8.47788363  -3.68227671 -10.06833661  -8.29059137  -1.47154081\n",
      " -10.29212394]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-7.047   \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-12.57617509 -10.45428655 -10.02324915 -10.14850704 -13.81011993\n",
      " -10.23141091]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-11.21   \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-1.96643605 -1.97791611 -1.84744648 -1.82640548 -2.02480113 -1.94426214]\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.931   \u001b[0m | \u001b[95m 0.7442  \u001b[0m | \u001b[95m 0.01505 \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 68.61   \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 160.3   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.1119  \u001b[0m | \u001b[95m 0.7041  \u001b[0m |\n",
      "[-7.68892516 -9.03834484 -8.6083093  -8.69337545 -7.7807494  -8.88021053]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-8.448   \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.04858 \u001b[0m | \u001b[0m 9.909   \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 19.13   \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 0.9892  \u001b[0m |\n",
      "[-1.6516833  -1.65574788 -1.581527   -1.54992484 -1.69217603 -1.66498192]\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-1.633   \u001b[0m | \u001b[95m 0.7016  \u001b[0m | \u001b[95m 0.0116  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 859.6   \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 0.2637  \u001b[0m | \u001b[95m 0.8152  \u001b[0m | \u001b[95m 0.8523  \u001b[0m |\n",
      "[-31.82007185 -32.3729508  -32.40014462 -32.04189371 -32.03610538\n",
      " -32.73738133]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-32.23   \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "[-0.6727861  -0.67192974 -0.60930989 -0.5932721  -0.69670918 -0.672904  ]\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.6528  \u001b[0m | \u001b[95m 0.9133  \u001b[0m | \u001b[95m 0.04154 \u001b[0m | \u001b[95m 12.2    \u001b[0m | \u001b[95m 152.8   \u001b[0m | \u001b[95m 859.9   \u001b[0m | \u001b[95m 88.78   \u001b[0m | \u001b[95m 19.04   \u001b[0m | \u001b[95m 0.267   \u001b[0m | \u001b[95m 0.7124  \u001b[0m | \u001b[95m 0.7969  \u001b[0m |\n",
      "[-1.79626064 -7.72315266 -8.24440935 -8.81229422 -1.03096046 -9.03659159]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-6.107   \u001b[0m | \u001b[0m 0.5927  \u001b[0m | \u001b[0m 0.1494  \u001b[0m | \u001b[0m 7.078   \u001b[0m | \u001b[0m 70.49   \u001b[0m | \u001b[0m 440.7   \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 13.91   \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 0.6571  \u001b[0m |\n",
      "[-2.36973685 -2.36717742 -2.22194717 -2.2132181  -2.41684077 -2.34822584]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.323   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 9.138   \u001b[0m | \u001b[0m 52.9    \u001b[0m | \u001b[0m 445.9   \u001b[0m | \u001b[0m 161.9   \u001b[0m | \u001b[0m 16.89   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "[-8.80485083 -1.09417666 -1.30866469 -7.84060485 -9.70992049 -1.12425703]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.98    \u001b[0m | \u001b[0m 0.8255  \u001b[0m | \u001b[0m 0.161   \u001b[0m | \u001b[0m 7.67    \u001b[0m | \u001b[0m 57.05   \u001b[0m | \u001b[0m 439.0   \u001b[0m | \u001b[0m 163.1   \u001b[0m | \u001b[0m 17.11   \u001b[0m | \u001b[0m 0.231   \u001b[0m | \u001b[0m 0.3744  \u001b[0m | \u001b[0m 0.9254  \u001b[0m |\n",
      "[-2.36475001 -2.36506048 -2.21696547 -2.21143337 -2.41834123 -2.3439231 ]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.32    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 13.16   \u001b[0m | \u001b[0m 62.64   \u001b[0m | \u001b[0m 458.3   \u001b[0m | \u001b[0m 157.7   \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "[ -0.48602793  -2.85379564 -10.23304701 -17.68423664  -9.10424869\n",
      "  -9.21234792]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-8.262   \u001b[0m | \u001b[0m 0.8992  \u001b[0m | \u001b[0m 0.1456  \u001b[0m | \u001b[0m 4.572   \u001b[0m | \u001b[0m 52.42   \u001b[0m | \u001b[0m 435.2   \u001b[0m | \u001b[0m 162.5   \u001b[0m | \u001b[0m 21.93   \u001b[0m | \u001b[0m 0.9546  \u001b[0m | \u001b[0m 0.388   \u001b[0m | \u001b[0m 0.9976  \u001b[0m |\n",
      "[ -9.02333065 -10.26279657  -8.44059944  -9.92263902  -8.94201133\n",
      " -10.1976634 ]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-9.465   \u001b[0m | \u001b[0m 0.9563  \u001b[0m | \u001b[0m 0.0961  \u001b[0m | \u001b[0m 4.732   \u001b[0m | \u001b[0m 148.8   \u001b[0m | \u001b[0m 875.7   \u001b[0m | \u001b[0m 91.12   \u001b[0m | \u001b[0m 18.43   \u001b[0m | \u001b[0m 0.09408 \u001b[0m | \u001b[0m 0.892   \u001b[0m | \u001b[0m 0.8534  \u001b[0m |\n",
      "[ -0.63111303  -0.62869371 -12.80501532 -12.88428829  -0.64729094\n",
      " -12.04306255]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-6.607   \u001b[0m | \u001b[0m 0.5643  \u001b[0m | \u001b[0m 0.04727 \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 169.2   \u001b[0m | \u001b[0m 847.4   \u001b[0m | \u001b[0m 90.42   \u001b[0m | \u001b[0m 9.348   \u001b[0m | \u001b[0m 0.1102  \u001b[0m | \u001b[0m 0.9997  \u001b[0m | \u001b[0m 0.7495  \u001b[0m |\n",
      "[-0.43498603 -0.44149722 -0.36964322 -0.38734166 -0.43924673 -0.43607217]\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-0.4181  \u001b[0m | \u001b[95m 0.9706  \u001b[0m | \u001b[95m 0.1049  \u001b[0m | \u001b[95m 8.144   \u001b[0m | \u001b[95m 52.08   \u001b[0m | \u001b[95m 438.1   \u001b[0m | \u001b[95m 167.8   \u001b[0m | \u001b[95m 10.91   \u001b[0m | \u001b[95m 0.06854 \u001b[0m | \u001b[95m 0.02798 \u001b[0m | \u001b[95m 0.6646  \u001b[0m |\n",
      "[-32.62183181 -28.76237374 -28.53115407 -28.53516873 -22.82543557\n",
      " -28.78108029]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-28.34   \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "[-2.31203547 -2.32109727 -2.20653016 -2.18626953 -2.35698906 -2.30988543]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.282   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 6.8     \u001b[0m | \u001b[0m 57.82   \u001b[0m | \u001b[0m 450.6   \u001b[0m | \u001b[0m 173.6   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.41813117148728995, 'params': {'colsample_bytree': 0.97060091756119, 'learning_rate': 0.10487817351631633, 'max_depth': 8.143599040830644, 'min_child_samples': 52.07932431794734, 'n_estimators': 438.0561774170633, 'num_iteration': 167.82041608186472, 'num_leaves': 10.914206072965271, 'reg_alpha': 0.06854401658720022, 'reg_lambda': 0.027978686900804073, 'subsample': 0.6645741339356268}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=167, num_iteration=167 will be ignored. Current value: num_iterations=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.418101\n",
      "[2]\tvalid_0's l2: 0.414116\n",
      "[3]\tvalid_0's l2: 0.40995\n",
      "[4]\tvalid_0's l2: 0.404993\n",
      "[5]\tvalid_0's l2: 0.399755\n",
      "[6]\tvalid_0's l2: 0.394798\n",
      "[7]\tvalid_0's l2: 0.390779\n",
      "[8]\tvalid_0's l2: 0.390341\n",
      "[9]\tvalid_0's l2: 0.387415\n",
      "[10]\tvalid_0's l2: 0.382706\n",
      "[11]\tvalid_0's l2: 0.380839\n",
      "[12]\tvalid_0's l2: 0.380473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[13]\tvalid_0's l2: 0.376991\n",
      "[14]\tvalid_0's l2: 0.37408\n",
      "[15]\tvalid_0's l2: 0.369769\n",
      "[16]\tvalid_0's l2: 0.371793\n",
      "[17]\tvalid_0's l2: 0.369702\n",
      "[18]\tvalid_0's l2: 0.368341\n",
      "[19]\tvalid_0's l2: 0.366568\n",
      "[20]\tvalid_0's l2: 0.367192\n",
      "[21]\tvalid_0's l2: 0.367891\n",
      "[22]\tvalid_0's l2: 0.368268\n",
      "[23]\tvalid_0's l2: 0.369464\n",
      "[24]\tvalid_0's l2: 0.371125\n",
      "[25]\tvalid_0's l2: 0.369767\n",
      "[26]\tvalid_0's l2: 0.36766\n",
      "[27]\tvalid_0's l2: 0.36707\n",
      "[28]\tvalid_0's l2: 0.367263\n",
      "[29]\tvalid_0's l2: 0.368954\n",
      "[30]\tvalid_0's l2: 0.368406\n",
      "[31]\tvalid_0's l2: 0.366749\n",
      "[32]\tvalid_0's l2: 0.368569\n",
      "[33]\tvalid_0's l2: 0.36717\n",
      "[34]\tvalid_0's l2: 0.36793\n",
      "[35]\tvalid_0's l2: 0.36817\n",
      "[36]\tvalid_0's l2: 0.368407\n",
      "[37]\tvalid_0's l2: 0.366194\n",
      "[38]\tvalid_0's l2: 0.365776\n",
      "[39]\tvalid_0's l2: 0.366423\n",
      "[40]\tvalid_0's l2: 0.365907\n",
      "[41]\tvalid_0's l2: 0.365831\n",
      "[42]\tvalid_0's l2: 0.366135\n",
      "[43]\tvalid_0's l2: 0.366203\n",
      "[44]\tvalid_0's l2: 0.366587\n",
      "[45]\tvalid_0's l2: 0.367377\n",
      "[46]\tvalid_0's l2: 0.495288\n",
      "[47]\tvalid_0's l2: 0.472316\n",
      "[48]\tvalid_0's l2: 0.461484\n",
      "[49]\tvalid_0's l2: 0.457608\n",
      "[50]\tvalid_0's l2: 0.457666\n",
      "[51]\tvalid_0's l2: 0.443205\n",
      "[52]\tvalid_0's l2: 0.428309\n",
      "[53]\tvalid_0's l2: 0.430145\n",
      "[54]\tvalid_0's l2: 0.41663\n",
      "[55]\tvalid_0's l2: 0.407416\n",
      "[56]\tvalid_0's l2: 0.407705\n",
      "[57]\tvalid_0's l2: 0.402269\n",
      "[58]\tvalid_0's l2: 0.625005\n",
      "[59]\tvalid_0's l2: 0.620916\n",
      "[60]\tvalid_0's l2: 0.573718\n",
      "[61]\tvalid_0's l2: 0.893235\n",
      "[62]\tvalid_0's l2: 0.791963\n",
      "[63]\tvalid_0's l2: 0.7113\n",
      "[64]\tvalid_0's l2: 0.697293\n",
      "[65]\tvalid_0's l2: 0.700535\n",
      "[66]\tvalid_0's l2: 0.63955\n",
      "[67]\tvalid_0's l2: 0.585848\n",
      "[68]\tvalid_0's l2: 0.543538\n",
      "[69]\tvalid_0's l2: 0.543658\n",
      "[70]\tvalid_0's l2: 0.539766\n",
      "[71]\tvalid_0's l2: 0.5315\n",
      "[72]\tvalid_0's l2: 0.50165\n",
      "[73]\tvalid_0's l2: 0.47579\n",
      "[74]\tvalid_0's l2: 0.478171\n",
      "[75]\tvalid_0's l2: 0.456436\n",
      "[76]\tvalid_0's l2: 0.457779\n",
      "[77]\tvalid_0's l2: 0.459316\n",
      "[78]\tvalid_0's l2: 0.462286\n",
      "[79]\tvalid_0's l2: 0.445395\n",
      "[80]\tvalid_0's l2: 0.431113\n",
      "[81]\tvalid_0's l2: 0.436187\n",
      "[82]\tvalid_0's l2: 0.424597\n",
      "[83]\tvalid_0's l2: 0.428864\n",
      "[84]\tvalid_0's l2: 0.429641\n",
      "[85]\tvalid_0's l2: 0.434583\n",
      "[86]\tvalid_0's l2: 0.421624\n",
      "[87]\tvalid_0's l2: 0.412007\n",
      "[88]\tvalid_0's l2: 0.415188\n",
      "[89]\tvalid_0's l2: 0.41379\n",
      "[90]\tvalid_0's l2: 0.417582\n",
      "[91]\tvalid_0's l2: 0.584496\n",
      "[92]\tvalid_0's l2: 0.541508\n",
      "[93]\tvalid_0's l2: 0.511263\n",
      "[94]\tvalid_0's l2: 0.523753\n",
      "[95]\tvalid_0's l2: 0.525937\n",
      "[96]\tvalid_0's l2: 0.532041\n",
      "[97]\tvalid_0's l2: 0.502797\n",
      "[98]\tvalid_0's l2: 0.505964\n",
      "[99]\tvalid_0's l2: 0.479764\n",
      "[100]\tvalid_0's l2: 0.459647\n",
      "[101]\tvalid_0's l2: 0.539198\n",
      "[102]\tvalid_0's l2: 0.548662\n",
      "[103]\tvalid_0's l2: 0.558113\n",
      "[104]\tvalid_0's l2: 0.519639\n",
      "[105]\tvalid_0's l2: 0.606429\n",
      "[106]\tvalid_0's l2: 0.610127\n",
      "[107]\tvalid_0's l2: 0.621723\n",
      "[108]\tvalid_0's l2: 0.576791\n",
      "[109]\tvalid_0's l2: 0.583957\n",
      "[110]\tvalid_0's l2: 0.590234\n",
      "[111]\tvalid_0's l2: 0.547964\n",
      "[112]\tvalid_0's l2: 0.511119\n",
      "[113]\tvalid_0's l2: 0.483785\n",
      "[114]\tvalid_0's l2: 0.459822\n",
      "[115]\tvalid_0's l2: 0.441653\n",
      "[116]\tvalid_0's l2: 0.428489\n",
      "[117]\tvalid_0's l2: 0.433124\n",
      "[118]\tvalid_0's l2: 0.420574\n",
      "[119]\tvalid_0's l2: 0.424141\n",
      "[120]\tvalid_0's l2: 0.428735\n",
      "[121]\tvalid_0's l2: 0.434096\n",
      "[122]\tvalid_0's l2: 0.440813\n",
      "[123]\tvalid_0's l2: 0.427426\n",
      "[124]\tvalid_0's l2: 0.418206\n",
      "[125]\tvalid_0's l2: 0.422273\n",
      "[126]\tvalid_0's l2: 0.425903\n",
      "[127]\tvalid_0's l2: 0.41391\n",
      "[128]\tvalid_0's l2: 0.419456\n",
      "[129]\tvalid_0's l2: 0.410297\n",
      "[130]\tvalid_0's l2: 0.401251\n",
      "[131]\tvalid_0's l2: 0.407223\n",
      "[132]\tvalid_0's l2: 0.400979\n",
      "[133]\tvalid_0's l2: 0.393659\n",
      "[134]\tvalid_0's l2: 0.434237\n",
      "[135]\tvalid_0's l2: 0.421386\n",
      "[136]\tvalid_0's l2: 0.488855\n",
      "[137]\tvalid_0's l2: 0.495909\n",
      "[138]\tvalid_0's l2: 0.471386\n",
      "[139]\tvalid_0's l2: 0.45344\n",
      "[140]\tvalid_0's l2: 0.461493\n",
      "[141]\tvalid_0's l2: 0.467442\n",
      "[142]\tvalid_0's l2: 0.474337\n",
      "[143]\tvalid_0's l2: 0.45387\n",
      "[144]\tvalid_0's l2: 0.458757\n",
      "[145]\tvalid_0's l2: 0.442125\n",
      "[146]\tvalid_0's l2: 0.449881\n",
      "[147]\tvalid_0's l2: 0.458508\n",
      "[148]\tvalid_0's l2: 0.46507\n",
      "[149]\tvalid_0's l2: 0.448192\n",
      "[150]\tvalid_0's l2: 0.43366\n",
      "[151]\tvalid_0's l2: 0.468788\n",
      "[152]\tvalid_0's l2: 0.513891\n",
      "[153]\tvalid_0's l2: 0.488266\n",
      "[154]\tvalid_0's l2: 0.494184\n",
      "[155]\tvalid_0's l2: 0.471732\n",
      "[156]\tvalid_0's l2: 0.48127\n",
      "[157]\tvalid_0's l2: 0.486389\n",
      "[158]\tvalid_0's l2: 0.495283\n",
      "[159]\tvalid_0's l2: 0.504308\n",
      "[160]\tvalid_0's l2: 0.511907\n",
      "[161]\tvalid_0's l2: 0.486486\n",
      "[162]\tvalid_0's l2: 0.490645\n",
      "[163]\tvalid_0's l2: 0.465733\n",
      "[164]\tvalid_0's l2: 0.449286\n",
      "[165]\tvalid_0's l2: 0.43449\n",
      "[166]\tvalid_0's l2: 0.423249\n",
      "[167]\tvalid_0's l2: 0.411519\n",
      "[1]\tvalid_0's l2: 0.418101\n",
      "[2]\tvalid_0's l2: 0.414116\n",
      "[3]\tvalid_0's l2: 0.40995\n",
      "[4]\tvalid_0's l2: 0.404993\n",
      "[5]\tvalid_0's l2: 0.399755\n",
      "[6]\tvalid_0's l2: 0.394798\n",
      "[7]\tvalid_0's l2: 0.390779\n",
      "[8]\tvalid_0's l2: 0.390341\n",
      "[9]\tvalid_0's l2: 0.387415\n",
      "[10]\tvalid_0's l2: 0.382706\n",
      "[11]\tvalid_0's l2: 0.380839\n",
      "[12]\tvalid_0's l2: 0.380473\n",
      "[13]\tvalid_0's l2: 0.376991\n",
      "[14]\tvalid_0's l2: 0.37408\n",
      "[15]\tvalid_0's l2: 0.369769\n",
      "[16]\tvalid_0's l2: 0.371793\n",
      "[17]\tvalid_0's l2: 0.369702\n",
      "[18]\tvalid_0's l2: 0.368341\n",
      "[19]\tvalid_0's l2: 0.366568\n",
      "[20]\tvalid_0's l2: 0.367192\n",
      "[21]\tvalid_0's l2: 0.367891\n",
      "[22]\tvalid_0's l2: 0.368268\n",
      "[23]\tvalid_0's l2: 0.369464\n",
      "[24]\tvalid_0's l2: 0.371125\n",
      "[25]\tvalid_0's l2: 0.369767\n",
      "[26]\tvalid_0's l2: 0.36766\n",
      "[27]\tvalid_0's l2: 0.36707\n",
      "[28]\tvalid_0's l2: 0.367263\n",
      "[29]\tvalid_0's l2: 0.368954\n",
      "[30]\tvalid_0's l2: 0.368406\n",
      "[31]\tvalid_0's l2: 0.366749\n",
      "[32]\tvalid_0's l2: 0.368569\n",
      "[33]\tvalid_0's l2: 0.36717\n",
      "[34]\tvalid_0's l2: 0.36793\n",
      "[35]\tvalid_0's l2: 0.36817\n",
      "[36]\tvalid_0's l2: 0.368407\n",
      "[37]\tvalid_0's l2: 0.366194\n",
      "[38]\tvalid_0's l2: 0.365776\n",
      "---- Train error ----\n",
      "0.18800885507934922\n",
      "---- CV error ----\n",
      "0.3657758313736292\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.02399057020585016\n",
      "mse = 0.38124499706416043\n",
      "grit\n",
      "grit\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-14.13404858 -16.56085408 -13.61935051 -14.06955355 -13.83189406\n",
      " -15.87237345]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-14.68   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-12.50082799 -12.55566203 -12.42316196 -12.61230924 -20.82380154\n",
      "  -3.26833476]\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-12.36   \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "[-13.99423143  -2.22603474 -22.43897353 -13.00311774 -22.56754554\n",
      "  -3.097743  ]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-12.89   \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-13.26459853  -1.74731154 -12.90457162  -1.54626642 -13.06805933\n",
      " -23.77852665]\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-11.05   \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "[-26.09814052 -26.27311485 -25.58903895 -26.08262767 -25.82164909\n",
      " -26.04125774]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-25.98   \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-16.32799593 -16.41392149 -15.6030641  -15.13028367 -14.85004915\n",
      " -16.29382127]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-15.77   \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "[-22.87188079  -1.94354092 -22.42307145 -24.385302   -22.53734534\n",
      " -16.42785072]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-18.43   \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 33.22   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 25.95   \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.8471  \u001b[0m |\n",
      "[-22.02088759 -22.04748752 -24.08129291 -24.52658691 -24.23013502\n",
      " -22.08828284]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-23.17   \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "[-47.22437224 -47.27483603 -46.79225941 -47.24859118 -47.01824898\n",
      " -47.10282197]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-47.11   \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "[-16.03871201 -12.50691061 -13.32637515  -2.61267938 -14.41418115\n",
      " -16.07868713]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-12.5    \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 47.61   \u001b[0m | \u001b[0m 568.1   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.6486  \u001b[0m |\n",
      "[-12.37571577 -12.43999352 -12.21990074 -12.04532036 -12.59314224\n",
      " -12.3909491 ]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-12.34   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 14.87   \u001b[0m | \u001b[0m 280.8   \u001b[0m | \u001b[0m 152.7   \u001b[0m | \u001b[0m 18.43   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9467  \u001b[0m |\n",
      "[ -1.96910317 -13.33946417 -14.56542677 -13.72963132 -13.55116429\n",
      " -13.91253657]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-11.84   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 526.6   \u001b[0m | \u001b[0m 120.3   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9194  \u001b[0m |\n",
      "[ -4.92622054 -12.22570362 -12.39708346 -13.36639744  -4.44596283\n",
      " -21.71705725]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-11.51   \u001b[0m | \u001b[0m 0.561   \u001b[0m | \u001b[0m 0.1179  \u001b[0m | \u001b[0m 4.555   \u001b[0m | \u001b[0m 25.01   \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 0.01987 \u001b[0m | \u001b[0m 0.9257  \u001b[0m | \u001b[0m 0.8376  \u001b[0m |\n",
      "[-12.69657699 -17.33559115 -12.05417127 -12.49581576  -5.69793436\n",
      " -12.56876993]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-12.14   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 11.07   \u001b[0m | \u001b[0m 544.9   \u001b[0m | \u001b[0m 162.4   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "[-13.50170325 -16.91033515 -14.49633941 -14.20883842 -14.71653496\n",
      " -14.23129459]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-14.68   \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.03905 \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 47.2    \u001b[0m | \u001b[0m 565.5   \u001b[0m | \u001b[0m 140.1   \u001b[0m | \u001b[0m 17.04   \u001b[0m | \u001b[0m 0.5629  \u001b[0m | \u001b[0m 0.3078  \u001b[0m | \u001b[0m 0.9589  \u001b[0m |\n",
      "[-15.84999576 -20.54969839 -23.0672595  -15.84263156 -20.22919731\n",
      " -24.72679635]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-20.04   \u001b[0m | \u001b[0m 0.5064  \u001b[0m | \u001b[0m 0.1625  \u001b[0m | \u001b[0m 2.255   \u001b[0m | \u001b[0m 15.71   \u001b[0m | \u001b[0m 296.1   \u001b[0m | \u001b[0m 115.8   \u001b[0m | \u001b[0m 4.546   \u001b[0m | \u001b[0m 0.9448  \u001b[0m | \u001b[0m 0.5113  \u001b[0m | \u001b[0m 0.9563  \u001b[0m |\n",
      "[-15.32887327 -12.19379234 -11.74908108 -12.22304456 -11.91473221\n",
      " -12.27480263]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-12.61   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.99   \u001b[0m | \u001b[0m 302.1   \u001b[0m | \u001b[0m 183.0   \u001b[0m | \u001b[0m 7.564   \u001b[0m | \u001b[0m 0.05522 \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "[-26.14318731 -26.13795092 -25.64018606 -26.05660822 -25.83832322\n",
      " -26.04840111]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-25.98   \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "[ -2.32752565  -2.09762482 -12.08239825 -12.61151661 -13.14410897\n",
      " -12.35676597]\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-9.103   \u001b[0m | \u001b[95m 0.8542  \u001b[0m | \u001b[95m 0.133   \u001b[0m | \u001b[95m 8.224   \u001b[0m | \u001b[95m 71.92   \u001b[0m | \u001b[95m 447.5   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 27.69   \u001b[0m | \u001b[95m 0.8175  \u001b[0m | \u001b[95m 0.1869  \u001b[0m | \u001b[95m 0.8824  \u001b[0m |\n",
      "[-13.33133205 -13.50642872 -15.7257885  -15.24692159 -14.5992163\n",
      " -15.57626677]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-14.66   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0495  \u001b[0m | \u001b[0m 12.6    \u001b[0m | \u001b[0m 72.57   \u001b[0m | \u001b[0m 461.9   \u001b[0m | \u001b[0m 159.8   \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -9.10332338071524, 'params': {'colsample_bytree': 0.8541944792204825, 'learning_rate': 0.13299856596151294, 'max_depth': 8.224066390159873, 'min_child_samples': 71.92478893371324, 'n_estimators': 447.5299800650481, 'num_iteration': 159.48664612961014, 'num_leaves': 27.691834855069953, 'reg_alpha': 0.817468937666704, 'reg_lambda': 0.18694027186242523, 'subsample': 0.8824461595422382}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=159, num_iteration=159 will be ignored. Current value: num_iterations=159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.212731\n",
      "[2]\tvalid_0's l2: 0.212485\n",
      "[3]\tvalid_0's l2: 0.212565\n",
      "[4]\tvalid_0's l2: 0.211471\n",
      "[5]\tvalid_0's l2: 0.213369\n",
      "[6]\tvalid_0's l2: 0.212103\n",
      "[7]\tvalid_0's l2: 0.212785\n",
      "[8]\tvalid_0's l2: 0.212637\n",
      "[9]\tvalid_0's l2: 0.212846\n",
      "[10]\tvalid_0's l2: 0.213935\n",
      "[11]\tvalid_0's l2: 0.213454\n",
      "[12]\tvalid_0's l2: 0.21273\n",
      "[13]\tvalid_0's l2: 0.212427\n",
      "[14]\tvalid_0's l2: 0.211444\n",
      "[15]\tvalid_0's l2: 0.211957\n",
      "[16]\tvalid_0's l2: 0.212131\n",
      "[17]\tvalid_0's l2: 0.212077\n",
      "[18]\tvalid_0's l2: 0.21124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[19]\tvalid_0's l2: 0.211059\n",
      "[20]\tvalid_0's l2: 0.212463\n",
      "[21]\tvalid_0's l2: 0.210828\n",
      "[22]\tvalid_0's l2: 0.211118\n",
      "[23]\tvalid_0's l2: 0.210512\n",
      "[24]\tvalid_0's l2: 0.211044\n",
      "[25]\tvalid_0's l2: 0.210672\n",
      "[26]\tvalid_0's l2: 0.210274\n",
      "[27]\tvalid_0's l2: 0.209855\n",
      "[28]\tvalid_0's l2: 0.209694\n",
      "[29]\tvalid_0's l2: 0.21023\n",
      "[30]\tvalid_0's l2: 0.210277\n",
      "[31]\tvalid_0's l2: 0.210185\n",
      "[32]\tvalid_0's l2: 0.210823\n",
      "[33]\tvalid_0's l2: 0.211344\n",
      "[34]\tvalid_0's l2: 0.210445\n",
      "[35]\tvalid_0's l2: 0.210267\n",
      "[36]\tvalid_0's l2: 0.210307\n",
      "[37]\tvalid_0's l2: 0.211138\n",
      "[38]\tvalid_0's l2: 0.210605\n",
      "[39]\tvalid_0's l2: 0.211026\n",
      "[40]\tvalid_0's l2: 0.21081\n",
      "[41]\tvalid_0's l2: 0.210646\n",
      "[42]\tvalid_0's l2: 0.210696\n",
      "[43]\tvalid_0's l2: 0.210445\n",
      "[44]\tvalid_0's l2: 0.209909\n",
      "[45]\tvalid_0's l2: 0.211059\n",
      "[46]\tvalid_0's l2: 0.211059\n",
      "[47]\tvalid_0's l2: 0.211059\n",
      "[48]\tvalid_0's l2: 0.211059\n",
      "[49]\tvalid_0's l2: 0.211059\n",
      "[50]\tvalid_0's l2: 0.211059\n",
      "[51]\tvalid_0's l2: 0.211059\n",
      "[52]\tvalid_0's l2: 0.211059\n",
      "[53]\tvalid_0's l2: 0.211059\n",
      "[54]\tvalid_0's l2: 0.211059\n",
      "[55]\tvalid_0's l2: 0.211059\n",
      "[56]\tvalid_0's l2: 0.211059\n",
      "[57]\tvalid_0's l2: 0.211059\n",
      "[58]\tvalid_0's l2: 0.211059\n",
      "[59]\tvalid_0's l2: 0.211059\n",
      "[60]\tvalid_0's l2: 0.445424\n",
      "[61]\tvalid_0's l2: 0.445424\n",
      "[62]\tvalid_0's l2: 0.445424\n",
      "[63]\tvalid_0's l2: 0.445424\n",
      "[64]\tvalid_0's l2: 1.69617\n",
      "[65]\tvalid_0's l2: 1.69617\n",
      "[66]\tvalid_0's l2: 1.69617\n",
      "[67]\tvalid_0's l2: 1.69617\n",
      "[68]\tvalid_0's l2: 1.69617\n",
      "[69]\tvalid_0's l2: 1.69617\n",
      "[70]\tvalid_0's l2: 1.69617\n",
      "[71]\tvalid_0's l2: 1.69617\n",
      "[72]\tvalid_0's l2: 1.69617\n",
      "[73]\tvalid_0's l2: 1.69617\n",
      "[74]\tvalid_0's l2: 1.69617\n",
      "[75]\tvalid_0's l2: 1.69617\n",
      "[76]\tvalid_0's l2: 3.34159\n",
      "[77]\tvalid_0's l2: 3.34159\n",
      "[78]\tvalid_0's l2: 3.34159\n",
      "[79]\tvalid_0's l2: 3.34159\n",
      "[80]\tvalid_0's l2: 3.34159\n",
      "[81]\tvalid_0's l2: 3.34159\n",
      "[82]\tvalid_0's l2: 3.34159\n",
      "[83]\tvalid_0's l2: 3.34159\n",
      "[84]\tvalid_0's l2: 3.34159\n",
      "[85]\tvalid_0's l2: 3.34159\n",
      "[86]\tvalid_0's l2: 3.34159\n",
      "[87]\tvalid_0's l2: 3.34159\n",
      "[88]\tvalid_0's l2: 3.34159\n",
      "[89]\tvalid_0's l2: 3.34159\n",
      "[90]\tvalid_0's l2: 3.34159\n",
      "[91]\tvalid_0's l2: 3.34159\n",
      "[92]\tvalid_0's l2: 3.34159\n",
      "[93]\tvalid_0's l2: 3.34159\n",
      "[94]\tvalid_0's l2: 3.34159\n",
      "[95]\tvalid_0's l2: 3.34159\n",
      "[96]\tvalid_0's l2: 3.34159\n",
      "[97]\tvalid_0's l2: 3.34159\n",
      "[98]\tvalid_0's l2: 3.34159\n",
      "[99]\tvalid_0's l2: 3.34159\n",
      "[100]\tvalid_0's l2: 3.34159\n",
      "[101]\tvalid_0's l2: 3.34159\n",
      "[102]\tvalid_0's l2: 3.34159\n",
      "[103]\tvalid_0's l2: 3.34159\n",
      "[104]\tvalid_0's l2: 3.34159\n",
      "[105]\tvalid_0's l2: 3.34159\n",
      "[106]\tvalid_0's l2: 3.34159\n",
      "[107]\tvalid_0's l2: 4.62148\n",
      "[108]\tvalid_0's l2: 4.62148\n",
      "[109]\tvalid_0's l2: 4.7694\n",
      "[110]\tvalid_0's l2: 5.52856\n",
      "[111]\tvalid_0's l2: 6.23613\n",
      "[112]\tvalid_0's l2: 6.39504\n",
      "[113]\tvalid_0's l2: 7.02705\n",
      "[114]\tvalid_0's l2: 7.59932\n",
      "[115]\tvalid_0's l2: 7.55816\n",
      "[116]\tvalid_0's l2: 8.08141\n",
      "[117]\tvalid_0's l2: 8.08369\n",
      "[118]\tvalid_0's l2: 8.84936\n",
      "[119]\tvalid_0's l2: 9.23286\n",
      "[120]\tvalid_0's l2: 9.12575\n",
      "[121]\tvalid_0's l2: 9.46534\n",
      "[122]\tvalid_0's l2: 9.77339\n",
      "[123]\tvalid_0's l2: 10.058\n",
      "[124]\tvalid_0's l2: 10.2947\n",
      "[125]\tvalid_0's l2: 10.5029\n",
      "[126]\tvalid_0's l2: 10.6859\n",
      "[127]\tvalid_0's l2: 10.8466\n",
      "[128]\tvalid_0's l2: 10.6172\n",
      "[129]\tvalid_0's l2: 10.4176\n",
      "[130]\tvalid_0's l2: 10.6285\n",
      "[131]\tvalid_0's l2: 10.8127\n",
      "[132]\tvalid_0's l2: 10.9703\n",
      "[133]\tvalid_0's l2: 11.1087\n",
      "[134]\tvalid_0's l2: 11.2223\n",
      "[135]\tvalid_0's l2: 11.3188\n",
      "[136]\tvalid_0's l2: 11.414\n",
      "[137]\tvalid_0's l2: 11.4927\n",
      "[138]\tvalid_0's l2: 11.3843\n",
      "[139]\tvalid_0's l2: 11.4542\n",
      "[140]\tvalid_0's l2: 11.3018\n",
      "[141]\tvalid_0's l2: 11.279\n",
      "[142]\tvalid_0's l2: 11.3668\n",
      "[143]\tvalid_0's l2: 11.3392\n",
      "[144]\tvalid_0's l2: 11.4261\n",
      "[145]\tvalid_0's l2: 11.2757\n",
      "[146]\tvalid_0's l2: 11.367\n",
      "[147]\tvalid_0's l2: 11.4422\n",
      "[148]\tvalid_0's l2: 11.4023\n",
      "[149]\tvalid_0's l2: 11.3473\n",
      "[150]\tvalid_0's l2: 11.4278\n",
      "[151]\tvalid_0's l2: 11.4955\n",
      "[152]\tvalid_0's l2: 11.5562\n",
      "[153]\tvalid_0's l2: 11.4885\n",
      "[154]\tvalid_0's l2: 11.5537\n",
      "[155]\tvalid_0's l2: 11.6091\n",
      "[156]\tvalid_0's l2: 11.6624\n",
      "[157]\tvalid_0's l2: 11.5984\n",
      "[158]\tvalid_0's l2: 11.6555\n",
      "[159]\tvalid_0's l2: 11.6057\n",
      "[1]\tvalid_0's l2: 0.212731\n",
      "[2]\tvalid_0's l2: 0.212485\n",
      "[3]\tvalid_0's l2: 0.212565\n",
      "[4]\tvalid_0's l2: 0.211471\n",
      "[5]\tvalid_0's l2: 0.213369\n",
      "[6]\tvalid_0's l2: 0.212103\n",
      "[7]\tvalid_0's l2: 0.212785\n",
      "[8]\tvalid_0's l2: 0.212637\n",
      "[9]\tvalid_0's l2: 0.212846\n",
      "[10]\tvalid_0's l2: 0.213935\n",
      "[11]\tvalid_0's l2: 0.213454\n",
      "[12]\tvalid_0's l2: 0.21273\n",
      "[13]\tvalid_0's l2: 0.212427\n",
      "[14]\tvalid_0's l2: 0.211444\n",
      "[15]\tvalid_0's l2: 0.211957\n",
      "[16]\tvalid_0's l2: 0.212131\n",
      "[17]\tvalid_0's l2: 0.212077\n",
      "[18]\tvalid_0's l2: 0.21124\n",
      "[19]\tvalid_0's l2: 0.211059\n",
      "[20]\tvalid_0's l2: 0.212463\n",
      "[21]\tvalid_0's l2: 0.210828\n",
      "[22]\tvalid_0's l2: 0.211118\n",
      "[23]\tvalid_0's l2: 0.210512\n",
      "[24]\tvalid_0's l2: 0.211044\n",
      "[25]\tvalid_0's l2: 0.210672\n",
      "[26]\tvalid_0's l2: 0.210274\n",
      "[27]\tvalid_0's l2: 0.209855\n",
      "[28]\tvalid_0's l2: 0.209694\n",
      "---- Train error ----\n",
      "0.13070520828143667\n",
      "---- CV error ----\n",
      "0.20969418000825374\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.012899529866976067\n",
      "mse = 0.2169031608664567\n",
      "materialHardship\n",
      "materialHardship\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.0225577  -0.01856147 -0.02273912 -0.02147822 -0.02402637 -0.02016025]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.02159 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.02215419 -0.01905024 -0.02297011 -0.02147073 -0.02299809 -0.01979593]\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.02141 \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "[-0.02292451 -0.01876559 -0.02295871 -0.02255283 -0.02286797 -0.01999628]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.02168 \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.0219806  -0.01957861 -0.02274806 -0.02203683 -0.02306797 -0.01989032]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.02155 \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.02165167 -0.01963313 -0.02303745 -0.02125243 -0.02345473 -0.01982593]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.02148 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.02180761 -0.01966844 -0.02290075 -0.02183175 -0.02308887 -0.01998901]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.02155 \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "[-0.02261522 -0.01830922 -0.02304377 -0.02042441 -0.02325164 -0.02040191]\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.02134 \u001b[0m | \u001b[95m 0.8387  \u001b[0m | \u001b[95m 0.1723  \u001b[0m | \u001b[95m 7.045   \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 94.36   \u001b[0m | \u001b[95m 53.73   \u001b[0m | \u001b[95m 22.49   \u001b[0m | \u001b[95m 0.6974  \u001b[0m | \u001b[95m 0.462   \u001b[0m | \u001b[95m 0.9106  \u001b[0m |\n",
      "[-0.02728829 -0.02256603 -0.02618112 -0.02379467 -0.02875415 -0.02403336]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.02544 \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "[-0.02347321 -0.02015092 -0.02338119 -0.02171114 -0.02534032 -0.02087032]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.02249 \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 0.02635 \u001b[0m | \u001b[0m 14.44   \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 30.92   \u001b[0m | \u001b[0m 199.2   \u001b[0m | \u001b[0m 21.47   \u001b[0m | \u001b[0m 0.2659  \u001b[0m | \u001b[0m 0.7022  \u001b[0m | \u001b[0m 0.9906  \u001b[0m |\n",
      "[-0.0219179  -0.01833625 -0.02371876 -0.02115718 -0.02314515 -0.02051803]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.02147 \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 0.1761  \u001b[0m | \u001b[0m 9.356   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 244.6   \u001b[0m | \u001b[0m 194.8   \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 0.7343  \u001b[0m | \u001b[0m 0.5751  \u001b[0m | \u001b[0m 0.938   \u001b[0m |\n",
      "[-0.02306213 -0.01878906 -0.02346067 -0.02067803 -0.02423706 -0.02091805]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.02186 \u001b[0m | \u001b[0m 0.5979  \u001b[0m | \u001b[0m 0.1172  \u001b[0m | \u001b[0m 1.149   \u001b[0m | \u001b[0m 192.6   \u001b[0m | \u001b[0m 346.0   \u001b[0m | \u001b[0m 50.01   \u001b[0m | \u001b[0m 9.415   \u001b[0m | \u001b[0m 0.2818  \u001b[0m | \u001b[0m 0.5016  \u001b[0m | \u001b[0m 0.6154  \u001b[0m |\n",
      "[-0.02232161 -0.01836943 -0.02341118 -0.0206149  -0.02331032 -0.02029905]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.02139 \u001b[0m | \u001b[0m 0.5257  \u001b[0m | \u001b[0m 0.18    \u001b[0m | \u001b[0m 4.668   \u001b[0m | \u001b[0m 199.0   \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 163.7   \u001b[0m | \u001b[0m 21.45   \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 0.5493  \u001b[0m | \u001b[0m 0.6226  \u001b[0m |\n",
      "[-0.02284428 -0.01841777 -0.02327447 -0.02080308 -0.02375364 -0.02079167]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.02165 \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 0.07228 \u001b[0m | \u001b[0m 1.89    \u001b[0m | \u001b[0m 199.3   \u001b[0m | \u001b[0m 248.1   \u001b[0m | \u001b[0m 192.5   \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 0.409   \u001b[0m | \u001b[0m 0.4954  \u001b[0m | \u001b[0m 0.6264  \u001b[0m |\n",
      "[-0.02203002 -0.01876606 -0.02310362 -0.02193976 -0.023187   -0.0206531 ]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.02161 \u001b[0m | \u001b[0m 0.9783  \u001b[0m | \u001b[0m 0.14    \u001b[0m | \u001b[0m 10.16   \u001b[0m | \u001b[0m 142.4   \u001b[0m | \u001b[0m 147.3   \u001b[0m | \u001b[0m 196.2   \u001b[0m | \u001b[0m 28.93   \u001b[0m | \u001b[0m 0.4833  \u001b[0m | \u001b[0m 0.7031  \u001b[0m | \u001b[0m 0.7935  \u001b[0m |\n",
      "[-0.02476442 -0.02054951 -0.02476931 -0.02194041 -0.02606802 -0.02213675]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.02337 \u001b[0m | \u001b[0m 0.5569  \u001b[0m | \u001b[0m 0.03812 \u001b[0m | \u001b[0m 1.125   \u001b[0m | \u001b[0m 197.8   \u001b[0m | \u001b[0m 546.6   \u001b[0m | \u001b[0m 51.88   \u001b[0m | \u001b[0m 27.46   \u001b[0m | \u001b[0m 0.7589  \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.5795  \u001b[0m |\n",
      "[-0.02241421 -0.01821416 -0.0230596  -0.02094186 -0.02368603 -0.02059047]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.02148 \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 0.1949  \u001b[0m | \u001b[0m 9.99    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 220.6   \u001b[0m | \u001b[0m 54.77   \u001b[0m | \u001b[0m 27.75   \u001b[0m | \u001b[0m 0.3329  \u001b[0m | \u001b[0m 0.4638  \u001b[0m | \u001b[0m 0.5839  \u001b[0m |\n",
      "[-0.02240764 -0.01926294 -0.02272477 -0.02168204 -0.02372408 -0.01973032]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.02159 \u001b[0m | \u001b[0m 0.5221  \u001b[0m | \u001b[0m 0.09692 \u001b[0m | \u001b[0m 3.891   \u001b[0m | \u001b[0m 41.03   \u001b[0m | \u001b[0m 26.73   \u001b[0m | \u001b[0m 51.75   \u001b[0m | \u001b[0m 11.53   \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.3091  \u001b[0m | \u001b[0m 0.5827  \u001b[0m |\n",
      "[-0.0216775  -0.01937614 -0.02298814 -0.02202145 -0.02337521 -0.02004937]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.02158 \u001b[0m | \u001b[0m 0.7274  \u001b[0m | \u001b[0m 0.1355  \u001b[0m | \u001b[0m 14.25   \u001b[0m | \u001b[0m 30.92   \u001b[0m | \u001b[0m 227.0   \u001b[0m | \u001b[0m 82.09   \u001b[0m | \u001b[0m 21.93   \u001b[0m | \u001b[0m 0.4404  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 0.5164  \u001b[0m |\n",
      "[-0.0238075  -0.02038808 -0.02339015 -0.02192264 -0.02520051 -0.02081707]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.02259 \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 0.02772 \u001b[0m | \u001b[0m 3.144   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 204.5   \u001b[0m | \u001b[0m 195.2   \u001b[0m | \u001b[0m 4.438   \u001b[0m | \u001b[0m 0.05712 \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.7652  \u001b[0m |\n",
      "[-0.02215155 -0.01945953 -0.02811879 -0.02249695 -0.02292141 -0.0208215 ]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.02266 \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.1947  \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 654.3   \u001b[0m | \u001b[0m 198.7   \u001b[0m | \u001b[0m 20.25   \u001b[0m | \u001b[0m 0.5756  \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.021341028729888495, 'params': {'colsample_bytree': 0.8386693369871645, 'learning_rate': 0.17227711542317167, 'max_depth': 7.04508792816996, 'min_child_samples': 169.2544729869422, 'n_estimators': 94.36064691179153, 'num_iteration': 53.73094893771463, 'num_leaves': 22.4855333683266, 'reg_alpha': 0.6973591621250499, 'reg_lambda': 0.46203590390449933, 'subsample': 0.9106173447266883}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=53, num_iteration=53 will be ignored. Current value: num_iterations=53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0187974\n",
      "[2]\tvalid_0's l2: 0.0183888\n",
      "[3]\tvalid_0's l2: 0.0180847\n",
      "[4]\tvalid_0's l2: 0.0178497\n",
      "[5]\tvalid_0's l2: 0.0177725\n",
      "[6]\tvalid_0's l2: 0.0176624\n",
      "[7]\tvalid_0's l2: 0.01757\n",
      "[8]\tvalid_0's l2: 0.0175752\n",
      "[9]\tvalid_0's l2: 0.0174151\n",
      "[10]\tvalid_0's l2: 0.0174211\n",
      "[11]\tvalid_0's l2: 0.0172617\n",
      "[12]\tvalid_0's l2: 0.0173021\n",
      "[13]\tvalid_0's l2: 0.0173438\n",
      "[14]\tvalid_0's l2: 0.0173615\n",
      "[15]\tvalid_0's l2: 0.0173333\n",
      "[16]\tvalid_0's l2: 0.0172803\n",
      "[17]\tvalid_0's l2: 0.0171224\n",
      "[18]\tvalid_0's l2: 0.017091\n",
      "[19]\tvalid_0's l2: 0.0170655\n",
      "[20]\tvalid_0's l2: 0.017111\n",
      "[21]\tvalid_0's l2: 0.0170848\n",
      "[22]\tvalid_0's l2: 0.0169654\n",
      "[23]\tvalid_0's l2: 0.0169904\n",
      "[24]\tvalid_0's l2: 0.0170093\n",
      "[25]\tvalid_0's l2: 0.017071\n",
      "[26]\tvalid_0's l2: 0.0170972\n",
      "[27]\tvalid_0's l2: 0.0169984\n",
      "[28]\tvalid_0's l2: 0.0169865\n",
      "[29]\tvalid_0's l2: 0.0169842\n",
      "[30]\tvalid_0's l2: 0.0170375\n",
      "[31]\tvalid_0's l2: 0.0170494\n",
      "[32]\tvalid_0's l2: 0.0170501\n",
      "[33]\tvalid_0's l2: 0.0171234\n",
      "[34]\tvalid_0's l2: 0.0171229\n",
      "[35]\tvalid_0's l2: 0.0171406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[36]\tvalid_0's l2: 0.0170885\n",
      "[37]\tvalid_0's l2: 0.0171188\n",
      "[38]\tvalid_0's l2: 0.0170653\n",
      "[39]\tvalid_0's l2: 0.0169865\n",
      "[40]\tvalid_0's l2: 0.0169816\n",
      "[41]\tvalid_0's l2: 0.0169865\n",
      "[42]\tvalid_0's l2: 0.0170122\n",
      "[43]\tvalid_0's l2: 0.0169962\n",
      "[44]\tvalid_0's l2: 0.0170591\n",
      "[45]\tvalid_0's l2: 0.0170522\n",
      "[46]\tvalid_0's l2: 0.0166397\n",
      "[47]\tvalid_0's l2: 0.0167274\n",
      "[48]\tvalid_0's l2: 0.0167395\n",
      "[49]\tvalid_0's l2: 0.0167137\n",
      "[50]\tvalid_0's l2: 0.016709\n",
      "[51]\tvalid_0's l2: 0.0168287\n",
      "[52]\tvalid_0's l2: 0.0169417\n",
      "[53]\tvalid_0's l2: 0.0169049\n",
      "[1]\tvalid_0's l2: 0.0187974\n",
      "[2]\tvalid_0's l2: 0.0183888\n",
      "[3]\tvalid_0's l2: 0.0180847\n",
      "[4]\tvalid_0's l2: 0.0178497\n",
      "[5]\tvalid_0's l2: 0.0177725\n",
      "[6]\tvalid_0's l2: 0.0176624\n",
      "[7]\tvalid_0's l2: 0.01757\n",
      "[8]\tvalid_0's l2: 0.0175752\n",
      "[9]\tvalid_0's l2: 0.0174151\n",
      "[10]\tvalid_0's l2: 0.0174211\n",
      "[11]\tvalid_0's l2: 0.0172617\n",
      "[12]\tvalid_0's l2: 0.0173021\n",
      "[13]\tvalid_0's l2: 0.0173438\n",
      "[14]\tvalid_0's l2: 0.0173615\n",
      "[15]\tvalid_0's l2: 0.0173333\n",
      "[16]\tvalid_0's l2: 0.0172803\n",
      "[17]\tvalid_0's l2: 0.0171224\n",
      "[18]\tvalid_0's l2: 0.017091\n",
      "[19]\tvalid_0's l2: 0.0170655\n",
      "[20]\tvalid_0's l2: 0.017111\n",
      "[21]\tvalid_0's l2: 0.0170848\n",
      "[22]\tvalid_0's l2: 0.0169654\n",
      "[23]\tvalid_0's l2: 0.0169904\n",
      "[24]\tvalid_0's l2: 0.0170093\n",
      "[25]\tvalid_0's l2: 0.017071\n",
      "[26]\tvalid_0's l2: 0.0170972\n",
      "[27]\tvalid_0's l2: 0.0169984\n",
      "[28]\tvalid_0's l2: 0.0169865\n",
      "[29]\tvalid_0's l2: 0.0169842\n",
      "[30]\tvalid_0's l2: 0.0170375\n",
      "[31]\tvalid_0's l2: 0.0170494\n",
      "[32]\tvalid_0's l2: 0.0170501\n",
      "[33]\tvalid_0's l2: 0.0171234\n",
      "[34]\tvalid_0's l2: 0.0171229\n",
      "[35]\tvalid_0's l2: 0.0171406\n",
      "[36]\tvalid_0's l2: 0.0170885\n",
      "[37]\tvalid_0's l2: 0.0171188\n",
      "[38]\tvalid_0's l2: 0.0170653\n",
      "[39]\tvalid_0's l2: 0.0169865\n",
      "[40]\tvalid_0's l2: 0.0169816\n",
      "[41]\tvalid_0's l2: 0.0169865\n",
      "[42]\tvalid_0's l2: 0.0170122\n",
      "[43]\tvalid_0's l2: 0.0169962\n",
      "[44]\tvalid_0's l2: 0.0170591\n",
      "[45]\tvalid_0's l2: 0.0170522\n",
      "[46]\tvalid_0's l2: 0.0166397\n",
      "---- Train error ----\n",
      "0.015493944749224303\n",
      "---- CV error ----\n",
      "0.016639695522644677\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.10649249991358656\n",
      "mse = 0.0255595316615577\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.222   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.213   \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1227  \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.08486 \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2894  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2546  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.6822  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.06119 \u001b[0m | \u001b[95m 0.9711  \u001b[0m | \u001b[95m 0.02912 \u001b[0m | \u001b[95m 12.07   \u001b[0m | \u001b[95m 45.49   \u001b[0m | \u001b[95m 570.9   \u001b[0m | \u001b[95m 140.4   \u001b[0m | \u001b[95m 22.95   \u001b[0m | \u001b[95m 0.08744 \u001b[0m | \u001b[95m 0.5617  \u001b[0m | \u001b[95m 0.906   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.6639  \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1452  \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 47.61   \u001b[0m | \u001b[0m 568.1   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.6486  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1692  \u001b[0m | \u001b[0m 0.83    \u001b[0m | \u001b[0m 0.0792  \u001b[0m | \u001b[0m 13.95   \u001b[0m | \u001b[0m 29.89   \u001b[0m | \u001b[0m 570.4   \u001b[0m | \u001b[0m 136.0   \u001b[0m | \u001b[0m 11.2    \u001b[0m | \u001b[0m 0.4719  \u001b[0m | \u001b[0m 0.7444  \u001b[0m | \u001b[0m 0.6527  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.07475 \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 52.34   \u001b[0m | \u001b[0m 578.6   \u001b[0m | \u001b[0m 146.3   \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2086  \u001b[0m | \u001b[0m 0.8733  \u001b[0m | \u001b[0m 0.0247  \u001b[0m | \u001b[0m 3.36    \u001b[0m | \u001b[0m 17.28   \u001b[0m | \u001b[0m 503.0   \u001b[0m | \u001b[0m 106.2   \u001b[0m | \u001b[0m 28.95   \u001b[0m | \u001b[0m 0.7729  \u001b[0m | \u001b[0m 0.654   \u001b[0m | \u001b[0m 0.6658  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1035  \u001b[0m | \u001b[0m 0.8676  \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 14.41   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 472.8   \u001b[0m | \u001b[0m 123.9   \u001b[0m | \u001b[0m 29.08   \u001b[0m | \u001b[0m 0.5245  \u001b[0m | \u001b[0m 0.9207  \u001b[0m | \u001b[0m 0.6058  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1305  \u001b[0m | \u001b[0m 0.6036  \u001b[0m | \u001b[0m 0.1861  \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 51.62   \u001b[0m | \u001b[0m 583.8   \u001b[0m | \u001b[0m 115.7   \u001b[0m | \u001b[0m 9.911   \u001b[0m | \u001b[0m 0.2922  \u001b[0m | \u001b[0m 0.4568  \u001b[0m | \u001b[0m 0.8456  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2178  \u001b[0m | \u001b[0m 0.6111  \u001b[0m | \u001b[0m 0.03038 \u001b[0m | \u001b[0m 8.146   \u001b[0m | \u001b[0m 42.02   \u001b[0m | \u001b[0m 588.5   \u001b[0m | \u001b[0m 163.7   \u001b[0m | \u001b[0m 15.65   \u001b[0m | \u001b[0m 0.4921  \u001b[0m | \u001b[0m 0.0809  \u001b[0m | \u001b[0m 0.7945  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1293  \u001b[0m | \u001b[0m 0.8555  \u001b[0m | \u001b[0m 0.1296  \u001b[0m | \u001b[0m 12.47   \u001b[0m | \u001b[0m 57.72   \u001b[0m | \u001b[0m 564.0   \u001b[0m | \u001b[0m 126.6   \u001b[0m | \u001b[0m 12.91   \u001b[0m | \u001b[0m 0.6104  \u001b[0m | \u001b[0m 0.01027 \u001b[0m | \u001b[0m 0.8903  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1566  \u001b[0m | \u001b[0m 0.9147  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 6.327   \u001b[0m | \u001b[0m 42.98   \u001b[0m | \u001b[0m 603.8   \u001b[0m | \u001b[0m 134.6   \u001b[0m | \u001b[0m 6.253   \u001b[0m | \u001b[0m 0.6813  \u001b[0m | \u001b[0m 0.4071  \u001b[0m | \u001b[0m 0.8895  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1249  \u001b[0m | \u001b[0m 0.8129  \u001b[0m | \u001b[0m 0.1436  \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 80.04   \u001b[0m | \u001b[0m 594.4   \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 16.43   \u001b[0m | \u001b[0m 0.0246  \u001b[0m | \u001b[0m 0.5396  \u001b[0m | \u001b[0m 0.6176  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.07515 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 81.46   \u001b[0m | \u001b[0m 570.8   \u001b[0m | \u001b[0m 146.9   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.061194496491752105, 'params': {'colsample_bytree': 0.9710867964082177, 'learning_rate': 0.029123638873705462, 'max_depth': 12.065182733231854, 'min_child_samples': 45.48882316217731, 'n_estimators': 570.9410644165744, 'num_iteration': 140.4062102482627, 'num_leaves': 22.951635202140263, 'reg_alpha': 0.08743772146983486, 'reg_lambda': 0.5617457703361829, 'subsample': 0.9060483901675885}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0491849\tvalid_0's binary_logloss: 0.203108\n",
      "[2]\tvalid_0's l2: 0.0488819\tvalid_0's binary_logloss: 0.200707\n",
      "[3]\tvalid_0's l2: 0.0485988\tvalid_0's binary_logloss: 0.198578\n",
      "[4]\tvalid_0's l2: 0.0484497\tvalid_0's binary_logloss: 0.197472\n",
      "[5]\tvalid_0's l2: 0.048362\tvalid_0's binary_logloss: 0.196815\n",
      "[6]\tvalid_0's l2: 0.0482491\tvalid_0's binary_logloss: 0.196016\n",
      "[7]\tvalid_0's l2: 0.0480867\tvalid_0's binary_logloss: 0.194835\n",
      "[8]\tvalid_0's l2: 0.0481365\tvalid_0's binary_logloss: 0.19517\n",
      "[9]\tvalid_0's l2: 0.0479156\tvalid_0's binary_logloss: 0.193741\n",
      "[10]\tvalid_0's l2: 0.0477881\tvalid_0's binary_logloss: 0.192961\n",
      "[11]\tvalid_0's l2: 0.0477249\tvalid_0's binary_logloss: 0.192397\n",
      "[12]\tvalid_0's l2: 0.0477506\tvalid_0's binary_logloss: 0.192614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[13]\tvalid_0's l2: 0.0475904\tvalid_0's binary_logloss: 0.191453\n",
      "[14]\tvalid_0's l2: 0.0474277\tvalid_0's binary_logloss: 0.190271\n",
      "[15]\tvalid_0's l2: 0.0473965\tvalid_0's binary_logloss: 0.190083\n",
      "[16]\tvalid_0's l2: 0.0473229\tvalid_0's binary_logloss: 0.189518\n",
      "[17]\tvalid_0's l2: 0.0471718\tvalid_0's binary_logloss: 0.188711\n",
      "[18]\tvalid_0's l2: 0.0471425\tvalid_0's binary_logloss: 0.188705\n",
      "[19]\tvalid_0's l2: 0.0470669\tvalid_0's binary_logloss: 0.188192\n",
      "[20]\tvalid_0's l2: 0.046912\tvalid_0's binary_logloss: 0.187451\n",
      "[21]\tvalid_0's l2: 0.0469199\tvalid_0's binary_logloss: 0.187411\n",
      "[22]\tvalid_0's l2: 0.0468551\tvalid_0's binary_logloss: 0.187383\n",
      "[23]\tvalid_0's l2: 0.0466519\tvalid_0's binary_logloss: 0.186215\n",
      "[24]\tvalid_0's l2: 0.0467119\tvalid_0's binary_logloss: 0.186171\n",
      "[25]\tvalid_0's l2: 0.046658\tvalid_0's binary_logloss: 0.185901\n",
      "[26]\tvalid_0's l2: 0.0465954\tvalid_0's binary_logloss: 0.185884\n",
      "[27]\tvalid_0's l2: 0.0463924\tvalid_0's binary_logloss: 0.184464\n",
      "[28]\tvalid_0's l2: 0.0464279\tvalid_0's binary_logloss: 0.184653\n",
      "[29]\tvalid_0's l2: 0.0464411\tvalid_0's binary_logloss: 0.184492\n",
      "[30]\tvalid_0's l2: 0.0464072\tvalid_0's binary_logloss: 0.184648\n",
      "[31]\tvalid_0's l2: 0.0464182\tvalid_0's binary_logloss: 0.184679\n",
      "[32]\tvalid_0's l2: 0.0462666\tvalid_0's binary_logloss: 0.183598\n",
      "[33]\tvalid_0's l2: 0.0462825\tvalid_0's binary_logloss: 0.183732\n",
      "[34]\tvalid_0's l2: 0.0463668\tvalid_0's binary_logloss: 0.183777\n",
      "[35]\tvalid_0's l2: 0.0464006\tvalid_0's binary_logloss: 0.183932\n",
      "[36]\tvalid_0's l2: 0.0464807\tvalid_0's binary_logloss: 0.184331\n",
      "[37]\tvalid_0's l2: 0.0464153\tvalid_0's binary_logloss: 0.184167\n",
      "[38]\tvalid_0's l2: 0.0463761\tvalid_0's binary_logloss: 0.183967\n",
      "[39]\tvalid_0's l2: 0.046344\tvalid_0's binary_logloss: 0.183428\n",
      "[40]\tvalid_0's l2: 0.0463686\tvalid_0's binary_logloss: 0.18368\n",
      "[41]\tvalid_0's l2: 0.0464104\tvalid_0's binary_logloss: 0.18392\n",
      "[42]\tvalid_0's l2: 0.0463394\tvalid_0's binary_logloss: 0.183644\n",
      "[43]\tvalid_0's l2: 0.0463699\tvalid_0's binary_logloss: 0.183743\n",
      "[44]\tvalid_0's l2: 0.046314\tvalid_0's binary_logloss: 0.183211\n",
      "[45]\tvalid_0's l2: 0.0462394\tvalid_0's binary_logloss: 0.183025\n",
      "[46]\tvalid_0's l2: 0.0464902\tvalid_0's binary_logloss: 0.188837\n",
      "[47]\tvalid_0's l2: 0.0463731\tvalid_0's binary_logloss: 0.188197\n",
      "[48]\tvalid_0's l2: 0.0463681\tvalid_0's binary_logloss: 0.1881\n",
      "[49]\tvalid_0's l2: 0.0463671\tvalid_0's binary_logloss: 0.188223\n",
      "[50]\tvalid_0's l2: 0.0464266\tvalid_0's binary_logloss: 0.188524\n",
      "[51]\tvalid_0's l2: 0.0462914\tvalid_0's binary_logloss: 0.187729\n",
      "[52]\tvalid_0's l2: 0.0463164\tvalid_0's binary_logloss: 0.187606\n",
      "[53]\tvalid_0's l2: 0.0463638\tvalid_0's binary_logloss: 0.187865\n",
      "[54]\tvalid_0's l2: 0.0463623\tvalid_0's binary_logloss: 0.187684\n",
      "[55]\tvalid_0's l2: 0.0462228\tvalid_0's binary_logloss: 0.18684\n",
      "[56]\tvalid_0's l2: 0.0462333\tvalid_0's binary_logloss: 0.187035\n",
      "[57]\tvalid_0's l2: 0.0462853\tvalid_0's binary_logloss: 0.186908\n",
      "[58]\tvalid_0's l2: 0.0477782\tvalid_0's binary_logloss: 0.198696\n",
      "[59]\tvalid_0's l2: 0.0478211\tvalid_0's binary_logloss: 0.198967\n",
      "[60]\tvalid_0's l2: 0.0477062\tvalid_0's binary_logloss: 0.198198\n",
      "[61]\tvalid_0's l2: 0.0508992\tvalid_0's binary_logloss: 0.215408\n",
      "[62]\tvalid_0's l2: 0.0505759\tvalid_0's binary_logloss: 0.213936\n",
      "[63]\tvalid_0's l2: 0.0502588\tvalid_0's binary_logloss: 0.212387\n",
      "[64]\tvalid_0's l2: 0.0503206\tvalid_0's binary_logloss: 0.212737\n",
      "[65]\tvalid_0's l2: 0.0503268\tvalid_0's binary_logloss: 0.212888\n",
      "[66]\tvalid_0's l2: 0.0500283\tvalid_0's binary_logloss: 0.211446\n",
      "[67]\tvalid_0's l2: 0.0497285\tvalid_0's binary_logloss: 0.21001\n",
      "[68]\tvalid_0's l2: 0.0495744\tvalid_0's binary_logloss: 0.208833\n",
      "[69]\tvalid_0's l2: 0.0495457\tvalid_0's binary_logloss: 0.208912\n",
      "[70]\tvalid_0's l2: 0.0495325\tvalid_0's binary_logloss: 0.208911\n",
      "[71]\tvalid_0's l2: 0.0494919\tvalid_0's binary_logloss: 0.208749\n",
      "[72]\tvalid_0's l2: 0.0493092\tvalid_0's binary_logloss: 0.207721\n",
      "[73]\tvalid_0's l2: 0.0490981\tvalid_0's binary_logloss: 0.20649\n",
      "[74]\tvalid_0's l2: 0.0491682\tvalid_0's binary_logloss: 0.206877\n",
      "[75]\tvalid_0's l2: 0.0489695\tvalid_0's binary_logloss: 0.2058\n",
      "[76]\tvalid_0's l2: 0.0489717\tvalid_0's binary_logloss: 0.205808\n",
      "[77]\tvalid_0's l2: 0.0489896\tvalid_0's binary_logloss: 0.205967\n",
      "[78]\tvalid_0's l2: 0.0490362\tvalid_0's binary_logloss: 0.206234\n",
      "[79]\tvalid_0's l2: 0.0487536\tvalid_0's binary_logloss: 0.204739\n",
      "[80]\tvalid_0's l2: 0.0485243\tvalid_0's binary_logloss: 0.203544\n",
      "[81]\tvalid_0's l2: 0.0485685\tvalid_0's binary_logloss: 0.20383\n",
      "[82]\tvalid_0's l2: 0.048473\tvalid_0's binary_logloss: 0.203068\n",
      "[83]\tvalid_0's l2: 0.0484965\tvalid_0's binary_logloss: 0.20327\n",
      "[84]\tvalid_0's l2: 0.0485103\tvalid_0's binary_logloss: 0.203463\n",
      "[85]\tvalid_0's l2: 0.0485646\tvalid_0's binary_logloss: 0.203797\n",
      "[86]\tvalid_0's l2: 0.0483478\tvalid_0's binary_logloss: 0.202635\n",
      "[87]\tvalid_0's l2: 0.0482683\tvalid_0's binary_logloss: 0.202038\n",
      "[88]\tvalid_0's l2: 0.0483125\tvalid_0's binary_logloss: 0.202418\n",
      "[89]\tvalid_0's l2: 0.0483073\tvalid_0's binary_logloss: 0.202493\n",
      "[90]\tvalid_0's l2: 0.0483643\tvalid_0's binary_logloss: 0.202793\n",
      "[91]\tvalid_0's l2: 0.0515956\tvalid_0's binary_logloss: 0.219208\n",
      "[92]\tvalid_0's l2: 0.051317\tvalid_0's binary_logloss: 0.217779\n",
      "[93]\tvalid_0's l2: 0.0510106\tvalid_0's binary_logloss: 0.21622\n",
      "[94]\tvalid_0's l2: 0.0511227\tvalid_0's binary_logloss: 0.216831\n",
      "[95]\tvalid_0's l2: 0.0511511\tvalid_0's binary_logloss: 0.217031\n",
      "[96]\tvalid_0's l2: 0.0511883\tvalid_0's binary_logloss: 0.217327\n",
      "[97]\tvalid_0's l2: 0.0508947\tvalid_0's binary_logloss: 0.215683\n",
      "[98]\tvalid_0's l2: 0.0509233\tvalid_0's binary_logloss: 0.215847\n",
      "[99]\tvalid_0's l2: 0.0505982\tvalid_0's binary_logloss: 0.214373\n",
      "[100]\tvalid_0's l2: 0.0503023\tvalid_0's binary_logloss: 0.212994\n",
      "[101]\tvalid_0's l2: 0.0521295\tvalid_0's binary_logloss: 0.221507\n",
      "[102]\tvalid_0's l2: 0.052219\tvalid_0's binary_logloss: 0.222015\n",
      "[103]\tvalid_0's l2: 0.0523147\tvalid_0's binary_logloss: 0.222511\n",
      "[104]\tvalid_0's l2: 0.0519936\tvalid_0's binary_logloss: 0.220883\n",
      "[105]\tvalid_0's l2: 0.0540238\tvalid_0's binary_logloss: 0.229665\n",
      "[106]\tvalid_0's l2: 0.0540979\tvalid_0's binary_logloss: 0.230109\n",
      "[107]\tvalid_0's l2: 0.0542322\tvalid_0's binary_logloss: 0.230753\n",
      "[108]\tvalid_0's l2: 0.053709\tvalid_0's binary_logloss: 0.228547\n",
      "[109]\tvalid_0's l2: 0.0537964\tvalid_0's binary_logloss: 0.228978\n",
      "[110]\tvalid_0's l2: 0.0538656\tvalid_0's binary_logloss: 0.229357\n",
      "[111]\tvalid_0's l2: 0.0534889\tvalid_0's binary_logloss: 0.227655\n",
      "[112]\tvalid_0's l2: 0.0530236\tvalid_0's binary_logloss: 0.22569\n",
      "[113]\tvalid_0's l2: 0.0526016\tvalid_0's binary_logloss: 0.223758\n",
      "[114]\tvalid_0's l2: 0.052284\tvalid_0's binary_logloss: 0.222074\n",
      "[115]\tvalid_0's l2: 0.0518779\tvalid_0's binary_logloss: 0.220182\n",
      "[116]\tvalid_0's l2: 0.051521\tvalid_0's binary_logloss: 0.218541\n",
      "[117]\tvalid_0's l2: 0.0516065\tvalid_0's binary_logloss: 0.218961\n",
      "[118]\tvalid_0's l2: 0.0512313\tvalid_0's binary_logloss: 0.217171\n",
      "[119]\tvalid_0's l2: 0.0512928\tvalid_0's binary_logloss: 0.21754\n",
      "[120]\tvalid_0's l2: 0.0513677\tvalid_0's binary_logloss: 0.217974\n",
      "[121]\tvalid_0's l2: 0.0514374\tvalid_0's binary_logloss: 0.218396\n",
      "[122]\tvalid_0's l2: 0.0515221\tvalid_0's binary_logloss: 0.218861\n",
      "[123]\tvalid_0's l2: 0.0511834\tvalid_0's binary_logloss: 0.217343\n",
      "[124]\tvalid_0's l2: 0.0509744\tvalid_0's binary_logloss: 0.216077\n",
      "[125]\tvalid_0's l2: 0.0510083\tvalid_0's binary_logloss: 0.216294\n",
      "[126]\tvalid_0's l2: 0.0510644\tvalid_0's binary_logloss: 0.216621\n",
      "[127]\tvalid_0's l2: 0.0508313\tvalid_0's binary_logloss: 0.21539\n",
      "[128]\tvalid_0's l2: 0.0509127\tvalid_0's binary_logloss: 0.215859\n",
      "[129]\tvalid_0's l2: 0.0505679\tvalid_0's binary_logloss: 0.214149\n",
      "[130]\tvalid_0's l2: 0.0502782\tvalid_0's binary_logloss: 0.212795\n",
      "[131]\tvalid_0's l2: 0.0503836\tvalid_0's binary_logloss: 0.213332\n",
      "[132]\tvalid_0's l2: 0.0501526\tvalid_0's binary_logloss: 0.212086\n",
      "[133]\tvalid_0's l2: 0.0499171\tvalid_0's binary_logloss: 0.210951\n",
      "[134]\tvalid_0's l2: 0.0513014\tvalid_0's binary_logloss: 0.217559\n",
      "[135]\tvalid_0's l2: 0.0510346\tvalid_0's binary_logloss: 0.216265\n",
      "[136]\tvalid_0's l2: 0.0531174\tvalid_0's binary_logloss: 0.225527\n",
      "[137]\tvalid_0's l2: 0.0532303\tvalid_0's binary_logloss: 0.226109\n",
      "[138]\tvalid_0's l2: 0.0529099\tvalid_0's binary_logloss: 0.224497\n",
      "[139]\tvalid_0's l2: 0.0524886\tvalid_0's binary_logloss: 0.22276\n",
      "[140]\tvalid_0's l2: 0.0526432\tvalid_0's binary_logloss: 0.223508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0491849\tvalid_0's binary_logloss: 0.203108\n",
      "[2]\tvalid_0's l2: 0.0488819\tvalid_0's binary_logloss: 0.200707\n",
      "[3]\tvalid_0's l2: 0.0485988\tvalid_0's binary_logloss: 0.198578\n",
      "[4]\tvalid_0's l2: 0.0484497\tvalid_0's binary_logloss: 0.197472\n",
      "[5]\tvalid_0's l2: 0.048362\tvalid_0's binary_logloss: 0.196815\n",
      "[6]\tvalid_0's l2: 0.0482491\tvalid_0's binary_logloss: 0.196016\n",
      "[7]\tvalid_0's l2: 0.0480867\tvalid_0's binary_logloss: 0.194835\n",
      "[8]\tvalid_0's l2: 0.0481365\tvalid_0's binary_logloss: 0.19517\n",
      "[9]\tvalid_0's l2: 0.0479156\tvalid_0's binary_logloss: 0.193741\n",
      "[10]\tvalid_0's l2: 0.0477881\tvalid_0's binary_logloss: 0.192961\n",
      "[11]\tvalid_0's l2: 0.0477249\tvalid_0's binary_logloss: 0.192397\n",
      "[12]\tvalid_0's l2: 0.0477506\tvalid_0's binary_logloss: 0.192614\n",
      "[13]\tvalid_0's l2: 0.0475904\tvalid_0's binary_logloss: 0.191453\n",
      "[14]\tvalid_0's l2: 0.0474277\tvalid_0's binary_logloss: 0.190271\n",
      "[15]\tvalid_0's l2: 0.0473965\tvalid_0's binary_logloss: 0.190083\n",
      "[16]\tvalid_0's l2: 0.0473229\tvalid_0's binary_logloss: 0.189518\n",
      "[17]\tvalid_0's l2: 0.0471718\tvalid_0's binary_logloss: 0.188711\n",
      "[18]\tvalid_0's l2: 0.0471425\tvalid_0's binary_logloss: 0.188705\n",
      "[19]\tvalid_0's l2: 0.0470669\tvalid_0's binary_logloss: 0.188192\n",
      "[20]\tvalid_0's l2: 0.046912\tvalid_0's binary_logloss: 0.187451\n",
      "[21]\tvalid_0's l2: 0.0469199\tvalid_0's binary_logloss: 0.187411\n",
      "[22]\tvalid_0's l2: 0.0468551\tvalid_0's binary_logloss: 0.187383\n",
      "[23]\tvalid_0's l2: 0.0466519\tvalid_0's binary_logloss: 0.186215\n",
      "[24]\tvalid_0's l2: 0.0467119\tvalid_0's binary_logloss: 0.186171\n",
      "[25]\tvalid_0's l2: 0.046658\tvalid_0's binary_logloss: 0.185901\n",
      "[26]\tvalid_0's l2: 0.0465954\tvalid_0's binary_logloss: 0.185884\n",
      "[27]\tvalid_0's l2: 0.0463924\tvalid_0's binary_logloss: 0.184464\n",
      "[28]\tvalid_0's l2: 0.0464279\tvalid_0's binary_logloss: 0.184653\n",
      "[29]\tvalid_0's l2: 0.0464411\tvalid_0's binary_logloss: 0.184492\n",
      "[30]\tvalid_0's l2: 0.0464072\tvalid_0's binary_logloss: 0.184648\n",
      "[31]\tvalid_0's l2: 0.0464182\tvalid_0's binary_logloss: 0.184679\n",
      "[32]\tvalid_0's l2: 0.0462666\tvalid_0's binary_logloss: 0.183598\n",
      "[33]\tvalid_0's l2: 0.0462825\tvalid_0's binary_logloss: 0.183732\n",
      "[34]\tvalid_0's l2: 0.0463668\tvalid_0's binary_logloss: 0.183777\n",
      "[35]\tvalid_0's l2: 0.0464006\tvalid_0's binary_logloss: 0.183932\n",
      "[36]\tvalid_0's l2: 0.0464807\tvalid_0's binary_logloss: 0.184331\n",
      "[37]\tvalid_0's l2: 0.0464153\tvalid_0's binary_logloss: 0.184167\n",
      "[38]\tvalid_0's l2: 0.0463761\tvalid_0's binary_logloss: 0.183967\n",
      "[39]\tvalid_0's l2: 0.046344\tvalid_0's binary_logloss: 0.183428\n",
      "[40]\tvalid_0's l2: 0.0463686\tvalid_0's binary_logloss: 0.18368\n",
      "[41]\tvalid_0's l2: 0.0464104\tvalid_0's binary_logloss: 0.18392\n",
      "[42]\tvalid_0's l2: 0.0463394\tvalid_0's binary_logloss: 0.183644\n",
      "[43]\tvalid_0's l2: 0.0463699\tvalid_0's binary_logloss: 0.183743\n",
      "[44]\tvalid_0's l2: 0.046314\tvalid_0's binary_logloss: 0.183211\n",
      "[45]\tvalid_0's l2: 0.0462394\tvalid_0's binary_logloss: 0.183025\n",
      "[46]\tvalid_0's l2: 0.0464902\tvalid_0's binary_logloss: 0.188837\n",
      "[47]\tvalid_0's l2: 0.0463731\tvalid_0's binary_logloss: 0.188197\n",
      "[48]\tvalid_0's l2: 0.0463681\tvalid_0's binary_logloss: 0.1881\n",
      "[49]\tvalid_0's l2: 0.0463671\tvalid_0's binary_logloss: 0.188223\n",
      "[50]\tvalid_0's l2: 0.0464266\tvalid_0's binary_logloss: 0.188524\n",
      "[51]\tvalid_0's l2: 0.0462914\tvalid_0's binary_logloss: 0.187729\n",
      "[52]\tvalid_0's l2: 0.0463164\tvalid_0's binary_logloss: 0.187606\n",
      "[53]\tvalid_0's l2: 0.0463638\tvalid_0's binary_logloss: 0.187865\n",
      "[54]\tvalid_0's l2: 0.0463623\tvalid_0's binary_logloss: 0.187684\n",
      "[55]\tvalid_0's l2: 0.0462228\tvalid_0's binary_logloss: 0.18684\n",
      "---- Train error ----\n",
      "0.03643052057768667\n",
      "---- CV error ----\n",
      "0.046222763664545925\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.024840591479563745\n",
      "mse = 0.05207330412177481\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1729  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1706  \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 0.1926  \u001b[0m | \u001b[95m 1.117   \u001b[0m | \u001b[95m 30.22   \u001b[0m | \u001b[95m 305.7   \u001b[0m | \u001b[95m 148.5   \u001b[0m | \u001b[95m 24.67   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.9646  \u001b[0m | \u001b[95m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1742  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1823  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.176   \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1814  \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 0.01505 \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 68.61   \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 160.3   \u001b[0m | \u001b[0m 16.66   \u001b[0m | \u001b[0m 0.4092  \u001b[0m | \u001b[0m 0.1119  \u001b[0m | \u001b[0m 0.7041  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.1699  \u001b[0m | \u001b[95m 0.8387  \u001b[0m | \u001b[95m 0.1723  \u001b[0m | \u001b[95m 7.045   \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 94.36   \u001b[0m | \u001b[95m 53.73   \u001b[0m | \u001b[95m 22.49   \u001b[0m | \u001b[95m 0.6974  \u001b[0m | \u001b[95m 0.462   \u001b[0m | \u001b[95m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.177   \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.173   \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.17    \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 176.8   \u001b[0m | \u001b[0m 702.2   \u001b[0m | \u001b[0m 99.75   \u001b[0m | \u001b[0m 4.208   \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.5864  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1726  \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 574.3   \u001b[0m | \u001b[0m 167.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 0.02429 \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.1694  \u001b[0m | \u001b[95m 0.74    \u001b[0m | \u001b[95m 0.09247 \u001b[0m | \u001b[95m 4.982   \u001b[0m | \u001b[95m 180.9   \u001b[0m | \u001b[95m 277.0   \u001b[0m | \u001b[95m 184.5   \u001b[0m | \u001b[95m 25.02   \u001b[0m | \u001b[95m 0.4763  \u001b[0m | \u001b[95m 0.03582 \u001b[0m | \u001b[95m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1753  \u001b[0m | \u001b[0m 0.561   \u001b[0m | \u001b[0m 0.1179  \u001b[0m | \u001b[0m 4.555   \u001b[0m | \u001b[0m 25.01   \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 0.01987 \u001b[0m | \u001b[0m 0.9257  \u001b[0m | \u001b[0m 0.8376  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1753  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1729  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1827  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1696  \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-0.1692  \u001b[0m | \u001b[95m 0.7936  \u001b[0m | \u001b[95m 0.1276  \u001b[0m | \u001b[95m 11.92   \u001b[0m | \u001b[95m 198.9   \u001b[0m | \u001b[95m 362.6   \u001b[0m | \u001b[95m 76.97   \u001b[0m | \u001b[95m 25.06   \u001b[0m | \u001b[95m 0.3706  \u001b[0m | \u001b[95m 0.9528  \u001b[0m | \u001b[95m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1695  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1718  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.16921014047642124, 'params': {'colsample_bytree': 0.7935628287937404, 'learning_rate': 0.12763905062917794, 'max_depth': 11.924832237466552, 'min_child_samples': 198.90731873274026, 'n_estimators': 362.62776608925896, 'num_iteration': 76.96907462644411, 'num_leaves': 25.059465537678427, 'reg_alpha': 0.3706378509704009, 'reg_lambda': 0.9528080491402059, 'subsample': 0.566943254112491}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=76, num_iteration=76 will be ignored. Current value: num_iterations=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.155358\tvalid_0's binary_logloss: 0.490398\n",
      "[2]\tvalid_0's l2: 0.155787\tvalid_0's binary_logloss: 0.491546\n",
      "[3]\tvalid_0's l2: 0.156287\tvalid_0's binary_logloss: 0.492886\n",
      "[4]\tvalid_0's l2: 0.155987\tvalid_0's binary_logloss: 0.492101\n",
      "[5]\tvalid_0's l2: 0.1559\tvalid_0's binary_logloss: 0.491853\n",
      "[6]\tvalid_0's l2: 0.156442\tvalid_0's binary_logloss: 0.493505\n",
      "[7]\tvalid_0's l2: 0.15674\tvalid_0's binary_logloss: 0.494296\n",
      "[8]\tvalid_0's l2: 0.156085\tvalid_0's binary_logloss: 0.492301\n",
      "[9]\tvalid_0's l2: 0.156203\tvalid_0's binary_logloss: 0.492429\n",
      "[10]\tvalid_0's l2: 0.156737\tvalid_0's binary_logloss: 0.493876\n",
      "[11]\tvalid_0's l2: 0.156765\tvalid_0's binary_logloss: 0.494077\n",
      "[12]\tvalid_0's l2: 0.156693\tvalid_0's binary_logloss: 0.493907\n",
      "[13]\tvalid_0's l2: 0.156413\tvalid_0's binary_logloss: 0.493036\n",
      "[14]\tvalid_0's l2: 0.155523\tvalid_0's binary_logloss: 0.490154\n",
      "[15]\tvalid_0's l2: 0.155406\tvalid_0's binary_logloss: 0.489803\n",
      "[16]\tvalid_0's l2: 0.155512\tvalid_0's binary_logloss: 0.490432\n",
      "[17]\tvalid_0's l2: 0.155124\tvalid_0's binary_logloss: 0.489413\n",
      "[18]\tvalid_0's l2: 0.1551\tvalid_0's binary_logloss: 0.489516\n",
      "[19]\tvalid_0's l2: 0.155098\tvalid_0's binary_logloss: 0.489573\n",
      "[20]\tvalid_0's l2: 0.155398\tvalid_0's binary_logloss: 0.490371\n",
      "[21]\tvalid_0's l2: 0.155311\tvalid_0's binary_logloss: 0.490171\n",
      "[22]\tvalid_0's l2: 0.15569\tvalid_0's binary_logloss: 0.491197\n",
      "[23]\tvalid_0's l2: 0.156035\tvalid_0's binary_logloss: 0.492091\n",
      "[24]\tvalid_0's l2: 0.156275\tvalid_0's binary_logloss: 0.492631\n",
      "[25]\tvalid_0's l2: 0.156269\tvalid_0's binary_logloss: 0.492358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[26]\tvalid_0's l2: 0.156554\tvalid_0's binary_logloss: 0.492989\n",
      "[27]\tvalid_0's l2: 0.156049\tvalid_0's binary_logloss: 0.491547\n",
      "[28]\tvalid_0's l2: 0.15598\tvalid_0's binary_logloss: 0.491453\n",
      "[29]\tvalid_0's l2: 0.155807\tvalid_0's binary_logloss: 0.490844\n",
      "[30]\tvalid_0's l2: 0.155921\tvalid_0's binary_logloss: 0.491002\n",
      "[31]\tvalid_0's l2: 0.155894\tvalid_0's binary_logloss: 0.490843\n",
      "[32]\tvalid_0's l2: 0.155828\tvalid_0's binary_logloss: 0.490793\n",
      "[33]\tvalid_0's l2: 0.156032\tvalid_0's binary_logloss: 0.491134\n",
      "[34]\tvalid_0's l2: 0.155878\tvalid_0's binary_logloss: 0.490779\n",
      "[35]\tvalid_0's l2: 0.155766\tvalid_0's binary_logloss: 0.490475\n",
      "[36]\tvalid_0's l2: 0.155866\tvalid_0's binary_logloss: 0.490771\n",
      "[37]\tvalid_0's l2: 0.156169\tvalid_0's binary_logloss: 0.491828\n",
      "[38]\tvalid_0's l2: 0.156446\tvalid_0's binary_logloss: 0.49252\n",
      "[39]\tvalid_0's l2: 0.155737\tvalid_0's binary_logloss: 0.490321\n",
      "[40]\tvalid_0's l2: 0.155775\tvalid_0's binary_logloss: 0.49061\n",
      "[41]\tvalid_0's l2: 0.155643\tvalid_0's binary_logloss: 0.490171\n",
      "[42]\tvalid_0's l2: 0.155926\tvalid_0's binary_logloss: 0.490836\n",
      "[43]\tvalid_0's l2: 0.155823\tvalid_0's binary_logloss: 0.490498\n",
      "[44]\tvalid_0's l2: 0.155881\tvalid_0's binary_logloss: 0.490729\n",
      "[45]\tvalid_0's l2: 0.156002\tvalid_0's binary_logloss: 0.491104\n",
      "[46]\tvalid_0's l2: 0.158179\tvalid_0's binary_logloss: 0.496428\n",
      "[47]\tvalid_0's l2: 0.158163\tvalid_0's binary_logloss: 0.496321\n",
      "[48]\tvalid_0's l2: 0.157973\tvalid_0's binary_logloss: 0.495849\n",
      "[49]\tvalid_0's l2: 0.157764\tvalid_0's binary_logloss: 0.495371\n",
      "[50]\tvalid_0's l2: 0.15784\tvalid_0's binary_logloss: 0.495638\n",
      "[51]\tvalid_0's l2: 0.157449\tvalid_0's binary_logloss: 0.494631\n",
      "[52]\tvalid_0's l2: 0.157765\tvalid_0's binary_logloss: 0.495437\n",
      "[53]\tvalid_0's l2: 0.157654\tvalid_0's binary_logloss: 0.495145\n",
      "[54]\tvalid_0's l2: 0.156913\tvalid_0's binary_logloss: 0.493236\n",
      "[55]\tvalid_0's l2: 0.156872\tvalid_0's binary_logloss: 0.493239\n",
      "[56]\tvalid_0's l2: 0.156665\tvalid_0's binary_logloss: 0.492697\n",
      "[57]\tvalid_0's l2: 0.156497\tvalid_0's binary_logloss: 0.492396\n",
      "[58]\tvalid_0's l2: 0.159258\tvalid_0's binary_logloss: 0.499186\n",
      "[59]\tvalid_0's l2: 0.159114\tvalid_0's binary_logloss: 0.498911\n",
      "[60]\tvalid_0's l2: 0.158741\tvalid_0's binary_logloss: 0.497735\n",
      "[61]\tvalid_0's l2: 0.162075\tvalid_0's binary_logloss: 0.505793\n",
      "[62]\tvalid_0's l2: 0.160486\tvalid_0's binary_logloss: 0.502062\n",
      "[63]\tvalid_0's l2: 0.159842\tvalid_0's binary_logloss: 0.500442\n",
      "[64]\tvalid_0's l2: 0.159569\tvalid_0's binary_logloss: 0.499844\n",
      "[65]\tvalid_0's l2: 0.159663\tvalid_0's binary_logloss: 0.500122\n",
      "[66]\tvalid_0's l2: 0.158649\tvalid_0's binary_logloss: 0.497461\n",
      "[67]\tvalid_0's l2: 0.157927\tvalid_0's binary_logloss: 0.495278\n",
      "[68]\tvalid_0's l2: 0.157113\tvalid_0's binary_logloss: 0.493167\n",
      "[69]\tvalid_0's l2: 0.157092\tvalid_0's binary_logloss: 0.493124\n",
      "[70]\tvalid_0's l2: 0.157132\tvalid_0's binary_logloss: 0.49325\n",
      "[71]\tvalid_0's l2: 0.156845\tvalid_0's binary_logloss: 0.492624\n",
      "[72]\tvalid_0's l2: 0.156589\tvalid_0's binary_logloss: 0.491988\n",
      "[73]\tvalid_0's l2: 0.156344\tvalid_0's binary_logloss: 0.491164\n",
      "[74]\tvalid_0's l2: 0.156364\tvalid_0's binary_logloss: 0.491262\n",
      "[75]\tvalid_0's l2: 0.155887\tvalid_0's binary_logloss: 0.489949\n",
      "[76]\tvalid_0's l2: 0.155918\tvalid_0's binary_logloss: 0.490034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.155358\tvalid_0's binary_logloss: 0.490398\n",
      "[2]\tvalid_0's l2: 0.155787\tvalid_0's binary_logloss: 0.491546\n",
      "[3]\tvalid_0's l2: 0.156287\tvalid_0's binary_logloss: 0.492886\n",
      "[4]\tvalid_0's l2: 0.155987\tvalid_0's binary_logloss: 0.492101\n",
      "[5]\tvalid_0's l2: 0.1559\tvalid_0's binary_logloss: 0.491853\n",
      "[6]\tvalid_0's l2: 0.156442\tvalid_0's binary_logloss: 0.493505\n",
      "[7]\tvalid_0's l2: 0.15674\tvalid_0's binary_logloss: 0.494296\n",
      "[8]\tvalid_0's l2: 0.156085\tvalid_0's binary_logloss: 0.492301\n",
      "[9]\tvalid_0's l2: 0.156203\tvalid_0's binary_logloss: 0.492429\n",
      "[10]\tvalid_0's l2: 0.156737\tvalid_0's binary_logloss: 0.493876\n",
      "[11]\tvalid_0's l2: 0.156765\tvalid_0's binary_logloss: 0.494077\n",
      "[12]\tvalid_0's l2: 0.156693\tvalid_0's binary_logloss: 0.493907\n",
      "[13]\tvalid_0's l2: 0.156413\tvalid_0's binary_logloss: 0.493036\n",
      "[14]\tvalid_0's l2: 0.155523\tvalid_0's binary_logloss: 0.490154\n",
      "[15]\tvalid_0's l2: 0.155406\tvalid_0's binary_logloss: 0.489803\n",
      "[16]\tvalid_0's l2: 0.155512\tvalid_0's binary_logloss: 0.490432\n",
      "[17]\tvalid_0's l2: 0.155124\tvalid_0's binary_logloss: 0.489413\n",
      "[18]\tvalid_0's l2: 0.1551\tvalid_0's binary_logloss: 0.489516\n",
      "[19]\tvalid_0's l2: 0.155098\tvalid_0's binary_logloss: 0.489573\n",
      "---- Train error ----\n",
      "0.14567855449658818\n",
      "---- CV error ----\n",
      "0.15509791377556884\n",
      "---- leaderboard stats ----\n",
      "r2 = -0.0016586867079668721\n",
      "mse = 0.1744041463446064\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.175   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1756  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1812  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1887  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1785  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1818  \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1809  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1865  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.179   \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1783  \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 47.61   \u001b[0m | \u001b[0m 568.1   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.6486  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1903  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1795  \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.09247 \u001b[0m | \u001b[0m 4.982   \u001b[0m | \u001b[0m 180.9   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 25.02   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1767  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1817  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1824  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1873  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1771  \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1783  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1786  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1819  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.17503911598292302, 'params': {'colsample_bytree': 0.964808046408574, 'learning_rate': 0.07011135537053932, 'max_depth': 3.5748633634793223, 'min_child_samples': 48.866452925077546, 'n_estimators': 572.0477787908698, 'num_iteration': 139.33170544688772, 'num_leaves': 29.006406552597404, 'reg_alpha': 0.6531770968715709, 'reg_lambda': 0.7489066375339118, 'subsample': 0.8267849354258676}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=139, num_iteration=139 will be ignored. Current value: num_iterations=139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.173877\tvalid_0's binary_logloss: 0.531817\n",
      "[2]\tvalid_0's l2: 0.173114\tvalid_0's binary_logloss: 0.529704\n",
      "[3]\tvalid_0's l2: 0.172474\tvalid_0's binary_logloss: 0.527879\n",
      "[4]\tvalid_0's l2: 0.170899\tvalid_0's binary_logloss: 0.523513\n",
      "[5]\tvalid_0's l2: 0.170104\tvalid_0's binary_logloss: 0.521236\n",
      "[6]\tvalid_0's l2: 0.170074\tvalid_0's binary_logloss: 0.521093\n",
      "[7]\tvalid_0's l2: 0.169412\tvalid_0's binary_logloss: 0.51915\n",
      "[8]\tvalid_0's l2: 0.169543\tvalid_0's binary_logloss: 0.519538\n",
      "[9]\tvalid_0's l2: 0.168659\tvalid_0's binary_logloss: 0.517078\n",
      "[10]\tvalid_0's l2: 0.168474\tvalid_0's binary_logloss: 0.516376\n",
      "[11]\tvalid_0's l2: 0.167805\tvalid_0's binary_logloss: 0.514487\n",
      "[12]\tvalid_0's l2: 0.168049\tvalid_0's binary_logloss: 0.515171\n",
      "[13]\tvalid_0's l2: 0.167408\tvalid_0's binary_logloss: 0.513402\n",
      "[14]\tvalid_0's l2: 0.16688\tvalid_0's binary_logloss: 0.511694\n",
      "[15]\tvalid_0's l2: 0.167128\tvalid_0's binary_logloss: 0.512342\n",
      "[16]\tvalid_0's l2: 0.167425\tvalid_0's binary_logloss: 0.513105\n",
      "[17]\tvalid_0's l2: 0.166927\tvalid_0's binary_logloss: 0.511614\n",
      "[18]\tvalid_0's l2: 0.16646\tvalid_0's binary_logloss: 0.510225\n",
      "[19]\tvalid_0's l2: 0.166434\tvalid_0's binary_logloss: 0.510103\n",
      "[20]\tvalid_0's l2: 0.165845\tvalid_0's binary_logloss: 0.508353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21]\tvalid_0's l2: 0.166013\tvalid_0's binary_logloss: 0.508923\n",
      "[22]\tvalid_0's l2: 0.165844\tvalid_0's binary_logloss: 0.508501\n",
      "[23]\tvalid_0's l2: 0.165379\tvalid_0's binary_logloss: 0.507209\n",
      "[24]\tvalid_0's l2: 0.165097\tvalid_0's binary_logloss: 0.506417\n",
      "[25]\tvalid_0's l2: 0.164477\tvalid_0's binary_logloss: 0.504406\n",
      "[26]\tvalid_0's l2: 0.164484\tvalid_0's binary_logloss: 0.504459\n",
      "[27]\tvalid_0's l2: 0.164239\tvalid_0's binary_logloss: 0.503586\n",
      "[28]\tvalid_0's l2: 0.164139\tvalid_0's binary_logloss: 0.503463\n",
      "[29]\tvalid_0's l2: 0.163478\tvalid_0's binary_logloss: 0.501912\n",
      "[30]\tvalid_0's l2: 0.163382\tvalid_0's binary_logloss: 0.501567\n",
      "[31]\tvalid_0's l2: 0.163095\tvalid_0's binary_logloss: 0.500856\n",
      "[32]\tvalid_0's l2: 0.162888\tvalid_0's binary_logloss: 0.500089\n",
      "[33]\tvalid_0's l2: 0.162977\tvalid_0's binary_logloss: 0.500418\n",
      "[34]\tvalid_0's l2: 0.162914\tvalid_0's binary_logloss: 0.500221\n",
      "[35]\tvalid_0's l2: 0.163037\tvalid_0's binary_logloss: 0.500608\n",
      "[36]\tvalid_0's l2: 0.163219\tvalid_0's binary_logloss: 0.501208\n",
      "[37]\tvalid_0's l2: 0.162543\tvalid_0's binary_logloss: 0.499378\n",
      "[38]\tvalid_0's l2: 0.163045\tvalid_0's binary_logloss: 0.50042\n",
      "[39]\tvalid_0's l2: 0.163598\tvalid_0's binary_logloss: 0.501764\n",
      "[40]\tvalid_0's l2: 0.163835\tvalid_0's binary_logloss: 0.502323\n",
      "[41]\tvalid_0's l2: 0.163683\tvalid_0's binary_logloss: 0.502018\n",
      "[42]\tvalid_0's l2: 0.16412\tvalid_0's binary_logloss: 0.503202\n",
      "[43]\tvalid_0's l2: 0.16419\tvalid_0's binary_logloss: 0.50342\n",
      "[44]\tvalid_0's l2: 0.164153\tvalid_0's binary_logloss: 0.503338\n",
      "[45]\tvalid_0's l2: 0.16411\tvalid_0's binary_logloss: 0.503207\n",
      "[46]\tvalid_0's l2: 0.164455\tvalid_0's binary_logloss: 0.505406\n",
      "[47]\tvalid_0's l2: 0.164554\tvalid_0's binary_logloss: 0.50533\n",
      "[48]\tvalid_0's l2: 0.164261\tvalid_0's binary_logloss: 0.504569\n",
      "[49]\tvalid_0's l2: 0.164478\tvalid_0's binary_logloss: 0.505153\n",
      "[50]\tvalid_0's l2: 0.16444\tvalid_0's binary_logloss: 0.505155\n",
      "[51]\tvalid_0's l2: 0.163951\tvalid_0's binary_logloss: 0.503813\n",
      "[52]\tvalid_0's l2: 0.163295\tvalid_0's binary_logloss: 0.502166\n",
      "[53]\tvalid_0's l2: 0.163354\tvalid_0's binary_logloss: 0.502371\n",
      "[54]\tvalid_0's l2: 0.163427\tvalid_0's binary_logloss: 0.502474\n",
      "[55]\tvalid_0's l2: 0.163255\tvalid_0's binary_logloss: 0.501996\n",
      "[56]\tvalid_0's l2: 0.163452\tvalid_0's binary_logloss: 0.502545\n",
      "[57]\tvalid_0's l2: 0.163236\tvalid_0's binary_logloss: 0.501964\n",
      "[58]\tvalid_0's l2: 0.164409\tvalid_0's binary_logloss: 0.506264\n",
      "[59]\tvalid_0's l2: 0.164496\tvalid_0's binary_logloss: 0.506631\n",
      "[60]\tvalid_0's l2: 0.163796\tvalid_0's binary_logloss: 0.504732\n",
      "[61]\tvalid_0's l2: 0.165788\tvalid_0's binary_logloss: 0.510708\n",
      "[62]\tvalid_0's l2: 0.165327\tvalid_0's binary_logloss: 0.509268\n",
      "[63]\tvalid_0's l2: 0.165003\tvalid_0's binary_logloss: 0.508168\n",
      "[64]\tvalid_0's l2: 0.16504\tvalid_0's binary_logloss: 0.508272\n",
      "[65]\tvalid_0's l2: 0.164891\tvalid_0's binary_logloss: 0.507995\n",
      "[66]\tvalid_0's l2: 0.164521\tvalid_0's binary_logloss: 0.506882\n",
      "[67]\tvalid_0's l2: 0.164455\tvalid_0's binary_logloss: 0.50631\n",
      "[68]\tvalid_0's l2: 0.164245\tvalid_0's binary_logloss: 0.505428\n",
      "[69]\tvalid_0's l2: 0.164177\tvalid_0's binary_logloss: 0.50529\n",
      "[70]\tvalid_0's l2: 0.164223\tvalid_0's binary_logloss: 0.505429\n",
      "[71]\tvalid_0's l2: 0.164283\tvalid_0's binary_logloss: 0.505663\n",
      "[72]\tvalid_0's l2: 0.163889\tvalid_0's binary_logloss: 0.504607\n",
      "[73]\tvalid_0's l2: 0.163768\tvalid_0's binary_logloss: 0.504144\n",
      "[74]\tvalid_0's l2: 0.16377\tvalid_0's binary_logloss: 0.504185\n",
      "[75]\tvalid_0's l2: 0.163523\tvalid_0's binary_logloss: 0.503545\n",
      "[76]\tvalid_0's l2: 0.163431\tvalid_0's binary_logloss: 0.503315\n",
      "[77]\tvalid_0's l2: 0.163413\tvalid_0's binary_logloss: 0.503315\n",
      "[78]\tvalid_0's l2: 0.163498\tvalid_0's binary_logloss: 0.50359\n",
      "[79]\tvalid_0's l2: 0.163055\tvalid_0's binary_logloss: 0.502163\n",
      "[80]\tvalid_0's l2: 0.163102\tvalid_0's binary_logloss: 0.502127\n",
      "[81]\tvalid_0's l2: 0.163204\tvalid_0's binary_logloss: 0.502436\n",
      "[82]\tvalid_0's l2: 0.163282\tvalid_0's binary_logloss: 0.502502\n",
      "[83]\tvalid_0's l2: 0.16342\tvalid_0's binary_logloss: 0.502976\n",
      "[84]\tvalid_0's l2: 0.163471\tvalid_0's binary_logloss: 0.503148\n",
      "[85]\tvalid_0's l2: 0.16354\tvalid_0's binary_logloss: 0.503414\n",
      "[86]\tvalid_0's l2: 0.163124\tvalid_0's binary_logloss: 0.502122\n",
      "[87]\tvalid_0's l2: 0.162707\tvalid_0's binary_logloss: 0.500809\n",
      "[88]\tvalid_0's l2: 0.162787\tvalid_0's binary_logloss: 0.501107\n",
      "[89]\tvalid_0's l2: 0.162728\tvalid_0's binary_logloss: 0.501004\n",
      "[90]\tvalid_0's l2: 0.162781\tvalid_0's binary_logloss: 0.501198\n",
      "[91]\tvalid_0's l2: 0.16401\tvalid_0's binary_logloss: 0.505242\n",
      "[92]\tvalid_0's l2: 0.163553\tvalid_0's binary_logloss: 0.50387\n",
      "[93]\tvalid_0's l2: 0.163394\tvalid_0's binary_logloss: 0.503217\n",
      "[94]\tvalid_0's l2: 0.163455\tvalid_0's binary_logloss: 0.503493\n",
      "[95]\tvalid_0's l2: 0.16352\tvalid_0's binary_logloss: 0.503718\n",
      "[96]\tvalid_0's l2: 0.163579\tvalid_0's binary_logloss: 0.503904\n",
      "[97]\tvalid_0's l2: 0.16296\tvalid_0's binary_logloss: 0.502129\n",
      "[98]\tvalid_0's l2: 0.163135\tvalid_0's binary_logloss: 0.502621\n",
      "[99]\tvalid_0's l2: 0.1631\tvalid_0's binary_logloss: 0.502308\n",
      "[100]\tvalid_0's l2: 0.162774\tvalid_0's binary_logloss: 0.501329\n",
      "[101]\tvalid_0's l2: 0.163431\tvalid_0's binary_logloss: 0.503479\n",
      "[102]\tvalid_0's l2: 0.163578\tvalid_0's binary_logloss: 0.503912\n",
      "[103]\tvalid_0's l2: 0.163647\tvalid_0's binary_logloss: 0.504185\n",
      "[104]\tvalid_0's l2: 0.16298\tvalid_0's binary_logloss: 0.502428\n",
      "[105]\tvalid_0's l2: 0.163745\tvalid_0's binary_logloss: 0.504773\n",
      "[106]\tvalid_0's l2: 0.163858\tvalid_0's binary_logloss: 0.505139\n",
      "[107]\tvalid_0's l2: 0.164097\tvalid_0's binary_logloss: 0.505839\n",
      "[108]\tvalid_0's l2: 0.16365\tvalid_0's binary_logloss: 0.504477\n",
      "[109]\tvalid_0's l2: 0.163776\tvalid_0's binary_logloss: 0.504871\n",
      "[110]\tvalid_0's l2: 0.163921\tvalid_0's binary_logloss: 0.505312\n",
      "[111]\tvalid_0's l2: 0.163721\tvalid_0's binary_logloss: 0.504544\n",
      "[112]\tvalid_0's l2: 0.163421\tvalid_0's binary_logloss: 0.503517\n",
      "[113]\tvalid_0's l2: 0.163071\tvalid_0's binary_logloss: 0.502531\n",
      "[114]\tvalid_0's l2: 0.16303\tvalid_0's binary_logloss: 0.502173\n",
      "[115]\tvalid_0's l2: 0.162868\tvalid_0's binary_logloss: 0.501696\n",
      "[116]\tvalid_0's l2: 0.162645\tvalid_0's binary_logloss: 0.500934\n",
      "[117]\tvalid_0's l2: 0.162708\tvalid_0's binary_logloss: 0.501178\n",
      "[118]\tvalid_0's l2: 0.162838\tvalid_0's binary_logloss: 0.501181\n",
      "[119]\tvalid_0's l2: 0.162916\tvalid_0's binary_logloss: 0.501444\n",
      "[120]\tvalid_0's l2: 0.162966\tvalid_0's binary_logloss: 0.501647\n",
      "[121]\tvalid_0's l2: 0.163065\tvalid_0's binary_logloss: 0.502001\n",
      "[122]\tvalid_0's l2: 0.16322\tvalid_0's binary_logloss: 0.502451\n",
      "[123]\tvalid_0's l2: 0.163616\tvalid_0's binary_logloss: 0.503067\n",
      "[124]\tvalid_0's l2: 0.162949\tvalid_0's binary_logloss: 0.501137\n",
      "[125]\tvalid_0's l2: 0.162996\tvalid_0's binary_logloss: 0.501341\n",
      "[126]\tvalid_0's l2: 0.163052\tvalid_0's binary_logloss: 0.501546\n",
      "[127]\tvalid_0's l2: 0.16274\tvalid_0's binary_logloss: 0.500564\n",
      "[128]\tvalid_0's l2: 0.162811\tvalid_0's binary_logloss: 0.500826\n",
      "[129]\tvalid_0's l2: 0.162708\tvalid_0's binary_logloss: 0.500299\n",
      "[130]\tvalid_0's l2: 0.162248\tvalid_0's binary_logloss: 0.499105\n",
      "[131]\tvalid_0's l2: 0.162265\tvalid_0's binary_logloss: 0.499251\n",
      "[132]\tvalid_0's l2: 0.162072\tvalid_0's binary_logloss: 0.498554\n",
      "[133]\tvalid_0's l2: 0.161962\tvalid_0's binary_logloss: 0.498132\n",
      "[134]\tvalid_0's l2: 0.162271\tvalid_0's binary_logloss: 0.499315\n",
      "[135]\tvalid_0's l2: 0.162056\tvalid_0's binary_logloss: 0.498443\n",
      "[136]\tvalid_0's l2: 0.162674\tvalid_0's binary_logloss: 0.500523\n",
      "[137]\tvalid_0's l2: 0.16282\tvalid_0's binary_logloss: 0.501004\n",
      "[138]\tvalid_0's l2: 0.162919\tvalid_0's binary_logloss: 0.501077\n",
      "[139]\tvalid_0's l2: 0.162969\tvalid_0's binary_logloss: 0.501014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.173877\tvalid_0's binary_logloss: 0.531817\n",
      "[2]\tvalid_0's l2: 0.173114\tvalid_0's binary_logloss: 0.529704\n",
      "[3]\tvalid_0's l2: 0.172474\tvalid_0's binary_logloss: 0.527879\n",
      "[4]\tvalid_0's l2: 0.170899\tvalid_0's binary_logloss: 0.523513\n",
      "[5]\tvalid_0's l2: 0.170104\tvalid_0's binary_logloss: 0.521236\n",
      "[6]\tvalid_0's l2: 0.170074\tvalid_0's binary_logloss: 0.521093\n",
      "[7]\tvalid_0's l2: 0.169412\tvalid_0's binary_logloss: 0.51915\n",
      "[8]\tvalid_0's l2: 0.169543\tvalid_0's binary_logloss: 0.519538\n",
      "[9]\tvalid_0's l2: 0.168659\tvalid_0's binary_logloss: 0.517078\n",
      "[10]\tvalid_0's l2: 0.168474\tvalid_0's binary_logloss: 0.516376\n",
      "[11]\tvalid_0's l2: 0.167805\tvalid_0's binary_logloss: 0.514487\n",
      "[12]\tvalid_0's l2: 0.168049\tvalid_0's binary_logloss: 0.515171\n",
      "[13]\tvalid_0's l2: 0.167408\tvalid_0's binary_logloss: 0.513402\n",
      "[14]\tvalid_0's l2: 0.16688\tvalid_0's binary_logloss: 0.511694\n",
      "[15]\tvalid_0's l2: 0.167128\tvalid_0's binary_logloss: 0.512342\n",
      "[16]\tvalid_0's l2: 0.167425\tvalid_0's binary_logloss: 0.513105\n",
      "[17]\tvalid_0's l2: 0.166927\tvalid_0's binary_logloss: 0.511614\n",
      "[18]\tvalid_0's l2: 0.16646\tvalid_0's binary_logloss: 0.510225\n",
      "[19]\tvalid_0's l2: 0.166434\tvalid_0's binary_logloss: 0.510103\n",
      "[20]\tvalid_0's l2: 0.165845\tvalid_0's binary_logloss: 0.508353\n",
      "[21]\tvalid_0's l2: 0.166013\tvalid_0's binary_logloss: 0.508923\n",
      "[22]\tvalid_0's l2: 0.165844\tvalid_0's binary_logloss: 0.508501\n",
      "[23]\tvalid_0's l2: 0.165379\tvalid_0's binary_logloss: 0.507209\n",
      "[24]\tvalid_0's l2: 0.165097\tvalid_0's binary_logloss: 0.506417\n",
      "[25]\tvalid_0's l2: 0.164477\tvalid_0's binary_logloss: 0.504406\n",
      "[26]\tvalid_0's l2: 0.164484\tvalid_0's binary_logloss: 0.504459\n",
      "[27]\tvalid_0's l2: 0.164239\tvalid_0's binary_logloss: 0.503586\n",
      "[28]\tvalid_0's l2: 0.164139\tvalid_0's binary_logloss: 0.503463\n",
      "[29]\tvalid_0's l2: 0.163478\tvalid_0's binary_logloss: 0.501912\n",
      "[30]\tvalid_0's l2: 0.163382\tvalid_0's binary_logloss: 0.501567\n",
      "[31]\tvalid_0's l2: 0.163095\tvalid_0's binary_logloss: 0.500856\n",
      "[32]\tvalid_0's l2: 0.162888\tvalid_0's binary_logloss: 0.500089\n",
      "[33]\tvalid_0's l2: 0.162977\tvalid_0's binary_logloss: 0.500418\n",
      "[34]\tvalid_0's l2: 0.162914\tvalid_0's binary_logloss: 0.500221\n",
      "[35]\tvalid_0's l2: 0.163037\tvalid_0's binary_logloss: 0.500608\n",
      "[36]\tvalid_0's l2: 0.163219\tvalid_0's binary_logloss: 0.501208\n",
      "[37]\tvalid_0's l2: 0.162543\tvalid_0's binary_logloss: 0.499378\n",
      "[38]\tvalid_0's l2: 0.163045\tvalid_0's binary_logloss: 0.50042\n",
      "[39]\tvalid_0's l2: 0.163598\tvalid_0's binary_logloss: 0.501764\n",
      "[40]\tvalid_0's l2: 0.163835\tvalid_0's binary_logloss: 0.502323\n",
      "[41]\tvalid_0's l2: 0.163683\tvalid_0's binary_logloss: 0.502018\n",
      "[42]\tvalid_0's l2: 0.16412\tvalid_0's binary_logloss: 0.503202\n",
      "[43]\tvalid_0's l2: 0.16419\tvalid_0's binary_logloss: 0.50342\n",
      "[44]\tvalid_0's l2: 0.164153\tvalid_0's binary_logloss: 0.503338\n",
      "[45]\tvalid_0's l2: 0.16411\tvalid_0's binary_logloss: 0.503207\n",
      "[46]\tvalid_0's l2: 0.164455\tvalid_0's binary_logloss: 0.505406\n",
      "[47]\tvalid_0's l2: 0.164554\tvalid_0's binary_logloss: 0.50533\n",
      "[48]\tvalid_0's l2: 0.164261\tvalid_0's binary_logloss: 0.504569\n",
      "[49]\tvalid_0's l2: 0.164478\tvalid_0's binary_logloss: 0.505153\n",
      "[50]\tvalid_0's l2: 0.16444\tvalid_0's binary_logloss: 0.505155\n",
      "[51]\tvalid_0's l2: 0.163951\tvalid_0's binary_logloss: 0.503813\n",
      "[52]\tvalid_0's l2: 0.163295\tvalid_0's binary_logloss: 0.502166\n",
      "[53]\tvalid_0's l2: 0.163354\tvalid_0's binary_logloss: 0.502371\n",
      "[54]\tvalid_0's l2: 0.163427\tvalid_0's binary_logloss: 0.502474\n",
      "[55]\tvalid_0's l2: 0.163255\tvalid_0's binary_logloss: 0.501996\n",
      "[56]\tvalid_0's l2: 0.163452\tvalid_0's binary_logloss: 0.502545\n",
      "[57]\tvalid_0's l2: 0.163236\tvalid_0's binary_logloss: 0.501964\n",
      "[58]\tvalid_0's l2: 0.164409\tvalid_0's binary_logloss: 0.506264\n",
      "[59]\tvalid_0's l2: 0.164496\tvalid_0's binary_logloss: 0.506631\n",
      "[60]\tvalid_0's l2: 0.163796\tvalid_0's binary_logloss: 0.504732\n",
      "[61]\tvalid_0's l2: 0.165788\tvalid_0's binary_logloss: 0.510708\n",
      "[62]\tvalid_0's l2: 0.165327\tvalid_0's binary_logloss: 0.509268\n",
      "[63]\tvalid_0's l2: 0.165003\tvalid_0's binary_logloss: 0.508168\n",
      "[64]\tvalid_0's l2: 0.16504\tvalid_0's binary_logloss: 0.508272\n",
      "[65]\tvalid_0's l2: 0.164891\tvalid_0's binary_logloss: 0.507995\n",
      "[66]\tvalid_0's l2: 0.164521\tvalid_0's binary_logloss: 0.506882\n",
      "[67]\tvalid_0's l2: 0.164455\tvalid_0's binary_logloss: 0.50631\n",
      "[68]\tvalid_0's l2: 0.164245\tvalid_0's binary_logloss: 0.505428\n",
      "[69]\tvalid_0's l2: 0.164177\tvalid_0's binary_logloss: 0.50529\n",
      "[70]\tvalid_0's l2: 0.164223\tvalid_0's binary_logloss: 0.505429\n",
      "[71]\tvalid_0's l2: 0.164283\tvalid_0's binary_logloss: 0.505663\n",
      "[72]\tvalid_0's l2: 0.163889\tvalid_0's binary_logloss: 0.504607\n",
      "[73]\tvalid_0's l2: 0.163768\tvalid_0's binary_logloss: 0.504144\n",
      "[74]\tvalid_0's l2: 0.16377\tvalid_0's binary_logloss: 0.504185\n",
      "[75]\tvalid_0's l2: 0.163523\tvalid_0's binary_logloss: 0.503545\n",
      "[76]\tvalid_0's l2: 0.163431\tvalid_0's binary_logloss: 0.503315\n",
      "[77]\tvalid_0's l2: 0.163413\tvalid_0's binary_logloss: 0.503315\n",
      "[78]\tvalid_0's l2: 0.163498\tvalid_0's binary_logloss: 0.50359\n",
      "[79]\tvalid_0's l2: 0.163055\tvalid_0's binary_logloss: 0.502163\n",
      "[80]\tvalid_0's l2: 0.163102\tvalid_0's binary_logloss: 0.502127\n",
      "[81]\tvalid_0's l2: 0.163204\tvalid_0's binary_logloss: 0.502436\n",
      "[82]\tvalid_0's l2: 0.163282\tvalid_0's binary_logloss: 0.502502\n",
      "[83]\tvalid_0's l2: 0.16342\tvalid_0's binary_logloss: 0.502976\n",
      "[84]\tvalid_0's l2: 0.163471\tvalid_0's binary_logloss: 0.503148\n",
      "[85]\tvalid_0's l2: 0.16354\tvalid_0's binary_logloss: 0.503414\n",
      "[86]\tvalid_0's l2: 0.163124\tvalid_0's binary_logloss: 0.502122\n",
      "[87]\tvalid_0's l2: 0.162707\tvalid_0's binary_logloss: 0.500809\n",
      "[88]\tvalid_0's l2: 0.162787\tvalid_0's binary_logloss: 0.501107\n",
      "[89]\tvalid_0's l2: 0.162728\tvalid_0's binary_logloss: 0.501004\n",
      "[90]\tvalid_0's l2: 0.162781\tvalid_0's binary_logloss: 0.501198\n",
      "[91]\tvalid_0's l2: 0.16401\tvalid_0's binary_logloss: 0.505242\n",
      "[92]\tvalid_0's l2: 0.163553\tvalid_0's binary_logloss: 0.50387\n",
      "[93]\tvalid_0's l2: 0.163394\tvalid_0's binary_logloss: 0.503217\n",
      "[94]\tvalid_0's l2: 0.163455\tvalid_0's binary_logloss: 0.503493\n",
      "[95]\tvalid_0's l2: 0.16352\tvalid_0's binary_logloss: 0.503718\n",
      "[96]\tvalid_0's l2: 0.163579\tvalid_0's binary_logloss: 0.503904\n",
      "[97]\tvalid_0's l2: 0.16296\tvalid_0's binary_logloss: 0.502129\n",
      "[98]\tvalid_0's l2: 0.163135\tvalid_0's binary_logloss: 0.502621\n",
      "[99]\tvalid_0's l2: 0.1631\tvalid_0's binary_logloss: 0.502308\n",
      "[100]\tvalid_0's l2: 0.162774\tvalid_0's binary_logloss: 0.501329\n",
      "[101]\tvalid_0's l2: 0.163431\tvalid_0's binary_logloss: 0.503479\n",
      "[102]\tvalid_0's l2: 0.163578\tvalid_0's binary_logloss: 0.503912\n",
      "[103]\tvalid_0's l2: 0.163647\tvalid_0's binary_logloss: 0.504185\n",
      "[104]\tvalid_0's l2: 0.16298\tvalid_0's binary_logloss: 0.502428\n",
      "[105]\tvalid_0's l2: 0.163745\tvalid_0's binary_logloss: 0.504773\n",
      "[106]\tvalid_0's l2: 0.163858\tvalid_0's binary_logloss: 0.505139\n",
      "[107]\tvalid_0's l2: 0.164097\tvalid_0's binary_logloss: 0.505839\n",
      "[108]\tvalid_0's l2: 0.16365\tvalid_0's binary_logloss: 0.504477\n",
      "[109]\tvalid_0's l2: 0.163776\tvalid_0's binary_logloss: 0.504871\n",
      "[110]\tvalid_0's l2: 0.163921\tvalid_0's binary_logloss: 0.505312\n",
      "[111]\tvalid_0's l2: 0.163721\tvalid_0's binary_logloss: 0.504544\n",
      "[112]\tvalid_0's l2: 0.163421\tvalid_0's binary_logloss: 0.503517\n",
      "[113]\tvalid_0's l2: 0.163071\tvalid_0's binary_logloss: 0.502531\n",
      "[114]\tvalid_0's l2: 0.16303\tvalid_0's binary_logloss: 0.502173\n",
      "[115]\tvalid_0's l2: 0.162868\tvalid_0's binary_logloss: 0.501696\n",
      "[116]\tvalid_0's l2: 0.162645\tvalid_0's binary_logloss: 0.500934\n",
      "[117]\tvalid_0's l2: 0.162708\tvalid_0's binary_logloss: 0.501178\n",
      "[118]\tvalid_0's l2: 0.162838\tvalid_0's binary_logloss: 0.501181\n",
      "[119]\tvalid_0's l2: 0.162916\tvalid_0's binary_logloss: 0.501444\n",
      "[120]\tvalid_0's l2: 0.162966\tvalid_0's binary_logloss: 0.501647\n",
      "[121]\tvalid_0's l2: 0.163065\tvalid_0's binary_logloss: 0.502001\n",
      "[122]\tvalid_0's l2: 0.16322\tvalid_0's binary_logloss: 0.502451\n",
      "[123]\tvalid_0's l2: 0.163616\tvalid_0's binary_logloss: 0.503067\n",
      "[124]\tvalid_0's l2: 0.162949\tvalid_0's binary_logloss: 0.501137\n",
      "[125]\tvalid_0's l2: 0.162996\tvalid_0's binary_logloss: 0.501341\n",
      "[126]\tvalid_0's l2: 0.163052\tvalid_0's binary_logloss: 0.501546\n",
      "[127]\tvalid_0's l2: 0.16274\tvalid_0's binary_logloss: 0.500564\n",
      "[128]\tvalid_0's l2: 0.162811\tvalid_0's binary_logloss: 0.500826\n",
      "[129]\tvalid_0's l2: 0.162708\tvalid_0's binary_logloss: 0.500299\n",
      "[130]\tvalid_0's l2: 0.162248\tvalid_0's binary_logloss: 0.499105\n",
      "[131]\tvalid_0's l2: 0.162265\tvalid_0's binary_logloss: 0.499251\n",
      "[132]\tvalid_0's l2: 0.162072\tvalid_0's binary_logloss: 0.498554\n",
      "[133]\tvalid_0's l2: 0.161962\tvalid_0's binary_logloss: 0.498132\n",
      "---- Train error ----\n",
      "0.11686071867672544\n",
      "---- CV error ----\n",
      "0.16196207772904056\n",
      "---- leaderboard stats ----\n",
      "r2 = -0.019217971116992638\n",
      "mse = 0.20428263080049058\n",
      "0:03:04.508430\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "-------------  goss  --------------\n",
      "\n",
      "\n",
      "gpa\n",
      "gpa\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.3976691  -0.40116173 -0.39870659 -0.36244035 -0.39014261 -0.40803591]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.393   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.44435827 -0.43344554 -0.44788621 -0.45761544 -0.47117077 -0.45398814]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.4514  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.41834766 -0.38773095 -0.43189722 -0.40480805 -0.42081933 -0.43445737]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4163  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.51087787 -0.45380079 -0.44089974 -0.42125528 -0.44903555 -0.43894387]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.4525  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.42811743 -0.38591205 -0.41063587 -0.37949866 -0.44669742 -0.40470114]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.4093  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.38908795 -0.37835469 -0.37937155 -0.35722314 -0.38771327 -0.3865206 ]\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.3797  \u001b[0m | \u001b[95m 0.7442  \u001b[0m | \u001b[95m 0.01505 \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 68.61   \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 160.3   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.1119  \u001b[0m | \u001b[95m 0.7041  \u001b[0m |\n",
      "[-0.38666359 -0.38684774 -0.36933745 -0.36218065 -0.382831   -0.39278656]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.3801  \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.04858 \u001b[0m | \u001b[0m 9.909   \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 19.13   \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 0.9892  \u001b[0m |\n",
      "[-0.40460472 -0.38760031 -0.36212444 -0.36845171 -0.39690408 -0.39421306]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.3856  \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.06236 \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 79.94   \u001b[0m | \u001b[0m 436.5   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 6.845   \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 0.2771  \u001b[0m | \u001b[0m 0.9741  \u001b[0m |\n",
      "[-0.38648403 -0.3823815  -0.37940882 -0.36065967 -0.38640287 -0.39147464]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3811  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 65.9    \u001b[0m | \u001b[0m 448.7   \u001b[0m | \u001b[0m 176.2   \u001b[0m | \u001b[0m 8.92    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[-0.44403703 -0.46515765 -0.43272239 -0.41569854 -0.47664068 -0.4496246 ]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.4473  \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.1883  \u001b[0m | \u001b[0m 7.909   \u001b[0m | \u001b[0m 57.44   \u001b[0m | \u001b[0m 422.8   \u001b[0m | \u001b[0m 165.6   \u001b[0m | \u001b[0m 2.132   \u001b[0m | \u001b[0m 0.8054  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 0.7791  \u001b[0m |\n",
      "[-0.38474932 -0.37668294 -0.36675126 -0.34798111 -0.38414178 -0.38616543]\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.3744  \u001b[0m | \u001b[95m 0.962   \u001b[0m | \u001b[95m 0.03949 \u001b[0m | \u001b[95m 4.624   \u001b[0m | \u001b[95m 77.14   \u001b[0m | \u001b[95m 465.8   \u001b[0m | \u001b[95m 167.0   \u001b[0m | \u001b[95m 5.159   \u001b[0m | \u001b[95m 0.9421  \u001b[0m | \u001b[95m 0.8712  \u001b[0m | \u001b[95m 0.6366  \u001b[0m |\n",
      "[-0.38760798 -0.37283467 -0.37279956 -0.35284132 -0.37288621 -0.39966934]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.3764  \u001b[0m | \u001b[0m 0.7052  \u001b[0m | \u001b[0m 0.05524 \u001b[0m | \u001b[0m 6.119   \u001b[0m | \u001b[0m 69.97   \u001b[0m | \u001b[0m 454.0   \u001b[0m | \u001b[0m 152.7   \u001b[0m | \u001b[0m 2.41    \u001b[0m | \u001b[0m 0.4243  \u001b[0m | \u001b[0m 0.1717  \u001b[0m | \u001b[0m 0.7438  \u001b[0m |\n",
      "[-0.47544902 -0.47032937 -0.44292463 -0.4698285  -0.42875434 -0.46785709]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.4592  \u001b[0m | \u001b[0m 0.5183  \u001b[0m | \u001b[0m 0.1887  \u001b[0m | \u001b[0m 13.68   \u001b[0m | \u001b[0m 57.54   \u001b[0m | \u001b[0m 474.7   \u001b[0m | \u001b[0m 174.0   \u001b[0m | \u001b[0m 2.619   \u001b[0m | \u001b[0m 0.2793  \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 0.9805  \u001b[0m |\n",
      "[-0.40792007 -0.40943551 -0.38216408 -0.36191038 -0.4001412  -0.40409765]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.3943  \u001b[0m | \u001b[0m 0.9436  \u001b[0m | \u001b[0m 0.08959 \u001b[0m | \u001b[0m 13.43   \u001b[0m | \u001b[0m 86.92   \u001b[0m | \u001b[0m 453.4   \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 4.065   \u001b[0m | \u001b[0m 0.9037  \u001b[0m | \u001b[0m 0.04633 \u001b[0m | \u001b[0m 0.9555  \u001b[0m |\n",
      "[-0.45259768 -0.42765282 -0.39349123 -0.38379918 -0.4126238  -0.43747057]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.4179  \u001b[0m | \u001b[0m 0.9732  \u001b[0m | \u001b[0m 0.1198  \u001b[0m | \u001b[0m 10.02   \u001b[0m | \u001b[0m 84.88   \u001b[0m | \u001b[0m 447.5   \u001b[0m | \u001b[0m 183.4   \u001b[0m | \u001b[0m 2.234   \u001b[0m | \u001b[0m 0.1456  \u001b[0m | \u001b[0m 0.3378  \u001b[0m | \u001b[0m 0.6701  \u001b[0m |\n",
      "[-0.39260702 -0.3793545  -0.3717424  -0.36094366 -0.377872   -0.39241103]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.3792  \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 0.05335 \u001b[0m | \u001b[0m 1.505   \u001b[0m | \u001b[0m 79.72   \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 172.0   \u001b[0m | \u001b[0m 11.0    \u001b[0m | \u001b[0m 0.8687  \u001b[0m | \u001b[0m 0.0419  \u001b[0m | \u001b[0m 0.9727  \u001b[0m |\n",
      "[-0.40539174 -0.39354122 -0.39698482 -0.37784252 -0.40128462 -0.41418599]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3982  \u001b[0m | \u001b[0m 0.9462  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 81.37   \u001b[0m | \u001b[0m 464.4   \u001b[0m | \u001b[0m 152.7   \u001b[0m | \u001b[0m 12.28   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.8215  \u001b[0m |\n",
      "[-0.44142702 -0.45038282 -0.41169393 -0.41742972 -0.43033055 -0.48658155]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.4396  \u001b[0m | \u001b[0m 0.6852  \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 6.255   \u001b[0m | \u001b[0m 68.04   \u001b[0m | \u001b[0m 451.8   \u001b[0m | \u001b[0m 163.7   \u001b[0m | \u001b[0m 3.347   \u001b[0m | \u001b[0m 0.6337  \u001b[0m | \u001b[0m 0.02034 \u001b[0m | \u001b[0m 0.9837  \u001b[0m |\n",
      "[-0.41432794 -0.41457589 -0.39469147 -0.38541982 -0.3941588  -0.43082548]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.4057  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.1216  \u001b[0m | \u001b[0m 8.44    \u001b[0m | \u001b[0m 71.61   \u001b[0m | \u001b[0m 436.4   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 10.11   \u001b[0m | \u001b[0m 0.9001  \u001b[0m | \u001b[0m 0.5545  \u001b[0m | \u001b[0m 0.7974  \u001b[0m |\n",
      "[-0.45408328 -0.44962889 -0.38387408 -0.40572793 -0.43793489 -0.49203089]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.4372  \u001b[0m | \u001b[0m 0.6689  \u001b[0m | \u001b[0m 0.1731  \u001b[0m | \u001b[0m 10.73   \u001b[0m | \u001b[0m 78.02   \u001b[0m | \u001b[0m 447.6   \u001b[0m | \u001b[0m 171.1   \u001b[0m | \u001b[0m 15.54   \u001b[0m | \u001b[0m 0.1422  \u001b[0m | \u001b[0m 0.09532 \u001b[0m | \u001b[0m 0.8199  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.37441197346252447, 'params': {'colsample_bytree': 0.9620326142543789, 'learning_rate': 0.03948887328556474, 'max_depth': 4.62356709651877, 'min_child_samples': 77.13612923100344, 'n_estimators': 465.8040840524198, 'num_iteration': 166.95742170170405, 'num_leaves': 5.159433520144974, 'reg_alpha': 0.9420815721157043, 'reg_lambda': 0.871198189194913, 'subsample': 0.6365667271179661}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=166, num_iteration=166 will be ignored. Current value: num_iterations=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.420708\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.418022\n",
      "[3]\tvalid_0's l2: 0.416569\n",
      "[4]\tvalid_0's l2: 0.414601\n",
      "[5]\tvalid_0's l2: 0.412847\n",
      "[6]\tvalid_0's l2: 0.411363\n",
      "[7]\tvalid_0's l2: 0.409183\n",
      "[8]\tvalid_0's l2: 0.406925\n",
      "[9]\tvalid_0's l2: 0.405582\n",
      "[10]\tvalid_0's l2: 0.404682\n",
      "[11]\tvalid_0's l2: 0.401082\n",
      "[12]\tvalid_0's l2: 0.39888\n",
      "[13]\tvalid_0's l2: 0.39748\n",
      "[14]\tvalid_0's l2: 0.396215\n",
      "[15]\tvalid_0's l2: 0.394785\n",
      "[16]\tvalid_0's l2: 0.393334\n",
      "[17]\tvalid_0's l2: 0.392512\n",
      "[18]\tvalid_0's l2: 0.391882\n",
      "[19]\tvalid_0's l2: 0.39091\n",
      "[20]\tvalid_0's l2: 0.389618\n",
      "[21]\tvalid_0's l2: 0.388983\n",
      "[22]\tvalid_0's l2: 0.389326\n",
      "[23]\tvalid_0's l2: 0.387991\n",
      "[24]\tvalid_0's l2: 0.38726\n",
      "[25]\tvalid_0's l2: 0.385938\n",
      "[26]\tvalid_0's l2: 0.385838\n",
      "[27]\tvalid_0's l2: 0.384542\n",
      "[28]\tvalid_0's l2: 0.384301\n",
      "[29]\tvalid_0's l2: 0.383884\n",
      "[30]\tvalid_0's l2: 0.383822\n",
      "[31]\tvalid_0's l2: 0.384153\n",
      "[32]\tvalid_0's l2: 0.384463\n",
      "[33]\tvalid_0's l2: 0.385447\n",
      "[34]\tvalid_0's l2: 0.38622\n",
      "[35]\tvalid_0's l2: 0.386478\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l2: 0.383822\n",
      "---- Train error ----\n",
      "0.34772152601084727\n",
      "---- CV error ----\n",
      "0.3838216020758512\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.05005244833677269\n",
      "mse = 0.3710648078690564\n",
      "grit\n",
      "grit\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.24688788 -0.22606532 -0.28285275 -0.25367913 -0.25119979 -0.22647734]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2479  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.28617382 -0.26126695 -0.30423859 -0.27721227 -0.29258025 -0.26580369]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2812  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.25839392 -0.23663733 -0.29217956 -0.25311249 -0.26302617 -0.25167535]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2592  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.27342409 -0.24909713 -0.33036955 -0.26793706 -0.27389151 -0.27917781]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.279   \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.24124105 -0.2373259  -0.28393636 -0.26289167 -0.25605231 -0.23483067]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2527  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.22296582 -0.21458338 -0.2750584  -0.24009765 -0.25195036 -0.21348476]\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.2364  \u001b[0m | \u001b[95m 0.7442  \u001b[0m | \u001b[95m 0.01505 \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 68.61   \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 160.3   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.1119  \u001b[0m | \u001b[95m 0.7041  \u001b[0m |\n",
      "[-0.22722488 -0.21323554 -0.27544052 -0.23679866 -0.25044485 -0.21901839]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.237   \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.04858 \u001b[0m | \u001b[0m 9.909   \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 19.13   \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 0.9892  \u001b[0m |\n",
      "[-0.23798752 -0.2113934  -0.27685872 -0.23670364 -0.25765651 -0.22089382]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2402  \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.06236 \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 79.94   \u001b[0m | \u001b[0m 436.5   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 6.845   \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 0.2771  \u001b[0m | \u001b[0m 0.9741  \u001b[0m |\n",
      "[-0.22237671 -0.2112503  -0.2765797  -0.24044216 -0.2503203  -0.21512683]\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.236   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 15.0    \u001b[0m | \u001b[95m 65.65   \u001b[0m | \u001b[95m 448.3   \u001b[0m | \u001b[95m 175.2   \u001b[0m | \u001b[95m 8.671   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "[-0.2632301  -0.26744187 -0.3057908  -0.28237223 -0.28883168 -0.24148732]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2749  \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.1883  \u001b[0m | \u001b[0m 7.909   \u001b[0m | \u001b[0m 57.44   \u001b[0m | \u001b[0m 422.8   \u001b[0m | \u001b[0m 165.6   \u001b[0m | \u001b[0m 2.132   \u001b[0m | \u001b[0m 0.8054  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 0.7791  \u001b[0m |\n",
      "[-0.22732356 -0.21420931 -0.27214843 -0.2386904  -0.25074646 -0.2171373 ]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2367  \u001b[0m | \u001b[0m 0.962   \u001b[0m | \u001b[0m 0.03949 \u001b[0m | \u001b[0m 4.624   \u001b[0m | \u001b[0m 77.14   \u001b[0m | \u001b[0m 465.8   \u001b[0m | \u001b[0m 167.0   \u001b[0m | \u001b[0m 5.159   \u001b[0m | \u001b[0m 0.9421  \u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 0.6366  \u001b[0m |\n",
      "[-0.22613351 -0.21170085 -0.26939012 -0.24171307 -0.25786221 -0.21353623]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2367  \u001b[0m | \u001b[0m 0.7052  \u001b[0m | \u001b[0m 0.05524 \u001b[0m | \u001b[0m 6.119   \u001b[0m | \u001b[0m 69.97   \u001b[0m | \u001b[0m 454.0   \u001b[0m | \u001b[0m 152.7   \u001b[0m | \u001b[0m 2.41    \u001b[0m | \u001b[0m 0.4243  \u001b[0m | \u001b[0m 0.1717  \u001b[0m | \u001b[0m 0.7438  \u001b[0m |\n",
      "[-0.22407097 -0.21372842 -0.27141412 -0.24042611 -0.24891754 -0.21540734]\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.2357  \u001b[0m | \u001b[95m 0.6588  \u001b[0m | \u001b[95m 0.02517 \u001b[0m | \u001b[95m 1.946   \u001b[0m | \u001b[95m 85.09   \u001b[0m | \u001b[95m 452.3   \u001b[0m | \u001b[95m 192.3   \u001b[0m | \u001b[95m 10.51   \u001b[0m | \u001b[95m 0.2986  \u001b[0m | \u001b[95m 0.8513  \u001b[0m | \u001b[95m 0.855   \u001b[0m |\n",
      "[-0.222874   -0.21284125 -0.27767275 -0.23979558 -0.25095581 -0.21309871]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2362  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 75.07   \u001b[0m | \u001b[0m 471.2   \u001b[0m | \u001b[0m 193.2   \u001b[0m | \u001b[0m 6.969   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.501   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[-0.22401394 -0.21432139 -0.27815159 -0.24305599 -0.25139212 -0.21727419]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.238   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 98.99   \u001b[0m | \u001b[0m 460.3   \u001b[0m | \u001b[0m 179.6   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[-0.24439501 -0.22292397 -0.28550982 -0.24373606 -0.26163068 -0.22648431]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2474  \u001b[0m | \u001b[0m 0.5532  \u001b[0m | \u001b[0m 0.122   \u001b[0m | \u001b[0m 13.75   \u001b[0m | \u001b[0m 100.7   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 193.1   \u001b[0m | \u001b[0m 19.28   \u001b[0m | \u001b[0m 0.6635  \u001b[0m | \u001b[0m 0.4039  \u001b[0m | \u001b[0m 0.8185  \u001b[0m |\n",
      "[-0.29742547 -0.26957356 -0.34311166 -0.29257665 -0.32462762 -0.29936201]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3044  \u001b[0m | \u001b[0m 0.5059  \u001b[0m | \u001b[0m 0.1986  \u001b[0m | \u001b[0m 3.736   \u001b[0m | \u001b[0m 55.84   \u001b[0m | \u001b[0m 479.3   \u001b[0m | \u001b[0m 190.8   \u001b[0m | \u001b[0m 17.58   \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 0.05597 \u001b[0m | \u001b[0m 0.642   \u001b[0m |\n",
      "[-0.2399805  -0.2140723  -0.28337183 -0.23956866 -0.26050855 -0.22864782]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2444  \u001b[0m | \u001b[0m 0.5779  \u001b[0m | \u001b[0m 0.1054  \u001b[0m | \u001b[0m 8.882   \u001b[0m | \u001b[0m 99.25   \u001b[0m | \u001b[0m 441.4   \u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 4.56    \u001b[0m | \u001b[0m 0.522   \u001b[0m | \u001b[0m 0.1307  \u001b[0m | \u001b[0m 0.9618  \u001b[0m |\n",
      "[-0.22438342 -0.21516382 -0.27810073 -0.24434672 -0.25076685 -0.21695359]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2383  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 107.9   \u001b[0m | \u001b[0m 436.8   \u001b[0m | \u001b[0m 183.0   \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[-0.26980498 -0.23893553 -0.2919907  -0.25329512 -0.27578705 -0.25232565]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2637  \u001b[0m | \u001b[0m 0.8786  \u001b[0m | \u001b[0m 0.1765  \u001b[0m | \u001b[0m 11.81   \u001b[0m | \u001b[0m 91.08   \u001b[0m | \u001b[0m 431.5   \u001b[0m | \u001b[0m 198.3   \u001b[0m | \u001b[0m 8.982   \u001b[0m | \u001b[0m 0.9978  \u001b[0m | \u001b[0m 0.3281  \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.23566075131539044, 'params': {'colsample_bytree': 0.6588001148821923, 'learning_rate': 0.02516994111866326, 'max_depth': 1.945880183531221, 'min_child_samples': 85.08845115088026, 'n_estimators': 452.2549399490873, 'num_iteration': 192.26382477726418, 'num_leaves': 10.512505204813257, 'reg_alpha': 0.2986315609394449, 'reg_lambda': 0.8513010128708631, 'subsample': 0.8550315389886611}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=192, num_iteration=192 will be ignored. Current value: num_iterations=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.213202\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.213091\n",
      "[3]\tvalid_0's l2: 0.212989\n",
      "[4]\tvalid_0's l2: 0.213006\n",
      "[5]\tvalid_0's l2: 0.212915\n",
      "[6]\tvalid_0's l2: 0.212832\n",
      "[7]\tvalid_0's l2: 0.212758\n",
      "[8]\tvalid_0's l2: 0.212692\n",
      "[9]\tvalid_0's l2: 0.212479\n",
      "[10]\tvalid_0's l2: 0.212422\n",
      "[11]\tvalid_0's l2: 0.212338\n",
      "[12]\tvalid_0's l2: 0.212289\n",
      "[13]\tvalid_0's l2: 0.212314\n",
      "[14]\tvalid_0's l2: 0.212132\n",
      "[15]\tvalid_0's l2: 0.212056\n",
      "[16]\tvalid_0's l2: 0.21201\n",
      "[17]\tvalid_0's l2: 0.212085\n",
      "[18]\tvalid_0's l2: 0.212044\n",
      "[19]\tvalid_0's l2: 0.211871\n",
      "[20]\tvalid_0's l2: 0.211904\n",
      "[21]\tvalid_0's l2: 0.211722\n",
      "[22]\tvalid_0's l2: 0.211493\n",
      "[23]\tvalid_0's l2: 0.21133\n",
      "[24]\tvalid_0's l2: 0.211266\n",
      "[25]\tvalid_0's l2: 0.211148\n",
      "[26]\tvalid_0's l2: 0.211115\n",
      "[27]\tvalid_0's l2: 0.211152\n",
      "[28]\tvalid_0's l2: 0.211122\n",
      "[29]\tvalid_0's l2: 0.210907\n",
      "[30]\tvalid_0's l2: 0.210797\n",
      "[31]\tvalid_0's l2: 0.210649\n",
      "[32]\tvalid_0's l2: 0.210481\n",
      "[33]\tvalid_0's l2: 0.210441\n",
      "[34]\tvalid_0's l2: 0.210487\n",
      "[35]\tvalid_0's l2: 0.210567\n",
      "[36]\tvalid_0's l2: 0.210544\n",
      "[37]\tvalid_0's l2: 0.210403\n",
      "[38]\tvalid_0's l2: 0.210299\n",
      "[39]\tvalid_0's l2: 0.210278\n",
      "[40]\tvalid_0's l2: 0.210322\n",
      "[41]\tvalid_0's l2: 0.210298\n",
      "[42]\tvalid_0's l2: 0.210205\n",
      "[43]\tvalid_0's l2: 0.210329\n",
      "[44]\tvalid_0's l2: 0.210184\n",
      "[45]\tvalid_0's l2: 0.210014\n",
      "[46]\tvalid_0's l2: 0.209713\n",
      "[47]\tvalid_0's l2: 0.209789\n",
      "[48]\tvalid_0's l2: 0.209746\n",
      "[49]\tvalid_0's l2: 0.209504\n",
      "[50]\tvalid_0's l2: 0.209505\n",
      "[51]\tvalid_0's l2: 0.209557\n",
      "[52]\tvalid_0's l2: 0.209632\n",
      "[53]\tvalid_0's l2: 0.209325\n",
      "[54]\tvalid_0's l2: 0.209214\n",
      "[55]\tvalid_0's l2: 0.209262\n",
      "[56]\tvalid_0's l2: 0.209419\n",
      "[57]\tvalid_0's l2: 0.209296\n",
      "[58]\tvalid_0's l2: 0.209378\n",
      "[59]\tvalid_0's l2: 0.20932\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 0.209214\n",
      "---- Train error ----\n",
      "0.2302070443946643\n",
      "---- CV error ----\n",
      "0.20921434875432324\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.01432418459858309\n",
      "mse = 0.21659011055012237\n",
      "materialHardship\n",
      "materialHardship\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[-0.02171457 -0.0186889  -0.02348887 -0.0219455  -0.02299788 -0.02109164]\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.02165 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "[-0.02316263 -0.02222369 -0.02440846 -0.02394801 -0.02496046 -0.02192632]\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.02344 \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "[-0.02370099 -0.02055873 -0.0245287  -0.02346755 -0.02416043 -0.02327833]\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.02328 \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "[-0.02647416 -0.02439113 -0.02707062 -0.02704297 -0.02494807 -0.0230144 ]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.02549 \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "[-0.02159818 -0.02035662 -0.02520123 -0.02331455 -0.02345035 -0.02198687]\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.02265 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "[-0.02217538 -0.01839977 -0.02306871 -0.02122699 -0.02351929 -0.02047291]\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.02148 \u001b[0m | \u001b[95m 0.7442  \u001b[0m | \u001b[95m 0.01505 \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 68.61   \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 160.3   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.1119  \u001b[0m | \u001b[95m 0.7041  \u001b[0m |\n",
      "[-0.02136559 -0.01919118 -0.02332856 -0.02135293 -0.02270004 -0.02058113]\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.02142 \u001b[0m | \u001b[95m 0.6788  \u001b[0m | \u001b[95m 0.04858 \u001b[0m | \u001b[95m 9.909   \u001b[0m | \u001b[95m 73.5    \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 162.8   \u001b[0m | \u001b[95m 19.13   \u001b[0m | \u001b[95m 0.265   \u001b[0m | \u001b[95m 0.8081  \u001b[0m | \u001b[95m 0.9892  \u001b[0m |\n",
      "[-0.02196602 -0.01883522 -0.02367697 -0.02205617 -0.02350353 -0.02051498]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.02176 \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.06236 \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 79.94   \u001b[0m | \u001b[0m 436.5   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 6.845   \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 0.2771  \u001b[0m | \u001b[0m 0.9741  \u001b[0m |\n",
      "[-0.02241289 -0.01847144 -0.02330725 -0.02137994 -0.02347861 -0.0204639 ]\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.02159 \u001b[0m | \u001b[0m 0.8154  \u001b[0m | \u001b[0m 0.01901 \u001b[0m | \u001b[0m 14.01   \u001b[0m | \u001b[0m 72.7    \u001b[0m | \u001b[0m 453.8   \u001b[0m | \u001b[0m 156.1   \u001b[0m | \u001b[0m 3.498   \u001b[0m | \u001b[0m 0.8236  \u001b[0m | \u001b[0m 0.148   \u001b[0m | \u001b[0m 0.6023  \u001b[0m |\n",
      "[-0.0218605  -0.01932052 -0.02408751 -0.02186596 -0.02315629 -0.02107249]\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.02189 \u001b[0m | \u001b[0m 0.783   \u001b[0m | \u001b[0m 0.08193 \u001b[0m | \u001b[0m 6.531   \u001b[0m | \u001b[0m 74.54   \u001b[0m | \u001b[0m 457.5   \u001b[0m | \u001b[0m 172.1   \u001b[0m | \u001b[0m 6.917   \u001b[0m | \u001b[0m 0.9813  \u001b[0m | \u001b[0m 0.352   \u001b[0m | \u001b[0m 0.9402  \u001b[0m |\n",
      "[-0.02251262 -0.01914592 -0.02316556 -0.0224514  -0.02343562 -0.02074982]\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.02191 \u001b[0m | \u001b[0m 0.7147  \u001b[0m | \u001b[0m 0.08655 \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 70.5    \u001b[0m | \u001b[0m 566.4   \u001b[0m | \u001b[0m 148.2   \u001b[0m | \u001b[0m 25.12   \u001b[0m | \u001b[0m 0.8042  \u001b[0m | \u001b[0m 0.04613 \u001b[0m | \u001b[0m 0.5798  \u001b[0m |\n",
      "[-0.02466641 -0.01963248 -0.02706607 -0.02427832 -0.02479648 -0.0232029 ]\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.02394 \u001b[0m | \u001b[0m 0.9567  \u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 4.436   \u001b[0m | \u001b[0m 42.68   \u001b[0m | \u001b[0m 570.7   \u001b[0m | \u001b[0m 161.4   \u001b[0m | \u001b[0m 23.69   \u001b[0m | \u001b[0m 0.9524  \u001b[0m | \u001b[0m 0.9592  \u001b[0m | \u001b[0m 0.7586  \u001b[0m |\n",
      "[-0.02453207 -0.02120857 -0.02549385 -0.02411613 -0.02567149 -0.02340686]\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.02407 \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.161   \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 59.27   \u001b[0m | \u001b[0m 439.5   \u001b[0m | \u001b[0m 181.0   \u001b[0m | \u001b[0m 12.12   \u001b[0m | \u001b[0m 0.9521  \u001b[0m | \u001b[0m 0.9743  \u001b[0m | \u001b[0m 0.737   \u001b[0m |\n",
      "[-0.02374987 -0.02183782 -0.02662279 -0.02533568 -0.02260393 -0.02314877]\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.02388 \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.1982  \u001b[0m | \u001b[0m 12.01   \u001b[0m | \u001b[0m 85.12   \u001b[0m | \u001b[0m 445.1   \u001b[0m | \u001b[0m 153.2   \u001b[0m | \u001b[0m 12.13   \u001b[0m | \u001b[0m 0.6859  \u001b[0m | \u001b[0m 0.8356  \u001b[0m | \u001b[0m 0.682   \u001b[0m |\n",
      "[-0.02229318 -0.0185231  -0.02329075 -0.02128807 -0.02355245 -0.02022779]\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.02153 \u001b[0m | \u001b[0m 0.7396  \u001b[0m | \u001b[0m 0.0193  \u001b[0m | \u001b[0m 8.707   \u001b[0m | \u001b[0m 80.01   \u001b[0m | \u001b[0m 447.3   \u001b[0m | \u001b[0m 173.9   \u001b[0m | \u001b[0m 10.5    \u001b[0m | \u001b[0m 0.8996  \u001b[0m | \u001b[0m 0.00478 \u001b[0m | \u001b[0m 0.5281  \u001b[0m |\n",
      "[-0.02226919 -0.01868723 -0.02323631 -0.02205336 -0.02253781 -0.0218996 ]\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.02178 \u001b[0m | \u001b[0m 0.6775  \u001b[0m | \u001b[0m 0.07944 \u001b[0m | \u001b[0m 8.004   \u001b[0m | \u001b[0m 62.35   \u001b[0m | \u001b[0m 571.0   \u001b[0m | \u001b[0m 140.5   \u001b[0m | \u001b[0m 29.95   \u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 0.5898  \u001b[0m | \u001b[0m 0.9552  \u001b[0m |\n",
      "[-0.02290477 -0.02070113 -0.02535095 -0.02340124 -0.02394265 -0.02225741]\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.02309 \u001b[0m | \u001b[0m 0.5175  \u001b[0m | \u001b[0m 0.1403  \u001b[0m | \u001b[0m 9.808   \u001b[0m | \u001b[0m 64.31   \u001b[0m | \u001b[0m 577.4   \u001b[0m | \u001b[0m 138.1   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 0.2964  \u001b[0m | \u001b[0m 0.9323  \u001b[0m | \u001b[0m 0.8036  \u001b[0m |\n",
      "[-0.02296566 -0.02160651 -0.02687931 -0.02560861 -0.02649581 -0.02457958]\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.02469 \u001b[0m | \u001b[0m 0.6852  \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 6.255   \u001b[0m | \u001b[0m 68.04   \u001b[0m | \u001b[0m 451.8   \u001b[0m | \u001b[0m 163.7   \u001b[0m | \u001b[0m 3.347   \u001b[0m | \u001b[0m 0.6337  \u001b[0m | \u001b[0m 0.02034 \u001b[0m | \u001b[0m 0.9837  \u001b[0m |\n",
      "[-0.02219183 -0.01928866 -0.02498453 -0.02347629 -0.02322806 -0.02276016]\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.02265 \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.1216  \u001b[0m | \u001b[0m 8.44    \u001b[0m | \u001b[0m 71.61   \u001b[0m | \u001b[0m 436.4   \u001b[0m | \u001b[0m 165.3   \u001b[0m | \u001b[0m 10.11   \u001b[0m | \u001b[0m 0.9001  \u001b[0m | \u001b[0m 0.5545  \u001b[0m | \u001b[0m 0.7974  \u001b[0m |\n",
      "[-0.02405021 -0.02296444 -0.0268417  -0.02531495 -0.02517492 -0.02373449]\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.02468 \u001b[0m | \u001b[0m 0.6689  \u001b[0m | \u001b[0m 0.1731  \u001b[0m | \u001b[0m 10.73   \u001b[0m | \u001b[0m 78.02   \u001b[0m | \u001b[0m 447.6   \u001b[0m | \u001b[0m 171.1   \u001b[0m | \u001b[0m 15.54   \u001b[0m | \u001b[0m 0.1422  \u001b[0m | \u001b[0m 0.09532 \u001b[0m | \u001b[0m 0.8199  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.021419902560889877, 'params': {'colsample_bytree': 0.6788350779064587, 'learning_rate': 0.04858493330578331, 'max_depth': 9.909116279930052, 'min_child_samples': 73.49822091606751, 'n_estimators': 442.45576045363157, 'num_iteration': 162.80792470129595, 'num_leaves': 19.12621028739783, 'reg_alpha': 0.2649818752405111, 'reg_lambda': 0.8081319438014591, 'subsample': 0.9892454870915703}}\n",
      "1\n",
      "[LightGBM] [Warning] num_iterations is set=162, num_iteration=162 will be ignored. Current value: num_iterations=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.0191825\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.0190195\n",
      "[3]\tvalid_0's l2: 0.018875\n",
      "[4]\tvalid_0's l2: 0.0187414\n",
      "[5]\tvalid_0's l2: 0.0186459\n",
      "[6]\tvalid_0's l2: 0.0184939\n",
      "[7]\tvalid_0's l2: 0.0183661\n",
      "[8]\tvalid_0's l2: 0.0181336\n",
      "[9]\tvalid_0's l2: 0.0180607\n",
      "[10]\tvalid_0's l2: 0.0179597\n",
      "[11]\tvalid_0's l2: 0.0178304\n",
      "[12]\tvalid_0's l2: 0.0176984\n",
      "[13]\tvalid_0's l2: 0.0175906\n",
      "[14]\tvalid_0's l2: 0.0174932\n",
      "[15]\tvalid_0's l2: 0.0173947\n",
      "[16]\tvalid_0's l2: 0.0173241\n",
      "[17]\tvalid_0's l2: 0.0173051\n",
      "[18]\tvalid_0's l2: 0.0172452\n",
      "[19]\tvalid_0's l2: 0.0173045\n",
      "[20]\tvalid_0's l2: 0.0172567\n",
      "[21]\tvalid_0's l2: 0.0172703\n",
      "[22]\tvalid_0's l2: 0.0172861\n",
      "[23]\tvalid_0's l2: 0.0173412\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's l2: 0.0172452\n",
      "---- Train error ----\n",
      "0.019373252957904197\n",
      "---- CV error ----\n",
      "0.017245222259273905\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.08609132185915336\n",
      "mse = 0.026143124475680617\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.05707 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.05733 \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.05862 \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.06032 \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.05704 \u001b[0m | \u001b[95m 0.9092  \u001b[0m | \u001b[95m 0.105   \u001b[0m | \u001b[95m 12.34   \u001b[0m | \u001b[95m 28.23   \u001b[0m | \u001b[95m 226.8   \u001b[0m | \u001b[95m 88.81   \u001b[0m | \u001b[95m 15.11   \u001b[0m | \u001b[95m 0.4594  \u001b[0m | \u001b[95m 0.7095  \u001b[0m | \u001b[95m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.05898 \u001b[0m | \u001b[0m 0.7294  \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 7.61    \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.05699 \u001b[0m | \u001b[95m 0.8387  \u001b[0m | \u001b[95m 0.1723  \u001b[0m | \u001b[95m 7.045   \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 94.36   \u001b[0m | \u001b[95m 53.73   \u001b[0m | \u001b[95m 22.49   \u001b[0m | \u001b[95m 0.6974  \u001b[0m | \u001b[95m 0.462   \u001b[0m | \u001b[95m 0.9106  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.05621 \u001b[0m | \u001b[95m 0.7016  \u001b[0m | \u001b[95m 0.0116  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 859.6   \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 0.2637  \u001b[0m | \u001b[95m 0.8152  \u001b[0m | \u001b[95m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.05729 \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.07623 \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.05657 \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.04154 \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 152.8   \u001b[0m | \u001b[0m 859.9   \u001b[0m | \u001b[0m 88.78   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 0.267   \u001b[0m | \u001b[0m 0.7124  \u001b[0m | \u001b[0m 0.7969  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.05681 \u001b[0m | \u001b[0m 0.643   \u001b[0m | \u001b[0m 0.1175  \u001b[0m | \u001b[0m 2.287   \u001b[0m | \u001b[0m 153.3   \u001b[0m | \u001b[0m 864.9   \u001b[0m | \u001b[0m 94.6    \u001b[0m | \u001b[0m 2.68    \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 0.9845  \u001b[0m | \u001b[0m 0.8281  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.05655 \u001b[0m | \u001b[0m 0.7408  \u001b[0m | \u001b[0m 0.1984  \u001b[0m | \u001b[0m 9.665   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 845.8   \u001b[0m | \u001b[0m 108.4   \u001b[0m | \u001b[0m 17.01   \u001b[0m | \u001b[0m 0.843   \u001b[0m | \u001b[0m 0.9778  \u001b[0m | \u001b[0m 0.8643  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.05632 \u001b[0m | \u001b[0m 0.9738  \u001b[0m | \u001b[0m 0.1518  \u001b[0m | \u001b[0m 8.184   \u001b[0m | \u001b[0m 148.1   \u001b[0m | \u001b[0m 855.6   \u001b[0m | \u001b[0m 90.8    \u001b[0m | \u001b[0m 23.19   \u001b[0m | \u001b[0m 0.7228  \u001b[0m | \u001b[0m 0.8098  \u001b[0m | \u001b[0m 0.8383  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.05624 \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.1006  \u001b[0m | \u001b[0m 11.18   \u001b[0m | \u001b[0m 117.0   \u001b[0m | \u001b[0m 851.4   \u001b[0m | \u001b[0m 94.25   \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 0.03413 \u001b[0m | \u001b[0m 0.4141  \u001b[0m | \u001b[0m 0.6016  \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.05603 \u001b[0m | \u001b[95m 0.5858  \u001b[0m | \u001b[95m 0.111   \u001b[0m | \u001b[95m 11.58   \u001b[0m | \u001b[95m 146.2   \u001b[0m | \u001b[95m 849.8   \u001b[0m | \u001b[95m 91.35   \u001b[0m | \u001b[95m 26.45   \u001b[0m | \u001b[95m 0.3679  \u001b[0m | \u001b[95m 0.4248  \u001b[0m | \u001b[95m 0.5881  \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.05563 \u001b[0m | \u001b[95m 0.7162  \u001b[0m | \u001b[95m 0.1103  \u001b[0m | \u001b[95m 11.86   \u001b[0m | \u001b[95m 120.2   \u001b[0m | \u001b[95m 830.0   \u001b[0m | \u001b[95m 74.58   \u001b[0m | \u001b[95m 24.8    \u001b[0m | \u001b[95m 0.8761  \u001b[0m | \u001b[95m 0.4281  \u001b[0m | \u001b[95m 0.7421  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.05597 \u001b[0m | \u001b[0m 0.6084  \u001b[0m | \u001b[0m 0.1139  \u001b[0m | \u001b[0m 8.111   \u001b[0m | \u001b[0m 139.8   \u001b[0m | \u001b[0m 814.7   \u001b[0m | \u001b[0m 70.19   \u001b[0m | \u001b[0m 8.175   \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 0.059   \u001b[0m | \u001b[0m 0.8397  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.05646 \u001b[0m | \u001b[0m 0.8077  \u001b[0m | \u001b[0m 0.17    \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 146.2   \u001b[0m | \u001b[0m 844.4   \u001b[0m | \u001b[0m 92.15   \u001b[0m | \u001b[0m 29.13   \u001b[0m | \u001b[0m 0.96    \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.6558  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.05567 \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 0.07116 \u001b[0m | \u001b[0m 13.64   \u001b[0m | \u001b[0m 127.2   \u001b[0m | \u001b[0m 844.0   \u001b[0m | \u001b[0m 66.84   \u001b[0m | \u001b[0m 12.14   \u001b[0m | \u001b[0m 0.2796  \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 0.7765  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.0573  \u001b[0m | \u001b[0m 0.9214  \u001b[0m | \u001b[0m 0.1983  \u001b[0m | \u001b[0m 2.646   \u001b[0m | \u001b[0m 105.8   \u001b[0m | \u001b[0m 826.0   \u001b[0m | \u001b[0m 59.98   \u001b[0m | \u001b[0m 5.567   \u001b[0m | \u001b[0m 0.6869  \u001b[0m | \u001b[0m 0.01342 \u001b[0m | \u001b[0m 0.6141  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.05562645627100193, 'params': {'colsample_bytree': 0.7162153473743536, 'learning_rate': 0.11028622105318875, 'max_depth': 11.864011394123217, 'min_child_samples': 120.18437728904065, 'n_estimators': 829.9857004223551, 'num_iteration': 74.58222075182867, 'num_leaves': 24.79617798489564, 'reg_alpha': 0.8760921053640259, 'reg_lambda': 0.4281438033924748, 'subsample': 0.7421391563190007}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=74, num_iteration=74 will be ignored. Current value: num_iterations=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.048698\tvalid_0's binary_logloss: 0.199072\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.0482359\tvalid_0's binary_logloss: 0.195694\n",
      "[3]\tvalid_0's l2: 0.0477263\tvalid_0's binary_logloss: 0.192095\n",
      "[4]\tvalid_0's l2: 0.0474943\tvalid_0's binary_logloss: 0.190785\n",
      "[5]\tvalid_0's l2: 0.0476496\tvalid_0's binary_logloss: 0.19193\n",
      "[6]\tvalid_0's l2: 0.0472762\tvalid_0's binary_logloss: 0.189278\n",
      "[7]\tvalid_0's l2: 0.0470248\tvalid_0's binary_logloss: 0.1874\n",
      "[8]\tvalid_0's l2: 0.046945\tvalid_0's binary_logloss: 0.187246\n",
      "[9]\tvalid_0's l2: 0.0470603\tvalid_0's binary_logloss: 0.188183\n",
      "[10]\tvalid_0's l2: 0.0470186\tvalid_0's binary_logloss: 0.187988\n",
      "[11]\tvalid_0's l2: 0.0470139\tvalid_0's binary_logloss: 0.187959\n",
      "[12]\tvalid_0's l2: 0.0469724\tvalid_0's binary_logloss: 0.187344\n",
      "[13]\tvalid_0's l2: 0.0470165\tvalid_0's binary_logloss: 0.187813\n",
      "[14]\tvalid_0's l2: 0.0470072\tvalid_0's binary_logloss: 0.18796\n",
      "[15]\tvalid_0's l2: 0.0470692\tvalid_0's binary_logloss: 0.187988\n",
      "[16]\tvalid_0's l2: 0.0471781\tvalid_0's binary_logloss: 0.188709\n",
      "[17]\tvalid_0's l2: 0.0471857\tvalid_0's binary_logloss: 0.188765\n",
      "[18]\tvalid_0's l2: 0.0472104\tvalid_0's binary_logloss: 0.188906\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l2: 0.046945\tvalid_0's binary_logloss: 0.187246\n",
      "---- Train error ----\n",
      "0.05143190047051023\n",
      "---- CV error ----\n",
      "0.046945023350984494\n",
      "---- leaderboard stats ----\n",
      "r2 = 0.027556812368507155\n",
      "mse = 0.05192825850648769\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1778  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2097  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1805  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.199   \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1857  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1695  \u001b[0m | \u001b[95m 0.7442  \u001b[0m | \u001b[95m 0.01505 \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 68.61   \u001b[0m | \u001b[95m 442.5   \u001b[0m | \u001b[95m 160.3   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.1119  \u001b[0m | \u001b[95m 0.7041  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1725  \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.04858 \u001b[0m | \u001b[0m 9.909   \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 19.13   \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 0.9892  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1912  \u001b[0m | \u001b[0m 0.661   \u001b[0m | \u001b[0m 0.1622  \u001b[0m | \u001b[0m 5.057   \u001b[0m | \u001b[0m 51.35   \u001b[0m | \u001b[0m 433.9   \u001b[0m | \u001b[0m 181.5   \u001b[0m | \u001b[0m 4.921   \u001b[0m | \u001b[0m 0.3992  \u001b[0m | \u001b[0m 0.08505 \u001b[0m | \u001b[0m 0.5989  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1677  \u001b[0m | \u001b[95m 0.6466  \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 12.54   \u001b[0m | \u001b[95m 74.95   \u001b[0m | \u001b[95m 440.4   \u001b[0m | \u001b[95m 145.6   \u001b[0m | \u001b[95m 2.618   \u001b[0m | \u001b[95m 0.2893  \u001b[0m | \u001b[95m 0.3297  \u001b[0m | \u001b[95m 0.9299  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1839  \u001b[0m | \u001b[0m 0.6169  \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 56.53   \u001b[0m | \u001b[0m 421.5   \u001b[0m | \u001b[0m 134.5   \u001b[0m | \u001b[0m 4.385   \u001b[0m | \u001b[0m 0.8807  \u001b[0m | \u001b[0m 0.5768  \u001b[0m | \u001b[0m 0.9558  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1707  \u001b[0m | \u001b[0m 0.962   \u001b[0m | \u001b[0m 0.03949 \u001b[0m | \u001b[0m 4.624   \u001b[0m | \u001b[0m 77.14   \u001b[0m | \u001b[0m 465.8   \u001b[0m | \u001b[0m 167.0   \u001b[0m | \u001b[0m 5.159   \u001b[0m | \u001b[0m 0.9421  \u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 0.6366  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1677  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 74.89   \u001b[0m | \u001b[0m 464.1   \u001b[0m | \u001b[0m 137.4   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.168   \u001b[0m | \u001b[0m 0.7009  \u001b[0m | \u001b[0m 0.03541 \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 110.4   \u001b[0m | \u001b[0m 450.9   \u001b[0m | \u001b[0m 125.4   \u001b[0m | \u001b[0m 5.324   \u001b[0m | \u001b[0m 0.083   \u001b[0m | \u001b[0m 0.03446 \u001b[0m | \u001b[0m 0.7846  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1679  \u001b[0m | \u001b[0m 0.5819  \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 9.835   \u001b[0m | \u001b[0m 114.8   \u001b[0m | \u001b[0m 483.8   \u001b[0m | \u001b[0m 130.3   \u001b[0m | \u001b[0m 6.716   \u001b[0m | \u001b[0m 0.5612  \u001b[0m | \u001b[0m 0.6421  \u001b[0m | \u001b[0m 0.6072  \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.1674  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 122.5   \u001b[0m | \u001b[95m 461.0   \u001b[0m | \u001b[95m 157.2   \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.1671  \u001b[0m | \u001b[95m 0.833   \u001b[0m | \u001b[95m 0.03066 \u001b[0m | \u001b[95m 7.98    \u001b[0m | \u001b[95m 163.4   \u001b[0m | \u001b[95m 468.0   \u001b[0m | \u001b[95m 134.0   \u001b[0m | \u001b[95m 5.846   \u001b[0m | \u001b[95m 0.1734  \u001b[0m | \u001b[95m 0.438   \u001b[0m | \u001b[95m 0.928   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1672  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 149.0   \u001b[0m | \u001b[0m 496.6   \u001b[0m | \u001b[0m 161.6   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.8101  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1672  \u001b[0m | \u001b[0m 0.5965  \u001b[0m | \u001b[0m 0.1339  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 164.8   \u001b[0m | \u001b[0m 459.1   \u001b[0m | \u001b[0m 173.8   \u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 0.9016  \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 0.8746  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1679  \u001b[0m | \u001b[0m 0.7719  \u001b[0m | \u001b[0m 0.01726 \u001b[0m | \u001b[0m 12.5    \u001b[0m | \u001b[0m 110.6   \u001b[0m | \u001b[0m 487.0   \u001b[0m | \u001b[0m 130.5   \u001b[0m | \u001b[0m 6.678   \u001b[0m | \u001b[0m 0.7664  \u001b[0m | \u001b[0m 0.5762  \u001b[0m | \u001b[0m 0.9079  \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.1671  \u001b[0m | \u001b[95m 0.5644  \u001b[0m | \u001b[95m 0.1906  \u001b[0m | \u001b[95m 7.452   \u001b[0m | \u001b[95m 197.0   \u001b[0m | \u001b[95m 495.7   \u001b[0m | \u001b[95m 159.3   \u001b[0m | \u001b[95m 26.85   \u001b[0m | \u001b[95m 0.7526  \u001b[0m | \u001b[95m 0.2264  \u001b[0m | \u001b[95m 0.8661  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.16706207941647344, 'params': {'colsample_bytree': 0.5643986956367942, 'learning_rate': 0.1906410497224643, 'max_depth': 7.451983114129909, 'min_child_samples': 196.9568677785516, 'n_estimators': 495.69441013823524, 'num_iteration': 159.27415117976835, 'num_leaves': 26.85286562596417, 'reg_alpha': 0.7526250202247549, 'reg_lambda': 0.22641195908760614, 'subsample': 0.8661475461741497}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=159, num_iteration=159 will be ignored. Current value: num_iterations=159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.154706\tvalid_0's binary_logloss: 0.488553\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.155438\tvalid_0's binary_logloss: 0.490573\n",
      "[3]\tvalid_0's l2: 0.154705\tvalid_0's binary_logloss: 0.488596\n",
      "[4]\tvalid_0's l2: 0.154686\tvalid_0's binary_logloss: 0.488574\n",
      "[5]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[6]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[7]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[8]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[9]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[10]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[11]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[12]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[13]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[14]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "[15]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's l2: 0.154445\tvalid_0's binary_logloss: 0.487727\n",
      "---- Train error ----\n",
      "0.15775565484024812\n",
      "---- CV error ----\n",
      "0.15444499216974544\n",
      "---- leaderboard stats ----\n",
      "r2 = -0.0015304155602646752\n",
      "mse = 0.17438181236965813\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1821  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2075  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.198   \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2043  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1897  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1876  \u001b[0m | \u001b[0m 0.7304  \u001b[0m | \u001b[0m 0.0886  \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 50.87   \u001b[0m | \u001b[0m 564.0   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.9716  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.1754  \u001b[0m | \u001b[95m 0.6032  \u001b[0m | \u001b[95m 0.02479 \u001b[0m | \u001b[95m 12.4    \u001b[0m | \u001b[95m 60.5    \u001b[0m | \u001b[95m 563.1   \u001b[0m | \u001b[95m 131.4   \u001b[0m | \u001b[95m 21.15   \u001b[0m | \u001b[95m 0.6184  \u001b[0m | \u001b[95m 0.8283  \u001b[0m | \u001b[95m 0.5001  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1814  \u001b[0m | \u001b[0m 0.5792  \u001b[0m | \u001b[0m 0.05888 \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 33.19   \u001b[0m | \u001b[0m 227.7   \u001b[0m | \u001b[0m 85.05   \u001b[0m | \u001b[0m 15.06   \u001b[0m | \u001b[0m 0.007282\u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 0.7998  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1954  \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 0.1251  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 35.67   \u001b[0m | \u001b[0m 225.3   \u001b[0m | \u001b[0m 89.75   \u001b[0m | \u001b[0m 9.125   \u001b[0m | \u001b[0m 0.5762  \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 0.9434  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.179   \u001b[0m | \u001b[0m 0.6995  \u001b[0m | \u001b[0m 0.04563 \u001b[0m | \u001b[0m 9.306   \u001b[0m | \u001b[0m 59.05   \u001b[0m | \u001b[0m 570.5   \u001b[0m | \u001b[0m 130.7   \u001b[0m | \u001b[0m 18.09   \u001b[0m | \u001b[0m 0.7825  \u001b[0m | \u001b[0m 0.5352  \u001b[0m | \u001b[0m 0.8534  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.206   \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1775  \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.09247 \u001b[0m | \u001b[0m 4.982   \u001b[0m | \u001b[0m 180.9   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 25.02   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1792  \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.177   \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1775  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2057  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1775  \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.06931 \u001b[0m | \u001b[0m 1.744   \u001b[0m | \u001b[0m 142.1   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 77.45   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.5405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1782  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1777  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1784  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 158.7   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 8.06    \u001b[0m | \u001b[0m 0.4207  \u001b[0m | \u001b[0m 0.7088  \u001b[0m | \u001b[0m 0.8055  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.17541246349917258, 'params': {'colsample_bytree': 0.6032065810667311, 'learning_rate': 0.0247873990220248, 'max_depth': 12.397255167805731, 'min_child_samples': 60.50168770791395, 'n_estimators': 563.1161364672801, 'num_iteration': 131.4337180677012, 'num_leaves': 21.14775819741643, 'reg_alpha': 0.6184272430331157, 'reg_lambda': 0.828303915577041, 'subsample': 0.5001170569183866}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.174001\tvalid_0's binary_logloss: 0.53216\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.17377\tvalid_0's binary_logloss: 0.531526\n",
      "[3]\tvalid_0's l2: 0.173266\tvalid_0's binary_logloss: 0.530127\n",
      "[4]\tvalid_0's l2: 0.172887\tvalid_0's binary_logloss: 0.529076\n",
      "[5]\tvalid_0's l2: 0.172761\tvalid_0's binary_logloss: 0.528722\n",
      "[6]\tvalid_0's l2: 0.172388\tvalid_0's binary_logloss: 0.527694\n",
      "[7]\tvalid_0's l2: 0.171874\tvalid_0's binary_logloss: 0.526273\n",
      "[8]\tvalid_0's l2: 0.171486\tvalid_0's binary_logloss: 0.525184\n",
      "[9]\tvalid_0's l2: 0.171311\tvalid_0's binary_logloss: 0.524687\n",
      "[10]\tvalid_0's l2: 0.171071\tvalid_0's binary_logloss: 0.524022\n",
      "[11]\tvalid_0's l2: 0.170913\tvalid_0's binary_logloss: 0.523585\n",
      "[12]\tvalid_0's l2: 0.170475\tvalid_0's binary_logloss: 0.522405\n",
      "[13]\tvalid_0's l2: 0.170343\tvalid_0's binary_logloss: 0.522049\n",
      "[14]\tvalid_0's l2: 0.170247\tvalid_0's binary_logloss: 0.521744\n",
      "[15]\tvalid_0's l2: 0.170196\tvalid_0's binary_logloss: 0.521611\n",
      "[16]\tvalid_0's l2: 0.170103\tvalid_0's binary_logloss: 0.521356\n",
      "[17]\tvalid_0's l2: 0.16993\tvalid_0's binary_logloss: 0.520926\n",
      "[18]\tvalid_0's l2: 0.169747\tvalid_0's binary_logloss: 0.520429\n",
      "[19]\tvalid_0's l2: 0.169561\tvalid_0's binary_logloss: 0.519913\n",
      "[20]\tvalid_0's l2: 0.169346\tvalid_0's binary_logloss: 0.519306\n",
      "[21]\tvalid_0's l2: 0.168912\tvalid_0's binary_logloss: 0.518058\n",
      "[22]\tvalid_0's l2: 0.168778\tvalid_0's binary_logloss: 0.517636\n",
      "[23]\tvalid_0's l2: 0.168503\tvalid_0's binary_logloss: 0.516863\n",
      "[24]\tvalid_0's l2: 0.168483\tvalid_0's binary_logloss: 0.51675\n",
      "[25]\tvalid_0's l2: 0.168229\tvalid_0's binary_logloss: 0.51602\n",
      "[26]\tvalid_0's l2: 0.167785\tvalid_0's binary_logloss: 0.514816\n",
      "[27]\tvalid_0's l2: 0.167331\tvalid_0's binary_logloss: 0.513541\n",
      "[28]\tvalid_0's l2: 0.167078\tvalid_0's binary_logloss: 0.512804\n",
      "[29]\tvalid_0's l2: 0.16702\tvalid_0's binary_logloss: 0.512613\n",
      "[30]\tvalid_0's l2: 0.167025\tvalid_0's binary_logloss: 0.512607\n",
      "[31]\tvalid_0's l2: 0.166723\tvalid_0's binary_logloss: 0.511774\n",
      "[32]\tvalid_0's l2: 0.166817\tvalid_0's binary_logloss: 0.511975\n",
      "[33]\tvalid_0's l2: 0.166461\tvalid_0's binary_logloss: 0.511011\n",
      "[34]\tvalid_0's l2: 0.166438\tvalid_0's binary_logloss: 0.510911\n",
      "[35]\tvalid_0's l2: 0.166431\tvalid_0's binary_logloss: 0.510802\n",
      "[36]\tvalid_0's l2: 0.166082\tvalid_0's binary_logloss: 0.509835\n",
      "[37]\tvalid_0's l2: 0.166029\tvalid_0's binary_logloss: 0.509667\n",
      "[38]\tvalid_0's l2: 0.165883\tvalid_0's binary_logloss: 0.509244\n",
      "[39]\tvalid_0's l2: 0.165637\tvalid_0's binary_logloss: 0.508501\n",
      "[40]\tvalid_0's l2: 0.165571\tvalid_0's binary_logloss: 0.508296\n",
      "[41]\tvalid_0's l2: 0.165623\tvalid_0's binary_logloss: 0.508426\n",
      "[42]\tvalid_0's l2: 0.165983\tvalid_0's binary_logloss: 0.509563\n",
      "[43]\tvalid_0's l2: 0.166022\tvalid_0's binary_logloss: 0.509788\n",
      "[44]\tvalid_0's l2: 0.165754\tvalid_0's binary_logloss: 0.509195\n",
      "[45]\tvalid_0's l2: 0.165512\tvalid_0's binary_logloss: 0.508568\n",
      "[46]\tvalid_0's l2: 0.16542\tvalid_0's binary_logloss: 0.508303\n",
      "[47]\tvalid_0's l2: 0.16543\tvalid_0's binary_logloss: 0.508374\n",
      "[48]\tvalid_0's l2: 0.165299\tvalid_0's binary_logloss: 0.507994\n",
      "[49]\tvalid_0's l2: 0.165255\tvalid_0's binary_logloss: 0.50782\n",
      "[50]\tvalid_0's l2: 0.165188\tvalid_0's binary_logloss: 0.507607\n",
      "[51]\tvalid_0's l2: 0.165037\tvalid_0's binary_logloss: 0.507209\n",
      "[52]\tvalid_0's l2: 0.164777\tvalid_0's binary_logloss: 0.506552\n",
      "[53]\tvalid_0's l2: 0.164839\tvalid_0's binary_logloss: 0.506703\n",
      "[54]\tvalid_0's l2: 0.164914\tvalid_0's binary_logloss: 0.506926\n",
      "[55]\tvalid_0's l2: 0.164953\tvalid_0's binary_logloss: 0.507063\n",
      "[56]\tvalid_0's l2: 0.165243\tvalid_0's binary_logloss: 0.507886\n",
      "[57]\tvalid_0's l2: 0.165274\tvalid_0's binary_logloss: 0.507935\n",
      "[58]\tvalid_0's l2: 0.165255\tvalid_0's binary_logloss: 0.50794\n",
      "[59]\tvalid_0's l2: 0.165189\tvalid_0's binary_logloss: 0.507842\n",
      "[60]\tvalid_0's l2: 0.16518\tvalid_0's binary_logloss: 0.507837\n",
      "[61]\tvalid_0's l2: 0.165132\tvalid_0's binary_logloss: 0.507692\n",
      "[62]\tvalid_0's l2: 0.16529\tvalid_0's binary_logloss: 0.508132\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l2: 0.164777\tvalid_0's binary_logloss: 0.506552\n",
      "---- Train error ----\n",
      "0.13932914366541704\n",
      "---- CV error ----\n",
      "0.16477713778473155\n",
      "---- leaderboard stats ----\n",
      "r2 = -0.01428385655870068\n",
      "mse = 0.2032936824781467\n",
      "0:03:14.388560\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RepeatedKFold,RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "variables = test.columns.to_list()\n",
    "\n",
    "\n",
    "prediction = pd.read_csv('FFChallenge_v5/prediction.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "best_params_lgbm = dict()\n",
    "\n",
    "\n",
    "# Bayesian optimization function for regression-based models\n",
    "def optimize_gbm_regressor(data, targets,boosting_type):\n",
    "    \"\"\"Apply Bayesian Optimization to GBM parameters.\"\"\"\n",
    "\n",
    "    def gbm_crossval(num_leaves, max_depth, learning_rate,\n",
    "                     n_estimators,num_iteration,subsample,min_child_samples,\n",
    "                    colsample_bytree,reg_alpha,reg_lambda,):\n",
    "        \"\"\"GB cross validation.\n",
    "        \"\"\"\n",
    "        # Parameters to be optimized\n",
    "        clf = LGBMRegressor(\n",
    "            num_leaves=int(num_leaves),\n",
    "            max_depth=int(max_depth),\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=int(n_estimators),\n",
    "            num_iteration=int(num_iteration),\n",
    "            boosting_type = boosting_type,\n",
    "            subsample = subsample,\n",
    "            min_child_samples = int(min_child_samples),\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha = reg_alpha,\n",
    "            reg_lambda = reg_lambda,\n",
    "        )\n",
    "        cv = RepeatedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "        cval = cross_val_score(clf, data, targets, scoring='neg_mean_squared_error', cv=cv,n_jobs=-1)\n",
    "        print(cval)\n",
    "        return cval.mean()\n",
    "    \n",
    "    # Parameters to be optimized\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=gbm_crossval,\n",
    "        pbounds={\n",
    "            'num_leaves': (2, 30),\n",
    "            'max_depth': (1, 15),\n",
    "            'learning_rate': (0.01, 0.2),\n",
    "            'n_estimators': (10,1000),\n",
    "            'num_iteration':(50,200),\n",
    "            'subsample': (0.5,1.0),\n",
    "            'min_child_samples' : (10, 200),\n",
    "            'colsample_bytree':(0.5,1),\n",
    "            'reg_alpha': (0.0, 1.0),\n",
    "            'reg_lambda': (0.0, 1.0),\n",
    "        },\n",
    "        random_state=12345,\n",
    "        verbose=3\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=5)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "    return optimizer.max\n",
    "\n",
    "\n",
    "# Bayesian optimization function for classification-based models\n",
    "def optimize_gbm_classifier(data, targets,boosting_type):\n",
    "    \"\"\"Apply Bayesian Optimization to GBM parameters.\"\"\"\n",
    "#     self.boosting_type = boosting_type\n",
    "\n",
    "    def gbm_crossval(num_leaves, max_depth, learning_rate,\n",
    "                     n_estimators,num_iteration,subsample,min_child_samples,\n",
    "                    colsample_bytree,reg_alpha,reg_lambda,):\n",
    "        \"\"\"GB cross validation.\n",
    "        \"\"\"\n",
    "        clf = LGBMClassifier(\n",
    "        num_leaves=int(num_leaves),\n",
    "        max_depth=int(max_depth),\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        num_iteration=int(num_iteration),\n",
    "        boosting_type = boosting_type,\n",
    "        subsample = subsample,\n",
    "        min_child_samples = int(min_child_samples),\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha = reg_alpha,\n",
    "        reg_lambda = reg_lambda,\n",
    "        )\n",
    "        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=123)\n",
    "        cval = cross_val_score(clf, data, targets, scoring='neg_brier_score', cv=cv,n_jobs=-1)\n",
    "#         print(cval)\n",
    "        return cval.mean()\n",
    "    \n",
    "    # Parameters to be optimized\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=gbm_crossval,\n",
    "        pbounds={\n",
    "            'num_leaves': (2, 30),\n",
    "            'max_depth': (1, 15),\n",
    "            'learning_rate': (0.01, 0.2),\n",
    "            'n_estimators': (10,1000),\n",
    "            'num_iteration':(50,200),\n",
    "            'subsample': (0.5,1.0),\n",
    "            'min_child_samples' : (10, 200),\n",
    "            'colsample_bytree':(0.5,1),\n",
    "            'reg_alpha': (0.0, 1.0),\n",
    "            'reg_lambda': (0.0, 1.0),\n",
    "        },\n",
    "        random_state=12345,\n",
    "        verbose=3\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=5)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "    return optimizer.max\n",
    "\n",
    "\n",
    "classification_vars = ['eviction','layoff','jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "boosting_types = ['gbdt','dart','goss'] # List of the three boosting types\n",
    "\n",
    "best_params_each_model = dict()\n",
    "\n",
    "accuracies_each_model = dict()\n",
    "\n",
    "timings_each_model = dict()\n",
    "for boosting_type in boosting_types: # Go through all three of the different boosting types\n",
    "    print('------------- ',boosting_type, ' --------------')\n",
    "    print('\\n')\n",
    "    lgbm_accuracies = dict()\n",
    "    lgbm_timings = dict()\n",
    "    for variable in variables: # Go through all the variable outcomes\n",
    "#     for variable in ['grit','layoff']:\n",
    "    # variable = 'eviction'\n",
    "        print(variable)\n",
    "        start=datetime.now()\n",
    "        # Let's drop instances where the response is NA\n",
    "        y_train_no_na = y_train[variable].dropna()\n",
    "        X_train_no_na = X_train.loc[y_train_no_na.index.values]\n",
    "\n",
    "        y_CV_no_na = y_CV[variable].dropna()\n",
    "        X_CV_no_na = X_CV.loc[y_CV_no_na.index.values]\n",
    "\n",
    "        mask = leaderboard[variable].isna()\n",
    "        y_leaderboard = leaderboard[variable]\n",
    "\n",
    "        #training our model using light gbm\n",
    "\n",
    "        # specify parameters and distributions to sample from\n",
    "\n",
    "        # If the outcomes are continuous use the regressor. Otherwise use the classifier\n",
    "        if variable not in classification_vars:\n",
    "            print(variable)\n",
    "            # Run bayesian optimization to get optimal hyperparameters\n",
    "            params = optimize_gbm_regressor(X_train_no_na, y_train_no_na,boosting_type)\n",
    "            best_params = params['params']  \n",
    "            print(1)\n",
    "\n",
    "            # train a new model using the best hyperparameters \n",
    "            lgbm=LGBMRegressor(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                   n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                        num_iteration = int(best_params['num_iteration']),\n",
    "                        boosting_type=boosting_type, \n",
    "                        subsample = best_params['subsample'],\n",
    "                        min_child_samples = int(best_params['min_child_samples']),\n",
    "                        colsample_bytree=best_params['colsample_bytree'],\n",
    "                        reg_alpha = best_params['reg_alpha'],\n",
    "                        reg_lambda = best_params['reg_lambda'],\n",
    "                               silent = True)\n",
    "\n",
    "            # I used early stopping to help prevent overfitting the model on the training set (stops the model once it's performance doesn't\n",
    "            # improve for 5 iterations on the validation set)\n",
    "            lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2',\n",
    "             early_stopping_rounds = 5)\n",
    "\n",
    "            \n",
    "            # For early stopping (i.e. early stopping at 10 rounds with no improvement to cv)\n",
    "            # The model that displayed the score 10 rounds ago does not exist anymore (a few trees have been dropped).\n",
    "            # To get the best score you got 20 rounds ago, you have no option but to retrain a model with the appropriate number of iterations.\n",
    "#             https://www.kaggle.com/c/microsoft-malware-prediction/discussion/78253\n",
    "            if boosting_type=='dart':\n",
    "        \n",
    "                evaluation_score = lgbm.evals_result_\n",
    "\n",
    "                dart_best_iteration = evaluation_score['valid_0']['l2'].index(min(evaluation_score['valid_0']['l2']))+1\n",
    "            \n",
    "                \n",
    "                lgbm=LGBMRegressor(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                           n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                                num_iteration = dart_best_iteration,\n",
    "                                boosting_type='dart', \n",
    "                                subsample = best_params['subsample'],\n",
    "                                min_child_samples = int(best_params['min_child_samples']),\n",
    "                                colsample_bytree=best_params['colsample_bytree'],\n",
    "                                reg_alpha = best_params['reg_alpha'],\n",
    "                                reg_lambda = best_params['reg_lambda'],\n",
    "                                       silent = True)\n",
    "                lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2')\n",
    "\n",
    "            # Predictions on the training, cv, leaderboard and test set\n",
    "            y_pred_train = lgbm.predict(X_train_no_na)\n",
    "            y_pred_all = lgbm.predict(x_leaderboard)\n",
    "            cv_preds = lgbm.predict(X_CV_no_na)\n",
    "            # Save predictions of best model for leaderboard submition\n",
    "            pred_all_backgrounds = lgbm.predict(background_imputed_tot)\n",
    "\n",
    "        else:\n",
    "            # Run bayesian optimization\n",
    "            params = optimize_gbm_classifier(X_train_no_na, y_train_no_na,boosting_type)\n",
    "            best_params = params['params']  \n",
    "            print(0)\n",
    "            # Validation accuracy\n",
    "            \n",
    "            # train a new model using the best hyperparameters \n",
    "\n",
    "            lgbm=LGBMClassifier(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                       n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                        num_iteration = int(best_params['num_iteration']),\n",
    "                        boosting_type=boosting_type,\n",
    "                        subsample = best_params['subsample'],\n",
    "                        min_child_samples = int(best_params['min_child_samples']),\n",
    "                        colsample_bytree=best_params['colsample_bytree'],\n",
    "                        reg_alpha = best_params['reg_alpha'],\n",
    "                        reg_lambda = best_params['reg_lambda'],   \n",
    "                        silent = True)\n",
    "    #         lgbm.fit(X_train_no_na, y_train_no_na,eval_metric='l1')\n",
    "            lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2',\n",
    "                 early_stopping_rounds = 10)\n",
    "        \n",
    "            if boosting_type=='dart':\n",
    "                \n",
    "                evaluation_score = lgbm.evals_result_\n",
    "\n",
    "                dart_best_iteration = evaluation_score['valid_0']['l2'].index(min(evaluation_score['valid_0']['l2']))+1\n",
    "\n",
    "                lgbm=LGBMClassifier(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                           n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                                num_iteration = dart_best_iteration,\n",
    "                                boosting_type='dart', \n",
    "                                subsample = best_params['subsample'],\n",
    "                                min_child_samples = int(best_params['min_child_samples']),\n",
    "                                colsample_bytree=best_params['colsample_bytree'],\n",
    "                                reg_alpha = best_params['reg_alpha'],\n",
    "                                reg_lambda = best_params['reg_lambda'],\n",
    "                                       silent = True)\n",
    "                lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2')\n",
    "\n",
    "            # Predictions on the training, cv, leaderboard and test set\n",
    "            y_pred_train = lgbm.predict_proba(X_train_no_na)[:,1]\n",
    "            y_pred_all = lgbm.predict_proba(x_leaderboard)[:,1]\n",
    "            cv_preds = lgbm.predict_proba(X_CV_no_na)[:,1]\n",
    "            # Save predictions of best model for leaderboard submition\n",
    "            pred_all_backgrounds = lgbm.predict_proba(background_imputed_tot)[:,1]\n",
    "\n",
    "        best_params_lgbm[variable] = best_params\n",
    "        \n",
    "        #### Saving model to be interpretted later\n",
    "        joblib.dump(lgbm, 'lgbm_'+ variable + '_' + boosting_type + '.pkl')\n",
    "\n",
    "        # Can use mean square error as performance metric for both, since for 1 output, the mean square error and brier loss are the same.       \n",
    "        error_types = dict()  \n",
    "        print('---- Train error ----')\n",
    "        error_types['train'] = mean_squared_error(y_train_no_na,y_pred_train)\n",
    "        print(mean_squared_error(y_train_no_na,y_pred_train))\n",
    "        print('---- CV error ----')\n",
    "        error_types['CV'] = mean_squared_error(y_CV_no_na,cv_preds)\n",
    "        print(mean_squared_error(y_CV_no_na,cv_preds))\n",
    "\n",
    "        print('---- leaderboard stats ----')\n",
    "        print('r2 =',r2_score(y_leaderboard[~mask],y_pred_all[~mask]))\n",
    "        \n",
    "        error_types['leaderboard'] = mean_squared_error(y_leaderboard[~mask],y_pred_all[~mask])\n",
    "        print('mse =',mean_squared_error(y_leaderboard[~mask],y_pred_all[~mask]))\n",
    "        \n",
    "        lgbm_accuracies[variable] = error_types\n",
    "\n",
    "        # lgbm=LGBMClassifier(learning_rate = 0.05, n_estimators = len(background.columns), num_leaves = 32)\n",
    "\n",
    "\n",
    "        # Save predictions of best model for leaderboard submition\n",
    "\n",
    "        prediction[variable] = pred_all_backgrounds\n",
    "\n",
    "        lgbm_timings[variable] = datetime.now()-start\n",
    "        \n",
    "    best_params_each_model[boosting_type] = best_params_lgbm\n",
    "    accuracies_each_model[boosting_type] = lgbm_accuracies\n",
    "    timings_each_model[boosting_type] = lgbm_timings\n",
    "    #     print(pred_all_backgrounds==cv_preds)\n",
    "\n",
    "\n",
    "    prediction.to_csv('lgbm_preds_' + boosting_type + '.csv')\n",
    "    print(datetime.now()-start)\n",
    "    print('\\n\\n\\n------------------------------------------')\n",
    "best_params_each_model_no_sampling_copy = best_params_each_model.copy()\n",
    "\n",
    "\n",
    "accuracies_each_model_no_sampling_copy = accuracies_each_model.copy()\n",
    "    #     print(pred_all_backgrounds==cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model performance and parameters\n",
    "import pickle\n",
    "\n",
    "# Save models and params\n",
    "with open('best_params_tress_no_sampling.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_params_each_model_no_sampling_copy, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('best_params_tress_no_sampling.pickle', 'wb') as handle:\n",
    "    pickle.dump(accuracies_each_model_no_sampling_copy, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# best_params_each_model_no_sampling_copy\n",
    "# accuracies_each_model_no_sampling_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eviction dart 0.05207330412177481',\n",
       " 'eviction gbdt 0.050633443020071826',\n",
       " 'eviction goss 0.05192825850648769',\n",
       " 'gpa dart 0.38124499706416043',\n",
       " 'gpa gbdt 0.37764382969532606',\n",
       " 'gpa goss 0.3710648078690564',\n",
       " 'grit dart 0.2169031608664567',\n",
       " 'grit gbdt 0.21711522212374287',\n",
       " 'grit goss 0.21659011055012237',\n",
       " 'jobTraining dart 0.20428263080049058',\n",
       " 'jobTraining gbdt 0.19940966236005536',\n",
       " 'jobTraining goss 0.2032936824781467',\n",
       " 'layoff dart 0.1744041463446064',\n",
       " 'layoff gbdt 0.17419679113048317',\n",
       " 'layoff goss 0.17438181236965813',\n",
       " 'materialHardship dart 0.0255595316615577',\n",
       " 'materialHardship gbdt 0.02609444653819857',\n",
       " 'materialHardship goss 0.026143124475680617']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print accuracies\n",
    "lst_leader_board_accs = list()\n",
    "for model_name in accuracies_each_model:\n",
    "    for var_name in accuracies_each_model[model_name]:\n",
    "        lst_leader_board_accs.append(var_name + ' ' + model_name + ' ' +  str(accuracies_each_model[model_name][var_name]['leaderboard']))\n",
    "\n",
    "sorted(lst_leader_board_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the exact same code as the non-weighted model, except using balanced class weights to increase the weights associated with the minority class. Model calibration is used after training the models, since the probability become biased towards the minority class. This code only trains models for the categorical outcomes, since continuous outcomes do not need to be balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  gbdt  --------------\n",
      "\n",
      "\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.05957 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.0814  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.05879 \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.06    \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.05937 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.05952 \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.05963 \u001b[0m | \u001b[0m 0.6993  \u001b[0m | \u001b[0m 0.1586  \u001b[0m | \u001b[0m 8.776   \u001b[0m | \u001b[0m 16.65   \u001b[0m | \u001b[0m 500.2   \u001b[0m | \u001b[0m 138.2   \u001b[0m | \u001b[0m 16.77   \u001b[0m | \u001b[0m 0.1568  \u001b[0m | \u001b[0m 0.9366  \u001b[0m | \u001b[0m 0.651   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.05912 \u001b[0m | \u001b[0m 0.9563  \u001b[0m | \u001b[0m 0.14    \u001b[0m | \u001b[0m 8.631   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 141.4   \u001b[0m | \u001b[0m 53.37   \u001b[0m | \u001b[0m 10.2    \u001b[0m | \u001b[0m 0.8372  \u001b[0m | \u001b[0m 0.3031  \u001b[0m | \u001b[0m 0.8757  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.06624 \u001b[0m | \u001b[0m 0.8543  \u001b[0m | \u001b[0m 0.1259  \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 139.8   \u001b[0m | \u001b[0m 519.3   \u001b[0m | \u001b[0m 196.1   \u001b[0m | \u001b[0m 3.722   \u001b[0m | \u001b[0m 0.8729  \u001b[0m | \u001b[0m 0.8717  \u001b[0m | \u001b[0m 0.5743  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1092  \u001b[0m | \u001b[0m 0.6045  \u001b[0m | \u001b[0m 0.05215 \u001b[0m | \u001b[0m 6.933   \u001b[0m | \u001b[0m 121.6   \u001b[0m | \u001b[0m 185.1   \u001b[0m | \u001b[0m 52.25   \u001b[0m | \u001b[0m 22.86   \u001b[0m | \u001b[0m 0.8198  \u001b[0m | \u001b[0m 0.2483  \u001b[0m | \u001b[0m 0.6154  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.05982 \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 0.1126  \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 113.2   \u001b[0m | \u001b[0m 146.7   \u001b[0m | \u001b[0m 15.35   \u001b[0m | \u001b[0m 0.2968  \u001b[0m | \u001b[0m 0.13    \u001b[0m | \u001b[0m 0.8073  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1598  \u001b[0m | \u001b[0m 0.5662  \u001b[0m | \u001b[0m 0.03174 \u001b[0m | \u001b[0m 5.836   \u001b[0m | \u001b[0m 12.48   \u001b[0m | \u001b[0m 19.47   \u001b[0m | \u001b[0m 52.85   \u001b[0m | \u001b[0m 3.273   \u001b[0m | \u001b[0m 0.1875  \u001b[0m | \u001b[0m 0.2642  \u001b[0m | \u001b[0m 0.7621  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.06112 \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 9.643   \u001b[0m | \u001b[0m 137.7   \u001b[0m | \u001b[0m 512.9   \u001b[0m | \u001b[0m 191.1   \u001b[0m | \u001b[0m 4.579   \u001b[0m | \u001b[0m 0.7733  \u001b[0m | \u001b[0m 0.9664  \u001b[0m | \u001b[0m 0.5981  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1128  \u001b[0m | \u001b[0m 0.6186  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 160.1   \u001b[0m | \u001b[0m 488.1   \u001b[0m | \u001b[0m 81.55   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7274  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.07077 \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 185.9   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1904  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 147.9   \u001b[0m | \u001b[0m 416.5   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.553   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.05893 \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 0.09478 \u001b[0m | \u001b[0m 8.32    \u001b[0m | \u001b[0m 71.11   \u001b[0m | \u001b[0m 532.6   \u001b[0m | \u001b[0m 190.2   \u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 0.3044  \u001b[0m | \u001b[0m 0.522   \u001b[0m | \u001b[0m 0.7333  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.06286 \u001b[0m | \u001b[0m 0.815   \u001b[0m | \u001b[0m 0.05279 \u001b[0m | \u001b[0m 11.19   \u001b[0m | \u001b[0m 16.67   \u001b[0m | \u001b[0m 141.5   \u001b[0m | \u001b[0m 53.69   \u001b[0m | \u001b[0m 16.2    \u001b[0m | \u001b[0m 0.7742  \u001b[0m | \u001b[0m 0.4109  \u001b[0m | \u001b[0m 0.5787  \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.05857 \u001b[0m | \u001b[95m 0.8542  \u001b[0m | \u001b[95m 0.133   \u001b[0m | \u001b[95m 8.224   \u001b[0m | \u001b[95m 71.92   \u001b[0m | \u001b[95m 447.5   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 27.69   \u001b[0m | \u001b[95m 0.8175  \u001b[0m | \u001b[95m 0.1869  \u001b[0m | \u001b[95m 0.8824  \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.05843 \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 15.0    \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 399.1   \u001b[0m | \u001b[95m 62.08   \u001b[0m | \u001b[95m 30.0    \u001b[0m | \u001b[95m 0.4043  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.05843223656680918, 'params': {'colsample_bytree': 0.5, 'learning_rate': 0.2, 'max_depth': 15.0, 'min_child_samples': 10.0, 'n_estimators': 399.14135534046767, 'num_iteration': 62.08031519747842, 'num_leaves': 30.0, 'reg_alpha': 0.4043022142522065, 'reg_lambda': 1.0, 'subsample': 0.5}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=62, num_iteration=62 will be ignored. Current value: num_iterations=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.196833\tvalid_0's binary_logloss: 0.585557\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.159369\tvalid_0's binary_logloss: 0.505307\n",
      "[3]\tvalid_0's l2: 0.132265\tvalid_0's binary_logloss: 0.443251\n",
      "[4]\tvalid_0's l2: 0.110814\tvalid_0's binary_logloss: 0.391198\n",
      "[5]\tvalid_0's l2: 0.0977501\tvalid_0's binary_logloss: 0.355265\n",
      "[6]\tvalid_0's l2: 0.0860269\tvalid_0's binary_logloss: 0.321635\n",
      "[7]\tvalid_0's l2: 0.0801892\tvalid_0's binary_logloss: 0.301981\n",
      "[8]\tvalid_0's l2: 0.0743954\tvalid_0's binary_logloss: 0.282345\n",
      "[9]\tvalid_0's l2: 0.068289\tvalid_0's binary_logloss: 0.263569\n",
      "[10]\tvalid_0's l2: 0.0635337\tvalid_0's binary_logloss: 0.248025\n",
      "[11]\tvalid_0's l2: 0.0612069\tvalid_0's binary_logloss: 0.238546\n",
      "[12]\tvalid_0's l2: 0.0597573\tvalid_0's binary_logloss: 0.231027\n",
      "[13]\tvalid_0's l2: 0.0584132\tvalid_0's binary_logloss: 0.223961\n",
      "[14]\tvalid_0's l2: 0.056505\tvalid_0's binary_logloss: 0.216696\n",
      "[15]\tvalid_0's l2: 0.0543107\tvalid_0's binary_logloss: 0.208778\n",
      "[16]\tvalid_0's l2: 0.053464\tvalid_0's binary_logloss: 0.2061\n",
      "[17]\tvalid_0's l2: 0.0523379\tvalid_0's binary_logloss: 0.202196\n",
      "[18]\tvalid_0's l2: 0.0510278\tvalid_0's binary_logloss: 0.196277\n",
      "[19]\tvalid_0's l2: 0.0507595\tvalid_0's binary_logloss: 0.194849\n",
      "[20]\tvalid_0's l2: 0.0500243\tvalid_0's binary_logloss: 0.191561\n",
      "[21]\tvalid_0's l2: 0.0490701\tvalid_0's binary_logloss: 0.188742\n",
      "[22]\tvalid_0's l2: 0.0491635\tvalid_0's binary_logloss: 0.188506\n",
      "[23]\tvalid_0's l2: 0.0487054\tvalid_0's binary_logloss: 0.187573\n",
      "[24]\tvalid_0's l2: 0.0491573\tvalid_0's binary_logloss: 0.188129\n",
      "[25]\tvalid_0's l2: 0.048377\tvalid_0's binary_logloss: 0.187041\n",
      "[26]\tvalid_0's l2: 0.0482538\tvalid_0's binary_logloss: 0.186257\n",
      "[27]\tvalid_0's l2: 0.0480136\tvalid_0's binary_logloss: 0.186562\n",
      "[28]\tvalid_0's l2: 0.0481793\tvalid_0's binary_logloss: 0.186751\n",
      "[29]\tvalid_0's l2: 0.0482175\tvalid_0's binary_logloss: 0.186985\n",
      "[30]\tvalid_0's l2: 0.0476443\tvalid_0's binary_logloss: 0.185811\n",
      "[31]\tvalid_0's l2: 0.0477186\tvalid_0's binary_logloss: 0.186923\n",
      "[32]\tvalid_0's l2: 0.0479233\tvalid_0's binary_logloss: 0.187722\n",
      "[33]\tvalid_0's l2: 0.0481867\tvalid_0's binary_logloss: 0.189632\n",
      "[34]\tvalid_0's l2: 0.0479973\tvalid_0's binary_logloss: 0.190102\n",
      "[35]\tvalid_0's l2: 0.0480739\tvalid_0's binary_logloss: 0.190663\n",
      "[36]\tvalid_0's l2: 0.0481301\tvalid_0's binary_logloss: 0.190344\n",
      "[37]\tvalid_0's l2: 0.0481326\tvalid_0's binary_logloss: 0.190775\n",
      "[38]\tvalid_0's l2: 0.0481092\tvalid_0's binary_logloss: 0.192211\n",
      "[39]\tvalid_0's l2: 0.0479834\tvalid_0's binary_logloss: 0.193485\n",
      "[40]\tvalid_0's l2: 0.0480867\tvalid_0's binary_logloss: 0.193815\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l2: 0.0476443\tvalid_0's binary_logloss: 0.185811\n",
      "---- Train error ----\n",
      "0.0015104244046259738\n",
      "---- CV error ----\n",
      "0.0482726165639266\n",
      "---- leaderboard stats ----\n",
      "0.015565219221071791\n",
      "0.05256860701916669\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2023  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2221  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1922  \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1984  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.1862  \u001b[0m | \u001b[95m 0.9092  \u001b[0m | \u001b[95m 0.105   \u001b[0m | \u001b[95m 12.34   \u001b[0m | \u001b[95m 28.23   \u001b[0m | \u001b[95m 226.8   \u001b[0m | \u001b[95m 88.81   \u001b[0m | \u001b[95m 15.11   \u001b[0m | \u001b[95m 0.4594  \u001b[0m | \u001b[95m 0.7095  \u001b[0m | \u001b[95m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2154  \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 0.01505 \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 68.61   \u001b[0m | \u001b[0m 442.5   \u001b[0m | \u001b[0m 160.3   \u001b[0m | \u001b[0m 16.66   \u001b[0m | \u001b[0m 0.4092  \u001b[0m | \u001b[0m 0.1119  \u001b[0m | \u001b[0m 0.7041  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2256  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2409  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1843  \u001b[0m | \u001b[95m 0.8052  \u001b[0m | \u001b[95m 0.07623 \u001b[0m | \u001b[95m 11.45   \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 449.5   \u001b[0m | \u001b[95m 54.49   \u001b[0m | \u001b[95m 21.34   \u001b[0m | \u001b[95m 0.6751  \u001b[0m | \u001b[95m 0.2528  \u001b[0m | \u001b[95m 0.9977  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2198  \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 176.8   \u001b[0m | \u001b[0m 702.2   \u001b[0m | \u001b[0m 99.75   \u001b[0m | \u001b[0m 4.208   \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.5864  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1932  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2009  \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.06218 \u001b[0m | \u001b[0m 4.668   \u001b[0m | \u001b[0m 10.55   \u001b[0m | \u001b[0m 451.6   \u001b[0m | \u001b[0m 66.35   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 0.3266  \u001b[0m | \u001b[0m 0.5441  \u001b[0m | \u001b[0m 0.6517  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1931  \u001b[0m | \u001b[0m 0.9654  \u001b[0m | \u001b[0m 0.1156  \u001b[0m | \u001b[0m 14.86   \u001b[0m | \u001b[0m 36.87   \u001b[0m | \u001b[0m 230.0   \u001b[0m | \u001b[0m 80.61   \u001b[0m | \u001b[0m 9.661   \u001b[0m | \u001b[0m 0.8907  \u001b[0m | \u001b[0m 0.6353  \u001b[0m | \u001b[0m 0.6609  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1951  \u001b[0m | \u001b[0m 0.9919  \u001b[0m | \u001b[0m 0.1834  \u001b[0m | \u001b[0m 12.47   \u001b[0m | \u001b[0m 35.55   \u001b[0m | \u001b[0m 219.6   \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 0.1006  \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.9308  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1926  \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 12.17   \u001b[0m | \u001b[0m 41.52   \u001b[0m | \u001b[0m 217.1   \u001b[0m | \u001b[0m 100.3   \u001b[0m | \u001b[0m 13.72   \u001b[0m | \u001b[0m 0.000781\u001b[0m | \u001b[0m 0.1911  \u001b[0m | \u001b[0m 0.8793  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1907  \u001b[0m | \u001b[0m 0.6231  \u001b[0m | \u001b[0m 0.1746  \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 428.9   \u001b[0m | \u001b[0m 54.33   \u001b[0m | \u001b[0m 24.63   \u001b[0m | \u001b[0m 0.7268  \u001b[0m | \u001b[0m 0.3592  \u001b[0m | \u001b[0m 0.8698  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1989  \u001b[0m | \u001b[0m 0.6033  \u001b[0m | \u001b[0m 0.07055 \u001b[0m | \u001b[0m 5.604   \u001b[0m | \u001b[0m 33.84   \u001b[0m | \u001b[0m 461.2   \u001b[0m | \u001b[0m 56.96   \u001b[0m | \u001b[0m 16.42   \u001b[0m | \u001b[0m 0.4076  \u001b[0m | \u001b[0m 0.2732  \u001b[0m | \u001b[0m 0.9796  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1902  \u001b[0m | \u001b[0m 0.501   \u001b[0m | \u001b[0m 0.1784  \u001b[0m | \u001b[0m 5.733   \u001b[0m | \u001b[0m 38.3    \u001b[0m | \u001b[0m 462.8   \u001b[0m | \u001b[0m 61.11   \u001b[0m | \u001b[0m 17.69   \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 0.8458  \u001b[0m | \u001b[0m 0.891   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1941  \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 8.224   \u001b[0m | \u001b[0m 71.92   \u001b[0m | \u001b[0m 447.5   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 27.69   \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 0.8824  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1916  \u001b[0m | \u001b[0m 0.554   \u001b[0m | \u001b[0m 0.1456  \u001b[0m | \u001b[0m 6.462   \u001b[0m | \u001b[0m 50.52   \u001b[0m | \u001b[0m 469.1   \u001b[0m | \u001b[0m 70.92   \u001b[0m | \u001b[0m 17.62   \u001b[0m | \u001b[0m 0.6662  \u001b[0m | \u001b[0m 0.618   \u001b[0m | \u001b[0m 0.5673  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.1843072231479849, 'params': {'colsample_bytree': 0.8051524326000911, 'learning_rate': 0.07622676714877168, 'max_depth': 11.454976288940626, 'min_child_samples': 11.99606845130557, 'n_estimators': 449.5163267356571, 'num_iteration': 54.492523750639826, 'num_leaves': 21.342916046117168, 'reg_alpha': 0.6751144589005302, 'reg_lambda': 0.2528343060768782, 'subsample': 0.9977195529183328}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=54, num_iteration=54 will be ignored. Current value: num_iterations=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.246323\tvalid_0's binary_logloss: 0.685778\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.242177\tvalid_0's binary_logloss: 0.677442\n",
      "[3]\tvalid_0's l2: 0.23848\tvalid_0's binary_logloss: 0.669953\n",
      "[4]\tvalid_0's l2: 0.238591\tvalid_0's binary_logloss: 0.670141\n",
      "[5]\tvalid_0's l2: 0.235823\tvalid_0's binary_logloss: 0.664422\n",
      "[6]\tvalid_0's l2: 0.23212\tvalid_0's binary_logloss: 0.656786\n",
      "[7]\tvalid_0's l2: 0.231657\tvalid_0's binary_logloss: 0.655802\n",
      "[8]\tvalid_0's l2: 0.229908\tvalid_0's binary_logloss: 0.652061\n",
      "[9]\tvalid_0's l2: 0.229266\tvalid_0's binary_logloss: 0.65065\n",
      "[10]\tvalid_0's l2: 0.227135\tvalid_0's binary_logloss: 0.646194\n",
      "[11]\tvalid_0's l2: 0.225432\tvalid_0's binary_logloss: 0.642769\n",
      "[12]\tvalid_0's l2: 0.221741\tvalid_0's binary_logloss: 0.634908\n",
      "[13]\tvalid_0's l2: 0.216964\tvalid_0's binary_logloss: 0.624762\n",
      "[14]\tvalid_0's l2: 0.214077\tvalid_0's binary_logloss: 0.618468\n",
      "[15]\tvalid_0's l2: 0.214203\tvalid_0's binary_logloss: 0.618388\n",
      "[16]\tvalid_0's l2: 0.212046\tvalid_0's binary_logloss: 0.613748\n",
      "[17]\tvalid_0's l2: 0.21021\tvalid_0's binary_logloss: 0.609677\n",
      "[18]\tvalid_0's l2: 0.208329\tvalid_0's binary_logloss: 0.605156\n",
      "[19]\tvalid_0's l2: 0.205598\tvalid_0's binary_logloss: 0.599287\n",
      "[20]\tvalid_0's l2: 0.204591\tvalid_0's binary_logloss: 0.597354\n",
      "[21]\tvalid_0's l2: 0.203432\tvalid_0's binary_logloss: 0.594504\n",
      "[22]\tvalid_0's l2: 0.200444\tvalid_0's binary_logloss: 0.587949\n",
      "[23]\tvalid_0's l2: 0.20035\tvalid_0's binary_logloss: 0.587716\n",
      "[24]\tvalid_0's l2: 0.200348\tvalid_0's binary_logloss: 0.587346\n",
      "[25]\tvalid_0's l2: 0.198852\tvalid_0's binary_logloss: 0.584301\n",
      "[26]\tvalid_0's l2: 0.196391\tvalid_0's binary_logloss: 0.579174\n",
      "[27]\tvalid_0's l2: 0.195873\tvalid_0's binary_logloss: 0.577575\n",
      "[28]\tvalid_0's l2: 0.194678\tvalid_0's binary_logloss: 0.575072\n",
      "[29]\tvalid_0's l2: 0.193334\tvalid_0's binary_logloss: 0.572154\n",
      "[30]\tvalid_0's l2: 0.191048\tvalid_0's binary_logloss: 0.567282\n",
      "[31]\tvalid_0's l2: 0.190543\tvalid_0's binary_logloss: 0.566338\n",
      "[32]\tvalid_0's l2: 0.188145\tvalid_0's binary_logloss: 0.560873\n",
      "[33]\tvalid_0's l2: 0.187655\tvalid_0's binary_logloss: 0.559959\n",
      "[34]\tvalid_0's l2: 0.186893\tvalid_0's binary_logloss: 0.557927\n",
      "[35]\tvalid_0's l2: 0.186993\tvalid_0's binary_logloss: 0.558261\n",
      "[36]\tvalid_0's l2: 0.186361\tvalid_0's binary_logloss: 0.556813\n",
      "[37]\tvalid_0's l2: 0.185664\tvalid_0's binary_logloss: 0.554843\n",
      "[38]\tvalid_0's l2: 0.184495\tvalid_0's binary_logloss: 0.552197\n",
      "[39]\tvalid_0's l2: 0.184396\tvalid_0's binary_logloss: 0.551945\n",
      "[40]\tvalid_0's l2: 0.183854\tvalid_0's binary_logloss: 0.550931\n",
      "[41]\tvalid_0's l2: 0.183318\tvalid_0's binary_logloss: 0.549788\n",
      "[42]\tvalid_0's l2: 0.182325\tvalid_0's binary_logloss: 0.547894\n",
      "[43]\tvalid_0's l2: 0.180583\tvalid_0's binary_logloss: 0.544004\n",
      "[44]\tvalid_0's l2: 0.18003\tvalid_0's binary_logloss: 0.542949\n",
      "[45]\tvalid_0's l2: 0.179213\tvalid_0's binary_logloss: 0.541542\n",
      "[46]\tvalid_0's l2: 0.178966\tvalid_0's binary_logloss: 0.540568\n",
      "[47]\tvalid_0's l2: 0.179434\tvalid_0's binary_logloss: 0.541939\n",
      "[48]\tvalid_0's l2: 0.179104\tvalid_0's binary_logloss: 0.541255\n",
      "[49]\tvalid_0's l2: 0.178829\tvalid_0's binary_logloss: 0.540955\n",
      "[50]\tvalid_0's l2: 0.17869\tvalid_0's binary_logloss: 0.540779\n",
      "[51]\tvalid_0's l2: 0.178707\tvalid_0's binary_logloss: 0.540855\n",
      "[52]\tvalid_0's l2: 0.178023\tvalid_0's binary_logloss: 0.539225\n",
      "[53]\tvalid_0's l2: 0.177848\tvalid_0's binary_logloss: 0.539255\n",
      "[54]\tvalid_0's l2: 0.177946\tvalid_0's binary_logloss: 0.539275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[53]\tvalid_0's l2: 0.177848\tvalid_0's binary_logloss: 0.539255\n",
      "---- Train error ----\n",
      "0.1273775924876789\n",
      "---- CV error ----\n",
      "0.15349736878876705\n",
      "---- leaderboard stats ----\n",
      "-0.0053951672578369525\n",
      "0.17505472493917246\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1987  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2193  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1967  \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2003  \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.05196 \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.1893  \u001b[0m | \u001b[95m 0.9092  \u001b[0m | \u001b[95m 0.105   \u001b[0m | \u001b[95m 12.34   \u001b[0m | \u001b[95m 28.23   \u001b[0m | \u001b[95m 226.8   \u001b[0m | \u001b[95m 88.81   \u001b[0m | \u001b[95m 15.11   \u001b[0m | \u001b[95m 0.4594  \u001b[0m | \u001b[95m 0.7095  \u001b[0m | \u001b[95m 0.589   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1887  \u001b[0m | \u001b[95m 0.9641  \u001b[0m | \u001b[95m 0.02932 \u001b[0m | \u001b[95m 10.83   \u001b[0m | \u001b[95m 20.96   \u001b[0m | \u001b[95m 497.1   \u001b[0m | \u001b[95m 132.3   \u001b[0m | \u001b[95m 13.29   \u001b[0m | \u001b[95m 0.3121  \u001b[0m | \u001b[95m 0.151   \u001b[0m | \u001b[95m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2214  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1851  \u001b[0m | \u001b[95m 0.5792  \u001b[0m | \u001b[95m 0.05888 \u001b[0m | \u001b[95m 13.41   \u001b[0m | \u001b[95m 33.19   \u001b[0m | \u001b[95m 227.7   \u001b[0m | \u001b[95m 85.05   \u001b[0m | \u001b[95m 15.06   \u001b[0m | \u001b[95m 0.007282\u001b[0m | \u001b[95m 0.9673  \u001b[0m | \u001b[95m 0.7998  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1974  \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 0.09162 \u001b[0m | \u001b[0m 12.95   \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 215.7   \u001b[0m | \u001b[0m 74.94   \u001b[0m | \u001b[0m 7.475   \u001b[0m | \u001b[0m 0.9332  \u001b[0m | \u001b[0m 0.7296  \u001b[0m | \u001b[0m 0.6018  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2228  \u001b[0m | \u001b[0m 0.8006  \u001b[0m | \u001b[0m 0.1494  \u001b[0m | \u001b[0m 1.824   \u001b[0m | \u001b[0m 23.56   \u001b[0m | \u001b[0m 497.3   \u001b[0m | \u001b[0m 144.0   \u001b[0m | \u001b[0m 6.871   \u001b[0m | \u001b[0m 0.9538  \u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 0.9041  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1953  \u001b[0m | \u001b[0m 0.5105  \u001b[0m | \u001b[0m 0.1238  \u001b[0m | \u001b[0m 8.324   \u001b[0m | \u001b[0m 34.17   \u001b[0m | \u001b[0m 224.8   \u001b[0m | \u001b[0m 80.54   \u001b[0m | \u001b[0m 26.35   \u001b[0m | \u001b[0m 0.1838  \u001b[0m | \u001b[0m 0.172   \u001b[0m | \u001b[0m 0.551   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1885  \u001b[0m | \u001b[0m 0.6465  \u001b[0m | \u001b[0m 0.07909 \u001b[0m | \u001b[0m 13.5    \u001b[0m | \u001b[0m 27.1    \u001b[0m | \u001b[0m 221.5   \u001b[0m | \u001b[0m 78.04   \u001b[0m | \u001b[0m 14.8    \u001b[0m | \u001b[0m 0.1959  \u001b[0m | \u001b[0m 0.3544  \u001b[0m | \u001b[0m 0.8215  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.192   \u001b[0m | \u001b[0m 0.9654  \u001b[0m | \u001b[0m 0.1156  \u001b[0m | \u001b[0m 14.86   \u001b[0m | \u001b[0m 36.87   \u001b[0m | \u001b[0m 230.0   \u001b[0m | \u001b[0m 80.61   \u001b[0m | \u001b[0m 9.661   \u001b[0m | \u001b[0m 0.8907  \u001b[0m | \u001b[0m 0.6353  \u001b[0m | \u001b[0m 0.6609  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1879  \u001b[0m | \u001b[0m 0.6597  \u001b[0m | \u001b[0m 0.08379 \u001b[0m | \u001b[0m 7.62    \u001b[0m | \u001b[0m 32.39   \u001b[0m | \u001b[0m 210.5   \u001b[0m | \u001b[0m 86.2    \u001b[0m | \u001b[0m 19.68   \u001b[0m | \u001b[0m 0.9503  \u001b[0m | \u001b[0m 0.497   \u001b[0m | \u001b[0m 0.9821  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2103  \u001b[0m | \u001b[0m 0.9058  \u001b[0m | \u001b[0m 0.02534 \u001b[0m | \u001b[0m 5.505   \u001b[0m | \u001b[0m 25.81   \u001b[0m | \u001b[0m 210.8   \u001b[0m | \u001b[0m 81.74   \u001b[0m | \u001b[0m 8.949   \u001b[0m | \u001b[0m 0.9729  \u001b[0m | \u001b[0m 0.4342  \u001b[0m | \u001b[0m 0.7101  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1949  \u001b[0m | \u001b[0m 0.6094  \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 25.5    \u001b[0m | \u001b[0m 228.6   \u001b[0m | \u001b[0m 77.38   \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 0.8222  \u001b[0m | \u001b[0m 0.4018  \u001b[0m | \u001b[0m 0.5668  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1869  \u001b[0m | \u001b[0m 0.933   \u001b[0m | \u001b[0m 0.1002  \u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 211.3   \u001b[0m | \u001b[0m 75.92   \u001b[0m | \u001b[0m 27.39   \u001b[0m | \u001b[0m 0.3988  \u001b[0m | \u001b[0m 0.6991  \u001b[0m | \u001b[0m 0.9495  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1956  \u001b[0m | \u001b[0m 0.9581  \u001b[0m | \u001b[0m 0.08022 \u001b[0m | \u001b[0m 4.725   \u001b[0m | \u001b[0m 39.72   \u001b[0m | \u001b[0m 204.2   \u001b[0m | \u001b[0m 73.21   \u001b[0m | \u001b[0m 27.79   \u001b[0m | \u001b[0m 0.7958  \u001b[0m | \u001b[0m 0.8887  \u001b[0m | \u001b[0m 0.7902  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1853  \u001b[0m | \u001b[0m 0.5954  \u001b[0m | \u001b[0m 0.08248 \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 18.85   \u001b[0m | \u001b[0m 212.5   \u001b[0m | \u001b[0m 93.3    \u001b[0m | \u001b[0m 25.64   \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.4214  \u001b[0m | \u001b[0m 0.7254  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1865  \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.08389 \u001b[0m | \u001b[0m 8.241   \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 199.9   \u001b[0m | \u001b[0m 90.27   \u001b[0m | \u001b[0m 27.0    \u001b[0m | \u001b[0m 0.5443  \u001b[0m | \u001b[0m 0.3024  \u001b[0m | \u001b[0m 0.7353  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.185110160152525, 'params': {'colsample_bytree': 0.579174136829371, 'learning_rate': 0.05887836804180674, 'max_depth': 13.405036456804348, 'min_child_samples': 33.187465252044504, 'n_estimators': 227.73294708701923, 'num_iteration': 85.04612125372478, 'num_leaves': 15.061468292788899, 'reg_alpha': 0.0072818013166865425, 'reg_lambda': 0.9672516626137474, 'subsample': 0.7997577707367187}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=85, num_iteration=85 will be ignored. Current value: num_iterations=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.24608\tvalid_0's binary_logloss: 0.685303\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.2415\tvalid_0's binary_logloss: 0.67612\n",
      "[3]\tvalid_0's l2: 0.23965\tvalid_0's binary_logloss: 0.672396\n",
      "[4]\tvalid_0's l2: 0.236991\tvalid_0's binary_logloss: 0.667035\n",
      "[5]\tvalid_0's l2: 0.234162\tvalid_0's binary_logloss: 0.661325\n",
      "[6]\tvalid_0's l2: 0.231502\tvalid_0's binary_logloss: 0.655944\n",
      "[7]\tvalid_0's l2: 0.228652\tvalid_0's binary_logloss: 0.650149\n",
      "[8]\tvalid_0's l2: 0.227125\tvalid_0's binary_logloss: 0.646998\n",
      "[9]\tvalid_0's l2: 0.223975\tvalid_0's binary_logloss: 0.640572\n",
      "[10]\tvalid_0's l2: 0.22203\tvalid_0's binary_logloss: 0.636511\n",
      "[11]\tvalid_0's l2: 0.221048\tvalid_0's binary_logloss: 0.634426\n",
      "[12]\tvalid_0's l2: 0.218793\tvalid_0's binary_logloss: 0.629716\n",
      "[13]\tvalid_0's l2: 0.217476\tvalid_0's binary_logloss: 0.626946\n",
      "[14]\tvalid_0's l2: 0.216228\tvalid_0's binary_logloss: 0.624284\n",
      "[15]\tvalid_0's l2: 0.215124\tvalid_0's binary_logloss: 0.621884\n",
      "[16]\tvalid_0's l2: 0.213534\tvalid_0's binary_logloss: 0.618566\n",
      "[17]\tvalid_0's l2: 0.212455\tvalid_0's binary_logloss: 0.616262\n",
      "[18]\tvalid_0's l2: 0.210223\tvalid_0's binary_logloss: 0.611502\n",
      "[19]\tvalid_0's l2: 0.208227\tvalid_0's binary_logloss: 0.607188\n",
      "[20]\tvalid_0's l2: 0.207213\tvalid_0's binary_logloss: 0.605001\n",
      "[21]\tvalid_0's l2: 0.205418\tvalid_0's binary_logloss: 0.601204\n",
      "[22]\tvalid_0's l2: 0.203754\tvalid_0's binary_logloss: 0.597685\n",
      "[23]\tvalid_0's l2: 0.201774\tvalid_0's binary_logloss: 0.593311\n",
      "[24]\tvalid_0's l2: 0.200606\tvalid_0's binary_logloss: 0.590623\n",
      "[25]\tvalid_0's l2: 0.19981\tvalid_0's binary_logloss: 0.588926\n",
      "[26]\tvalid_0's l2: 0.198375\tvalid_0's binary_logloss: 0.585783\n",
      "[27]\tvalid_0's l2: 0.197953\tvalid_0's binary_logloss: 0.58467\n",
      "[28]\tvalid_0's l2: 0.197249\tvalid_0's binary_logloss: 0.582952\n",
      "[29]\tvalid_0's l2: 0.196745\tvalid_0's binary_logloss: 0.58186\n",
      "[30]\tvalid_0's l2: 0.195928\tvalid_0's binary_logloss: 0.580084\n",
      "[31]\tvalid_0's l2: 0.194751\tvalid_0's binary_logloss: 0.577291\n",
      "[32]\tvalid_0's l2: 0.193912\tvalid_0's binary_logloss: 0.575459\n",
      "[33]\tvalid_0's l2: 0.193117\tvalid_0's binary_logloss: 0.573672\n",
      "[34]\tvalid_0's l2: 0.193151\tvalid_0's binary_logloss: 0.573555\n",
      "[35]\tvalid_0's l2: 0.192505\tvalid_0's binary_logloss: 0.572022\n",
      "[36]\tvalid_0's l2: 0.191745\tvalid_0's binary_logloss: 0.570348\n",
      "[37]\tvalid_0's l2: 0.191146\tvalid_0's binary_logloss: 0.568866\n",
      "[38]\tvalid_0's l2: 0.190716\tvalid_0's binary_logloss: 0.56802\n",
      "[39]\tvalid_0's l2: 0.190047\tvalid_0's binary_logloss: 0.566497\n",
      "[40]\tvalid_0's l2: 0.189105\tvalid_0's binary_logloss: 0.56427\n",
      "[41]\tvalid_0's l2: 0.188714\tvalid_0's binary_logloss: 0.563435\n",
      "[42]\tvalid_0's l2: 0.187929\tvalid_0's binary_logloss: 0.561557\n",
      "[43]\tvalid_0's l2: 0.187371\tvalid_0's binary_logloss: 0.560153\n",
      "[44]\tvalid_0's l2: 0.18694\tvalid_0's binary_logloss: 0.559099\n",
      "[45]\tvalid_0's l2: 0.186297\tvalid_0's binary_logloss: 0.557459\n",
      "[46]\tvalid_0's l2: 0.186108\tvalid_0's binary_logloss: 0.557027\n",
      "[47]\tvalid_0's l2: 0.186181\tvalid_0's binary_logloss: 0.557259\n",
      "[48]\tvalid_0's l2: 0.186222\tvalid_0's binary_logloss: 0.557105\n",
      "[49]\tvalid_0's l2: 0.186909\tvalid_0's binary_logloss: 0.55834\n",
      "[50]\tvalid_0's l2: 0.186139\tvalid_0's binary_logloss: 0.556572\n",
      "[51]\tvalid_0's l2: 0.185227\tvalid_0's binary_logloss: 0.554411\n",
      "[52]\tvalid_0's l2: 0.184669\tvalid_0's binary_logloss: 0.553043\n",
      "[53]\tvalid_0's l2: 0.184375\tvalid_0's binary_logloss: 0.552259\n",
      "[54]\tvalid_0's l2: 0.184502\tvalid_0's binary_logloss: 0.552415\n",
      "[55]\tvalid_0's l2: 0.18454\tvalid_0's binary_logloss: 0.552474\n",
      "[56]\tvalid_0's l2: 0.184161\tvalid_0's binary_logloss: 0.551596\n",
      "[57]\tvalid_0's l2: 0.184025\tvalid_0's binary_logloss: 0.551159\n",
      "[58]\tvalid_0's l2: 0.183533\tvalid_0's binary_logloss: 0.54978\n",
      "[59]\tvalid_0's l2: 0.183488\tvalid_0's binary_logloss: 0.549516\n",
      "[60]\tvalid_0's l2: 0.183904\tvalid_0's binary_logloss: 0.550171\n",
      "[61]\tvalid_0's l2: 0.183291\tvalid_0's binary_logloss: 0.548786\n",
      "[62]\tvalid_0's l2: 0.182571\tvalid_0's binary_logloss: 0.547102\n",
      "[63]\tvalid_0's l2: 0.182571\tvalid_0's binary_logloss: 0.547003\n",
      "[64]\tvalid_0's l2: 0.18233\tvalid_0's binary_logloss: 0.54656\n",
      "[65]\tvalid_0's l2: 0.181913\tvalid_0's binary_logloss: 0.545432\n",
      "[66]\tvalid_0's l2: 0.1812\tvalid_0's binary_logloss: 0.543781\n",
      "[67]\tvalid_0's l2: 0.180577\tvalid_0's binary_logloss: 0.542535\n",
      "[68]\tvalid_0's l2: 0.180182\tvalid_0's binary_logloss: 0.541313\n",
      "[69]\tvalid_0's l2: 0.179602\tvalid_0's binary_logloss: 0.53981\n",
      "[70]\tvalid_0's l2: 0.1795\tvalid_0's binary_logloss: 0.539481\n",
      "[71]\tvalid_0's l2: 0.179525\tvalid_0's binary_logloss: 0.53955\n",
      "[72]\tvalid_0's l2: 0.179756\tvalid_0's binary_logloss: 0.540056\n",
      "[73]\tvalid_0's l2: 0.178443\tvalid_0's binary_logloss: 0.536797\n",
      "[74]\tvalid_0's l2: 0.177981\tvalid_0's binary_logloss: 0.535803\n",
      "[75]\tvalid_0's l2: 0.177304\tvalid_0's binary_logloss: 0.534303\n",
      "[76]\tvalid_0's l2: 0.177121\tvalid_0's binary_logloss: 0.534059\n",
      "[77]\tvalid_0's l2: 0.176994\tvalid_0's binary_logloss: 0.533784\n",
      "[78]\tvalid_0's l2: 0.176512\tvalid_0's binary_logloss: 0.532363\n",
      "[79]\tvalid_0's l2: 0.176086\tvalid_0's binary_logloss: 0.53123\n",
      "[80]\tvalid_0's l2: 0.176198\tvalid_0's binary_logloss: 0.531473\n",
      "[81]\tvalid_0's l2: 0.175055\tvalid_0's binary_logloss: 0.528788\n",
      "[82]\tvalid_0's l2: 0.174928\tvalid_0's binary_logloss: 0.528424\n",
      "[83]\tvalid_0's l2: 0.174319\tvalid_0's binary_logloss: 0.526954\n",
      "[84]\tvalid_0's l2: 0.174275\tvalid_0's binary_logloss: 0.526719\n",
      "[85]\tvalid_0's l2: 0.173954\tvalid_0's binary_logloss: 0.525902\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[85]\tvalid_0's l2: 0.173954\tvalid_0's binary_logloss: 0.525902\n",
      "---- Train error ----\n",
      "0.046578685436198405\n",
      "---- CV error ----\n",
      "0.16178638512006388\n",
      "---- leaderboard stats ----\n",
      "-0.05710643529501991\n",
      "0.21187664440564227\n",
      "0:02:59.650466\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "-------------  dart  --------------\n",
      "\n",
      "\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.08381 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1236  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.06075 \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.05759 \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.06096 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.08919 \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.102   \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2051  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.06059 \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 0.1151  \u001b[0m | \u001b[0m 4.125   \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 488.9   \u001b[0m | \u001b[0m 109.8   \u001b[0m | \u001b[0m 18.16   \u001b[0m | \u001b[0m 0.6589  \u001b[0m | \u001b[0m 0.2523  \u001b[0m | \u001b[0m 0.6938  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.06018 \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 47.61   \u001b[0m | \u001b[0m 568.1   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 27.26   \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.6486  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.05719 \u001b[0m | \u001b[95m 0.5116  \u001b[0m | \u001b[95m 0.1887  \u001b[0m | \u001b[95m 13.28   \u001b[0m | \u001b[95m 42.32   \u001b[0m | \u001b[95m 565.6   \u001b[0m | \u001b[95m 168.6   \u001b[0m | \u001b[95m 26.9    \u001b[0m | \u001b[95m 0.5723  \u001b[0m | \u001b[95m 0.8111  \u001b[0m | \u001b[95m 0.8566  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.05801 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 516.2   \u001b[0m | \u001b[0m 112.6   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.07826 \u001b[0m | \u001b[0m 0.8897  \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 810.2   \u001b[0m | \u001b[0m 186.3   \u001b[0m | \u001b[0m 24.33   \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.5351  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.203   \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.06901 \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 0.05605 \u001b[0m | \u001b[0m 13.1    \u001b[0m | \u001b[0m 41.67   \u001b[0m | \u001b[0m 572.6   \u001b[0m | \u001b[0m 168.2   \u001b[0m | \u001b[0m 29.65   \u001b[0m | \u001b[0m 0.3787  \u001b[0m | \u001b[0m 0.8404  \u001b[0m | \u001b[0m 0.7107  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1201  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 63.32   \u001b[0m | \u001b[0m 552.2   \u001b[0m | \u001b[0m 157.4   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.05789 \u001b[0m | \u001b[0m 0.7772  \u001b[0m | \u001b[0m 0.1659  \u001b[0m | \u001b[0m 14.6    \u001b[0m | \u001b[0m 12.47   \u001b[0m | \u001b[0m 541.6   \u001b[0m | \u001b[0m 146.2   \u001b[0m | \u001b[0m 29.31   \u001b[0m | \u001b[0m 0.77    \u001b[0m | \u001b[0m 0.6181  \u001b[0m | \u001b[0m 0.6935  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.06    \u001b[0m | \u001b[0m 0.7274  \u001b[0m | \u001b[0m 0.1355  \u001b[0m | \u001b[0m 14.25   \u001b[0m | \u001b[0m 30.92   \u001b[0m | \u001b[0m 227.0   \u001b[0m | \u001b[0m 82.09   \u001b[0m | \u001b[0m 21.93   \u001b[0m | \u001b[0m 0.4404  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 0.5164  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.06041 \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 8.224   \u001b[0m | \u001b[0m 71.92   \u001b[0m | \u001b[0m 447.5   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 27.69   \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 0.8824  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.06093 \u001b[0m | \u001b[0m 0.568   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 105.9   \u001b[0m | \u001b[0m 439.1   \u001b[0m | \u001b[0m 152.0   \u001b[0m | \u001b[0m 19.66   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.0571857717384798, 'params': {'colsample_bytree': 0.5115569764046519, 'learning_rate': 0.18873201236552564, 'max_depth': 13.284525033981414, 'min_child_samples': 42.324168062754666, 'n_estimators': 565.5591524781473, 'num_iteration': 168.5886680772516, 'num_leaves': 26.89672658026174, 'reg_alpha': 0.5722823918838528, 'reg_lambda': 0.8110964377735519, 'subsample': 0.8565559520793317}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=168, num_iteration=168 will be ignored. Current value: num_iterations=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.210235\tvalid_0's binary_logloss: 0.612659\n",
      "[2]\tvalid_0's l2: 0.181005\tvalid_0's binary_logloss: 0.550685\n",
      "[3]\tvalid_0's l2: 0.166278\tvalid_0's binary_logloss: 0.516942\n",
      "[4]\tvalid_0's l2: 0.148456\tvalid_0's binary_logloss: 0.475951\n",
      "[5]\tvalid_0's l2: 0.136093\tvalid_0's binary_logloss: 0.444722\n",
      "[6]\tvalid_0's l2: 0.125422\tvalid_0's binary_logloss: 0.417113\n",
      "[7]\tvalid_0's l2: 0.114998\tvalid_0's binary_logloss: 0.389389\n",
      "[8]\tvalid_0's l2: 0.117498\tvalid_0's binary_logloss: 0.397342\n",
      "[9]\tvalid_0's l2: 0.107256\tvalid_0's binary_logloss: 0.370104\n",
      "[10]\tvalid_0's l2: 0.0979871\tvalid_0's binary_logloss: 0.344938\n",
      "[11]\tvalid_0's l2: 0.0922764\tvalid_0's binary_logloss: 0.327595\n",
      "[12]\tvalid_0's l2: 0.0928769\tvalid_0's binary_logloss: 0.331491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\tvalid_0's l2: 0.0866294\tvalid_0's binary_logloss: 0.313357\n",
      "[14]\tvalid_0's l2: 0.0826975\tvalid_0's binary_logloss: 0.300983\n",
      "[15]\tvalid_0's l2: 0.0805447\tvalid_0's binary_logloss: 0.293602\n",
      "[16]\tvalid_0's l2: 0.0778621\tvalid_0's binary_logloss: 0.284266\n",
      "[17]\tvalid_0's l2: 0.0755736\tvalid_0's binary_logloss: 0.274659\n",
      "[18]\tvalid_0's l2: 0.0732193\tvalid_0's binary_logloss: 0.26754\n",
      "[19]\tvalid_0's l2: 0.0701364\tvalid_0's binary_logloss: 0.259314\n",
      "[20]\tvalid_0's l2: 0.0680118\tvalid_0's binary_logloss: 0.25209\n",
      "[21]\tvalid_0's l2: 0.068207\tvalid_0's binary_logloss: 0.253578\n",
      "[22]\tvalid_0's l2: 0.0669554\tvalid_0's binary_logloss: 0.249244\n",
      "[23]\tvalid_0's l2: 0.0649087\tvalid_0's binary_logloss: 0.242848\n",
      "[24]\tvalid_0's l2: 0.0625783\tvalid_0's binary_logloss: 0.235639\n",
      "[25]\tvalid_0's l2: 0.0618186\tvalid_0's binary_logloss: 0.231521\n",
      "[26]\tvalid_0's l2: 0.060137\tvalid_0's binary_logloss: 0.227057\n",
      "[27]\tvalid_0's l2: 0.0593525\tvalid_0's binary_logloss: 0.223351\n",
      "[28]\tvalid_0's l2: 0.0593492\tvalid_0's binary_logloss: 0.223666\n",
      "[29]\tvalid_0's l2: 0.05836\tvalid_0's binary_logloss: 0.220938\n",
      "[30]\tvalid_0's l2: 0.0572664\tvalid_0's binary_logloss: 0.217636\n",
      "[31]\tvalid_0's l2: 0.0567401\tvalid_0's binary_logloss: 0.216122\n",
      "[32]\tvalid_0's l2: 0.0565295\tvalid_0's binary_logloss: 0.214265\n",
      "[33]\tvalid_0's l2: 0.0563621\tvalid_0's binary_logloss: 0.212995\n",
      "[34]\tvalid_0's l2: 0.05538\tvalid_0's binary_logloss: 0.208412\n",
      "[35]\tvalid_0's l2: 0.0554799\tvalid_0's binary_logloss: 0.209217\n",
      "[36]\tvalid_0's l2: 0.0555458\tvalid_0's binary_logloss: 0.209679\n",
      "[37]\tvalid_0's l2: 0.055358\tvalid_0's binary_logloss: 0.207788\n",
      "[38]\tvalid_0's l2: 0.0545008\tvalid_0's binary_logloss: 0.204174\n",
      "[39]\tvalid_0's l2: 0.0548936\tvalid_0's binary_logloss: 0.206107\n",
      "[40]\tvalid_0's l2: 0.0546624\tvalid_0's binary_logloss: 0.205495\n",
      "[41]\tvalid_0's l2: 0.0548913\tvalid_0's binary_logloss: 0.206137\n",
      "[42]\tvalid_0's l2: 0.054658\tvalid_0's binary_logloss: 0.206244\n",
      "[43]\tvalid_0's l2: 0.0547902\tvalid_0's binary_logloss: 0.206523\n",
      "[44]\tvalid_0's l2: 0.0538181\tvalid_0's binary_logloss: 0.202953\n",
      "[45]\tvalid_0's l2: 0.0530461\tvalid_0's binary_logloss: 0.201361\n",
      "[46]\tvalid_0's l2: 0.0530285\tvalid_0's binary_logloss: 0.201463\n",
      "[47]\tvalid_0's l2: 0.0527426\tvalid_0's binary_logloss: 0.201802\n",
      "[48]\tvalid_0's l2: 0.0523286\tvalid_0's binary_logloss: 0.200398\n",
      "[49]\tvalid_0's l2: 0.0521028\tvalid_0's binary_logloss: 0.200171\n",
      "[50]\tvalid_0's l2: 0.0520387\tvalid_0's binary_logloss: 0.199769\n",
      "[51]\tvalid_0's l2: 0.0514915\tvalid_0's binary_logloss: 0.197919\n",
      "[52]\tvalid_0's l2: 0.0516663\tvalid_0's binary_logloss: 0.199075\n",
      "[53]\tvalid_0's l2: 0.0518288\tvalid_0's binary_logloss: 0.199165\n",
      "[54]\tvalid_0's l2: 0.0514876\tvalid_0's binary_logloss: 0.198291\n",
      "[55]\tvalid_0's l2: 0.050991\tvalid_0's binary_logloss: 0.195478\n",
      "[56]\tvalid_0's l2: 0.0508167\tvalid_0's binary_logloss: 0.195204\n",
      "[57]\tvalid_0's l2: 0.0502715\tvalid_0's binary_logloss: 0.194275\n",
      "[58]\tvalid_0's l2: 0.0503193\tvalid_0's binary_logloss: 0.194279\n",
      "[59]\tvalid_0's l2: 0.0503238\tvalid_0's binary_logloss: 0.194346\n",
      "[60]\tvalid_0's l2: 0.0499383\tvalid_0's binary_logloss: 0.193175\n",
      "[61]\tvalid_0's l2: 0.0499374\tvalid_0's binary_logloss: 0.192763\n",
      "[62]\tvalid_0's l2: 0.0499222\tvalid_0's binary_logloss: 0.193409\n",
      "[63]\tvalid_0's l2: 0.0497108\tvalid_0's binary_logloss: 0.193161\n",
      "[64]\tvalid_0's l2: 0.0497125\tvalid_0's binary_logloss: 0.193417\n",
      "[65]\tvalid_0's l2: 0.0497377\tvalid_0's binary_logloss: 0.193446\n",
      "[66]\tvalid_0's l2: 0.0496762\tvalid_0's binary_logloss: 0.191909\n",
      "[67]\tvalid_0's l2: 0.0493015\tvalid_0's binary_logloss: 0.191921\n",
      "[68]\tvalid_0's l2: 0.0485789\tvalid_0's binary_logloss: 0.190187\n",
      "[69]\tvalid_0's l2: 0.0485504\tvalid_0's binary_logloss: 0.190063\n",
      "[70]\tvalid_0's l2: 0.0485574\tvalid_0's binary_logloss: 0.190246\n",
      "[71]\tvalid_0's l2: 0.0483385\tvalid_0's binary_logloss: 0.189247\n",
      "[72]\tvalid_0's l2: 0.0481867\tvalid_0's binary_logloss: 0.188637\n",
      "[73]\tvalid_0's l2: 0.0483666\tvalid_0's binary_logloss: 0.188689\n",
      "[74]\tvalid_0's l2: 0.0484186\tvalid_0's binary_logloss: 0.188959\n",
      "[75]\tvalid_0's l2: 0.048207\tvalid_0's binary_logloss: 0.188889\n",
      "[76]\tvalid_0's l2: 0.0481125\tvalid_0's binary_logloss: 0.188871\n",
      "[77]\tvalid_0's l2: 0.0480655\tvalid_0's binary_logloss: 0.188865\n",
      "[78]\tvalid_0's l2: 0.0481888\tvalid_0's binary_logloss: 0.189332\n",
      "[79]\tvalid_0's l2: 0.0480513\tvalid_0's binary_logloss: 0.189407\n",
      "[80]\tvalid_0's l2: 0.048124\tvalid_0's binary_logloss: 0.189832\n",
      "[81]\tvalid_0's l2: 0.0482017\tvalid_0's binary_logloss: 0.190069\n",
      "[82]\tvalid_0's l2: 0.0482416\tvalid_0's binary_logloss: 0.188981\n",
      "[83]\tvalid_0's l2: 0.0482601\tvalid_0's binary_logloss: 0.188759\n",
      "[84]\tvalid_0's l2: 0.0484333\tvalid_0's binary_logloss: 0.189045\n",
      "[85]\tvalid_0's l2: 0.0485673\tvalid_0's binary_logloss: 0.189382\n",
      "[86]\tvalid_0's l2: 0.0482421\tvalid_0's binary_logloss: 0.189209\n",
      "[87]\tvalid_0's l2: 0.0484034\tvalid_0's binary_logloss: 0.189557\n",
      "[88]\tvalid_0's l2: 0.0485077\tvalid_0's binary_logloss: 0.189623\n",
      "[89]\tvalid_0's l2: 0.0484892\tvalid_0's binary_logloss: 0.189477\n",
      "[90]\tvalid_0's l2: 0.0485709\tvalid_0's binary_logloss: 0.189651\n",
      "[91]\tvalid_0's l2: 0.0485007\tvalid_0's binary_logloss: 0.189288\n",
      "[92]\tvalid_0's l2: 0.0489294\tvalid_0's binary_logloss: 0.19087\n",
      "[93]\tvalid_0's l2: 0.0492734\tvalid_0's binary_logloss: 0.191839\n",
      "[94]\tvalid_0's l2: 0.0491925\tvalid_0's binary_logloss: 0.191245\n",
      "[95]\tvalid_0's l2: 0.0492063\tvalid_0's binary_logloss: 0.191023\n",
      "[96]\tvalid_0's l2: 0.0492035\tvalid_0's binary_logloss: 0.19107\n",
      "[97]\tvalid_0's l2: 0.0488429\tvalid_0's binary_logloss: 0.189863\n",
      "[98]\tvalid_0's l2: 0.0490438\tvalid_0's binary_logloss: 0.190263\n",
      "[99]\tvalid_0's l2: 0.0487571\tvalid_0's binary_logloss: 0.1899\n",
      "[100]\tvalid_0's l2: 0.0487383\tvalid_0's binary_logloss: 0.191267\n",
      "[101]\tvalid_0's l2: 0.0487777\tvalid_0's binary_logloss: 0.190974\n",
      "[102]\tvalid_0's l2: 0.0488654\tvalid_0's binary_logloss: 0.191116\n",
      "[103]\tvalid_0's l2: 0.048918\tvalid_0's binary_logloss: 0.191163\n",
      "[104]\tvalid_0's l2: 0.048879\tvalid_0's binary_logloss: 0.190651\n",
      "[105]\tvalid_0's l2: 0.0488664\tvalid_0's binary_logloss: 0.190496\n",
      "[106]\tvalid_0's l2: 0.0489165\tvalid_0's binary_logloss: 0.19064\n",
      "[107]\tvalid_0's l2: 0.048962\tvalid_0's binary_logloss: 0.190727\n",
      "[108]\tvalid_0's l2: 0.0485069\tvalid_0's binary_logloss: 0.189744\n",
      "[109]\tvalid_0's l2: 0.0485535\tvalid_0's binary_logloss: 0.190054\n",
      "[110]\tvalid_0's l2: 0.0486151\tvalid_0's binary_logloss: 0.190316\n",
      "[111]\tvalid_0's l2: 0.0491341\tvalid_0's binary_logloss: 0.192491\n",
      "[112]\tvalid_0's l2: 0.0492556\tvalid_0's binary_logloss: 0.193308\n",
      "[113]\tvalid_0's l2: 0.0493828\tvalid_0's binary_logloss: 0.193168\n",
      "[114]\tvalid_0's l2: 0.0496112\tvalid_0's binary_logloss: 0.193245\n",
      "[115]\tvalid_0's l2: 0.0491058\tvalid_0's binary_logloss: 0.191665\n",
      "[116]\tvalid_0's l2: 0.0492928\tvalid_0's binary_logloss: 0.19312\n",
      "[117]\tvalid_0's l2: 0.0492055\tvalid_0's binary_logloss: 0.192669\n",
      "[118]\tvalid_0's l2: 0.0489746\tvalid_0's binary_logloss: 0.193634\n",
      "[119]\tvalid_0's l2: 0.0490268\tvalid_0's binary_logloss: 0.193431\n",
      "[120]\tvalid_0's l2: 0.0490273\tvalid_0's binary_logloss: 0.193118\n",
      "[121]\tvalid_0's l2: 0.0489996\tvalid_0's binary_logloss: 0.192795\n",
      "[122]\tvalid_0's l2: 0.0490754\tvalid_0's binary_logloss: 0.19282\n",
      "[123]\tvalid_0's l2: 0.0490762\tvalid_0's binary_logloss: 0.193281\n",
      "[124]\tvalid_0's l2: 0.048954\tvalid_0's binary_logloss: 0.193222\n",
      "[125]\tvalid_0's l2: 0.0489266\tvalid_0's binary_logloss: 0.192804\n",
      "[126]\tvalid_0's l2: 0.0489201\tvalid_0's binary_logloss: 0.19281\n",
      "[127]\tvalid_0's l2: 0.0488414\tvalid_0's binary_logloss: 0.192809\n",
      "[128]\tvalid_0's l2: 0.0489026\tvalid_0's binary_logloss: 0.193005\n",
      "[129]\tvalid_0's l2: 0.0490644\tvalid_0's binary_logloss: 0.194983\n",
      "[130]\tvalid_0's l2: 0.0487796\tvalid_0's binary_logloss: 0.19485\n",
      "[131]\tvalid_0's l2: 0.048738\tvalid_0's binary_logloss: 0.194332\n",
      "[132]\tvalid_0's l2: 0.0489267\tvalid_0's binary_logloss: 0.195453\n",
      "[133]\tvalid_0's l2: 0.0488666\tvalid_0's binary_logloss: 0.195866\n",
      "[134]\tvalid_0's l2: 0.0489115\tvalid_0's binary_logloss: 0.19566\n",
      "[135]\tvalid_0's l2: 0.0491461\tvalid_0's binary_logloss: 0.196071\n",
      "[136]\tvalid_0's l2: 0.0490544\tvalid_0's binary_logloss: 0.195255\n",
      "[137]\tvalid_0's l2: 0.0490824\tvalid_0's binary_logloss: 0.195074\n",
      "[138]\tvalid_0's l2: 0.0483678\tvalid_0's binary_logloss: 0.193352\n",
      "[139]\tvalid_0's l2: 0.0480455\tvalid_0's binary_logloss: 0.192711\n",
      "[140]\tvalid_0's l2: 0.0481181\tvalid_0's binary_logloss: 0.192624\n",
      "[141]\tvalid_0's l2: 0.0481739\tvalid_0's binary_logloss: 0.192455\n",
      "[142]\tvalid_0's l2: 0.0481495\tvalid_0's binary_logloss: 0.192146\n",
      "[143]\tvalid_0's l2: 0.048036\tvalid_0's binary_logloss: 0.193078\n",
      "[144]\tvalid_0's l2: 0.0480689\tvalid_0's binary_logloss: 0.192942\n",
      "[145]\tvalid_0's l2: 0.0486948\tvalid_0's binary_logloss: 0.196447\n",
      "[146]\tvalid_0's l2: 0.0486397\tvalid_0's binary_logloss: 0.195797\n",
      "[147]\tvalid_0's l2: 0.0486836\tvalid_0's binary_logloss: 0.195484\n",
      "[148]\tvalid_0's l2: 0.0487053\tvalid_0's binary_logloss: 0.195447\n",
      "[149]\tvalid_0's l2: 0.0488453\tvalid_0's binary_logloss: 0.196831\n",
      "[150]\tvalid_0's l2: 0.0490434\tvalid_0's binary_logloss: 0.19831\n",
      "[151]\tvalid_0's l2: 0.0490467\tvalid_0's binary_logloss: 0.197884\n",
      "[152]\tvalid_0's l2: 0.0490739\tvalid_0's binary_logloss: 0.197645\n",
      "[153]\tvalid_0's l2: 0.0488987\tvalid_0's binary_logloss: 0.196412\n",
      "[154]\tvalid_0's l2: 0.048935\tvalid_0's binary_logloss: 0.196284\n",
      "[155]\tvalid_0's l2: 0.0489289\tvalid_0's binary_logloss: 0.196732\n",
      "[156]\tvalid_0's l2: 0.0489156\tvalid_0's binary_logloss: 0.196259\n",
      "[157]\tvalid_0's l2: 0.0487873\tvalid_0's binary_logloss: 0.19552\n",
      "[158]\tvalid_0's l2: 0.0487974\tvalid_0's binary_logloss: 0.195281\n",
      "[159]\tvalid_0's l2: 0.0488362\tvalid_0's binary_logloss: 0.195045\n",
      "[160]\tvalid_0's l2: 0.0488581\tvalid_0's binary_logloss: 0.194858\n",
      "[161]\tvalid_0's l2: 0.0481546\tvalid_0's binary_logloss: 0.193825\n",
      "[162]\tvalid_0's l2: 0.0482261\tvalid_0's binary_logloss: 0.194039\n",
      "[163]\tvalid_0's l2: 0.0480041\tvalid_0's binary_logloss: 0.194138\n",
      "[164]\tvalid_0's l2: 0.0483035\tvalid_0's binary_logloss: 0.196371\n",
      "[165]\tvalid_0's l2: 0.0482809\tvalid_0's binary_logloss: 0.196556\n",
      "[166]\tvalid_0's l2: 0.0483592\tvalid_0's binary_logloss: 0.196814\n",
      "[167]\tvalid_0's l2: 0.0485079\tvalid_0's binary_logloss: 0.197957\n",
      "[168]\tvalid_0's l2: 0.048756\tvalid_0's binary_logloss: 0.199314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.210235\tvalid_0's binary_logloss: 0.612659\n",
      "[2]\tvalid_0's l2: 0.181005\tvalid_0's binary_logloss: 0.550685\n",
      "[3]\tvalid_0's l2: 0.166278\tvalid_0's binary_logloss: 0.516942\n",
      "[4]\tvalid_0's l2: 0.148456\tvalid_0's binary_logloss: 0.475951\n",
      "[5]\tvalid_0's l2: 0.136093\tvalid_0's binary_logloss: 0.444722\n",
      "[6]\tvalid_0's l2: 0.125422\tvalid_0's binary_logloss: 0.417113\n",
      "[7]\tvalid_0's l2: 0.114998\tvalid_0's binary_logloss: 0.389389\n",
      "[8]\tvalid_0's l2: 0.117498\tvalid_0's binary_logloss: 0.397342\n",
      "[9]\tvalid_0's l2: 0.107256\tvalid_0's binary_logloss: 0.370104\n",
      "[10]\tvalid_0's l2: 0.0979871\tvalid_0's binary_logloss: 0.344938\n",
      "[11]\tvalid_0's l2: 0.0922764\tvalid_0's binary_logloss: 0.327595\n",
      "[12]\tvalid_0's l2: 0.0928769\tvalid_0's binary_logloss: 0.331491\n",
      "[13]\tvalid_0's l2: 0.0866294\tvalid_0's binary_logloss: 0.313357\n",
      "[14]\tvalid_0's l2: 0.0826975\tvalid_0's binary_logloss: 0.300983\n",
      "[15]\tvalid_0's l2: 0.0805447\tvalid_0's binary_logloss: 0.293602\n",
      "[16]\tvalid_0's l2: 0.0778621\tvalid_0's binary_logloss: 0.284266\n",
      "[17]\tvalid_0's l2: 0.0755736\tvalid_0's binary_logloss: 0.274659\n",
      "[18]\tvalid_0's l2: 0.0732193\tvalid_0's binary_logloss: 0.26754\n",
      "[19]\tvalid_0's l2: 0.0701364\tvalid_0's binary_logloss: 0.259314\n",
      "[20]\tvalid_0's l2: 0.0680118\tvalid_0's binary_logloss: 0.25209\n",
      "[21]\tvalid_0's l2: 0.068207\tvalid_0's binary_logloss: 0.253578\n",
      "[22]\tvalid_0's l2: 0.0669554\tvalid_0's binary_logloss: 0.249244\n",
      "[23]\tvalid_0's l2: 0.0649087\tvalid_0's binary_logloss: 0.242848\n",
      "[24]\tvalid_0's l2: 0.0625783\tvalid_0's binary_logloss: 0.235639\n",
      "[25]\tvalid_0's l2: 0.0618186\tvalid_0's binary_logloss: 0.231521\n",
      "[26]\tvalid_0's l2: 0.060137\tvalid_0's binary_logloss: 0.227057\n",
      "[27]\tvalid_0's l2: 0.0593525\tvalid_0's binary_logloss: 0.223351\n",
      "[28]\tvalid_0's l2: 0.0593492\tvalid_0's binary_logloss: 0.223666\n",
      "[29]\tvalid_0's l2: 0.05836\tvalid_0's binary_logloss: 0.220938\n",
      "[30]\tvalid_0's l2: 0.0572664\tvalid_0's binary_logloss: 0.217636\n",
      "[31]\tvalid_0's l2: 0.0567401\tvalid_0's binary_logloss: 0.216122\n",
      "[32]\tvalid_0's l2: 0.0565295\tvalid_0's binary_logloss: 0.214265\n",
      "[33]\tvalid_0's l2: 0.0563621\tvalid_0's binary_logloss: 0.212995\n",
      "[34]\tvalid_0's l2: 0.05538\tvalid_0's binary_logloss: 0.208412\n",
      "[35]\tvalid_0's l2: 0.0554799\tvalid_0's binary_logloss: 0.209217\n",
      "[36]\tvalid_0's l2: 0.0555458\tvalid_0's binary_logloss: 0.209679\n",
      "[37]\tvalid_0's l2: 0.055358\tvalid_0's binary_logloss: 0.207788\n",
      "[38]\tvalid_0's l2: 0.0545008\tvalid_0's binary_logloss: 0.204174\n",
      "[39]\tvalid_0's l2: 0.0548936\tvalid_0's binary_logloss: 0.206107\n",
      "[40]\tvalid_0's l2: 0.0546624\tvalid_0's binary_logloss: 0.205495\n",
      "[41]\tvalid_0's l2: 0.0548913\tvalid_0's binary_logloss: 0.206137\n",
      "[42]\tvalid_0's l2: 0.054658\tvalid_0's binary_logloss: 0.206244\n",
      "[43]\tvalid_0's l2: 0.0547902\tvalid_0's binary_logloss: 0.206523\n",
      "[44]\tvalid_0's l2: 0.0538181\tvalid_0's binary_logloss: 0.202953\n",
      "[45]\tvalid_0's l2: 0.0530461\tvalid_0's binary_logloss: 0.201361\n",
      "[46]\tvalid_0's l2: 0.0530285\tvalid_0's binary_logloss: 0.201463\n",
      "[47]\tvalid_0's l2: 0.0527426\tvalid_0's binary_logloss: 0.201802\n",
      "[48]\tvalid_0's l2: 0.0523286\tvalid_0's binary_logloss: 0.200398\n",
      "[49]\tvalid_0's l2: 0.0521028\tvalid_0's binary_logloss: 0.200171\n",
      "[50]\tvalid_0's l2: 0.0520387\tvalid_0's binary_logloss: 0.199769\n",
      "[51]\tvalid_0's l2: 0.0514915\tvalid_0's binary_logloss: 0.197919\n",
      "[52]\tvalid_0's l2: 0.0516663\tvalid_0's binary_logloss: 0.199075\n",
      "[53]\tvalid_0's l2: 0.0518288\tvalid_0's binary_logloss: 0.199165\n",
      "[54]\tvalid_0's l2: 0.0514876\tvalid_0's binary_logloss: 0.198291\n",
      "[55]\tvalid_0's l2: 0.050991\tvalid_0's binary_logloss: 0.195478\n",
      "[56]\tvalid_0's l2: 0.0508167\tvalid_0's binary_logloss: 0.195204\n",
      "[57]\tvalid_0's l2: 0.0502715\tvalid_0's binary_logloss: 0.194275\n",
      "[58]\tvalid_0's l2: 0.0503193\tvalid_0's binary_logloss: 0.194279\n",
      "[59]\tvalid_0's l2: 0.0503238\tvalid_0's binary_logloss: 0.194346\n",
      "[60]\tvalid_0's l2: 0.0499383\tvalid_0's binary_logloss: 0.193175\n",
      "[61]\tvalid_0's l2: 0.0499374\tvalid_0's binary_logloss: 0.192763\n",
      "[62]\tvalid_0's l2: 0.0499222\tvalid_0's binary_logloss: 0.193409\n",
      "[63]\tvalid_0's l2: 0.0497108\tvalid_0's binary_logloss: 0.193161\n",
      "[64]\tvalid_0's l2: 0.0497125\tvalid_0's binary_logloss: 0.193417\n",
      "[65]\tvalid_0's l2: 0.0497377\tvalid_0's binary_logloss: 0.193446\n",
      "[66]\tvalid_0's l2: 0.0496762\tvalid_0's binary_logloss: 0.191909\n",
      "[67]\tvalid_0's l2: 0.0493015\tvalid_0's binary_logloss: 0.191921\n",
      "[68]\tvalid_0's l2: 0.0485789\tvalid_0's binary_logloss: 0.190187\n",
      "[69]\tvalid_0's l2: 0.0485504\tvalid_0's binary_logloss: 0.190063\n",
      "[70]\tvalid_0's l2: 0.0485574\tvalid_0's binary_logloss: 0.190246\n",
      "[71]\tvalid_0's l2: 0.0483385\tvalid_0's binary_logloss: 0.189247\n",
      "[72]\tvalid_0's l2: 0.0481867\tvalid_0's binary_logloss: 0.188637\n",
      "[73]\tvalid_0's l2: 0.0483666\tvalid_0's binary_logloss: 0.188689\n",
      "[74]\tvalid_0's l2: 0.0484186\tvalid_0's binary_logloss: 0.188959\n",
      "[75]\tvalid_0's l2: 0.048207\tvalid_0's binary_logloss: 0.188889\n",
      "[76]\tvalid_0's l2: 0.0481125\tvalid_0's binary_logloss: 0.188871\n",
      "[77]\tvalid_0's l2: 0.0480655\tvalid_0's binary_logloss: 0.188865\n",
      "[78]\tvalid_0's l2: 0.0481888\tvalid_0's binary_logloss: 0.189332\n",
      "[79]\tvalid_0's l2: 0.0480513\tvalid_0's binary_logloss: 0.189407\n",
      "[80]\tvalid_0's l2: 0.048124\tvalid_0's binary_logloss: 0.189832\n",
      "[81]\tvalid_0's l2: 0.0482017\tvalid_0's binary_logloss: 0.190069\n",
      "[82]\tvalid_0's l2: 0.0482416\tvalid_0's binary_logloss: 0.188981\n",
      "[83]\tvalid_0's l2: 0.0482601\tvalid_0's binary_logloss: 0.188759\n",
      "[84]\tvalid_0's l2: 0.0484333\tvalid_0's binary_logloss: 0.189045\n",
      "[85]\tvalid_0's l2: 0.0485673\tvalid_0's binary_logloss: 0.189382\n",
      "[86]\tvalid_0's l2: 0.0482421\tvalid_0's binary_logloss: 0.189209\n",
      "[87]\tvalid_0's l2: 0.0484034\tvalid_0's binary_logloss: 0.189557\n",
      "[88]\tvalid_0's l2: 0.0485077\tvalid_0's binary_logloss: 0.189623\n",
      "[89]\tvalid_0's l2: 0.0484892\tvalid_0's binary_logloss: 0.189477\n",
      "[90]\tvalid_0's l2: 0.0485709\tvalid_0's binary_logloss: 0.189651\n",
      "[91]\tvalid_0's l2: 0.0485007\tvalid_0's binary_logloss: 0.189288\n",
      "[92]\tvalid_0's l2: 0.0489294\tvalid_0's binary_logloss: 0.19087\n",
      "[93]\tvalid_0's l2: 0.0492734\tvalid_0's binary_logloss: 0.191839\n",
      "[94]\tvalid_0's l2: 0.0491925\tvalid_0's binary_logloss: 0.191245\n",
      "[95]\tvalid_0's l2: 0.0492063\tvalid_0's binary_logloss: 0.191023\n",
      "[96]\tvalid_0's l2: 0.0492035\tvalid_0's binary_logloss: 0.19107\n",
      "[97]\tvalid_0's l2: 0.0488429\tvalid_0's binary_logloss: 0.189863\n",
      "[98]\tvalid_0's l2: 0.0490438\tvalid_0's binary_logloss: 0.190263\n",
      "[99]\tvalid_0's l2: 0.0487571\tvalid_0's binary_logloss: 0.1899\n",
      "[100]\tvalid_0's l2: 0.0487383\tvalid_0's binary_logloss: 0.191267\n",
      "[101]\tvalid_0's l2: 0.0487777\tvalid_0's binary_logloss: 0.190974\n",
      "[102]\tvalid_0's l2: 0.0488654\tvalid_0's binary_logloss: 0.191116\n",
      "[103]\tvalid_0's l2: 0.048918\tvalid_0's binary_logloss: 0.191163\n",
      "[104]\tvalid_0's l2: 0.048879\tvalid_0's binary_logloss: 0.190651\n",
      "[105]\tvalid_0's l2: 0.0488664\tvalid_0's binary_logloss: 0.190496\n",
      "[106]\tvalid_0's l2: 0.0489165\tvalid_0's binary_logloss: 0.19064\n",
      "[107]\tvalid_0's l2: 0.048962\tvalid_0's binary_logloss: 0.190727\n",
      "[108]\tvalid_0's l2: 0.0485069\tvalid_0's binary_logloss: 0.189744\n",
      "[109]\tvalid_0's l2: 0.0485535\tvalid_0's binary_logloss: 0.190054\n",
      "[110]\tvalid_0's l2: 0.0486151\tvalid_0's binary_logloss: 0.190316\n",
      "[111]\tvalid_0's l2: 0.0491341\tvalid_0's binary_logloss: 0.192491\n",
      "[112]\tvalid_0's l2: 0.0492556\tvalid_0's binary_logloss: 0.193308\n",
      "[113]\tvalid_0's l2: 0.0493828\tvalid_0's binary_logloss: 0.193168\n",
      "[114]\tvalid_0's l2: 0.0496112\tvalid_0's binary_logloss: 0.193245\n",
      "[115]\tvalid_0's l2: 0.0491058\tvalid_0's binary_logloss: 0.191665\n",
      "[116]\tvalid_0's l2: 0.0492928\tvalid_0's binary_logloss: 0.19312\n",
      "[117]\tvalid_0's l2: 0.0492055\tvalid_0's binary_logloss: 0.192669\n",
      "[118]\tvalid_0's l2: 0.0489746\tvalid_0's binary_logloss: 0.193634\n",
      "[119]\tvalid_0's l2: 0.0490268\tvalid_0's binary_logloss: 0.193431\n",
      "[120]\tvalid_0's l2: 0.0490273\tvalid_0's binary_logloss: 0.193118\n",
      "[121]\tvalid_0's l2: 0.0489996\tvalid_0's binary_logloss: 0.192795\n",
      "[122]\tvalid_0's l2: 0.0490754\tvalid_0's binary_logloss: 0.19282\n",
      "[123]\tvalid_0's l2: 0.0490762\tvalid_0's binary_logloss: 0.193281\n",
      "[124]\tvalid_0's l2: 0.048954\tvalid_0's binary_logloss: 0.193222\n",
      "[125]\tvalid_0's l2: 0.0489266\tvalid_0's binary_logloss: 0.192804\n",
      "[126]\tvalid_0's l2: 0.0489201\tvalid_0's binary_logloss: 0.19281\n",
      "[127]\tvalid_0's l2: 0.0488414\tvalid_0's binary_logloss: 0.192809\n",
      "[128]\tvalid_0's l2: 0.0489026\tvalid_0's binary_logloss: 0.193005\n",
      "[129]\tvalid_0's l2: 0.0490644\tvalid_0's binary_logloss: 0.194983\n",
      "[130]\tvalid_0's l2: 0.0487796\tvalid_0's binary_logloss: 0.19485\n",
      "[131]\tvalid_0's l2: 0.048738\tvalid_0's binary_logloss: 0.194332\n",
      "[132]\tvalid_0's l2: 0.0489267\tvalid_0's binary_logloss: 0.195453\n",
      "[133]\tvalid_0's l2: 0.0488666\tvalid_0's binary_logloss: 0.195866\n",
      "[134]\tvalid_0's l2: 0.0489115\tvalid_0's binary_logloss: 0.19566\n",
      "[135]\tvalid_0's l2: 0.0491461\tvalid_0's binary_logloss: 0.196071\n",
      "[136]\tvalid_0's l2: 0.0490544\tvalid_0's binary_logloss: 0.195255\n",
      "[137]\tvalid_0's l2: 0.0490824\tvalid_0's binary_logloss: 0.195074\n",
      "[138]\tvalid_0's l2: 0.0483678\tvalid_0's binary_logloss: 0.193352\n",
      "[139]\tvalid_0's l2: 0.0480455\tvalid_0's binary_logloss: 0.192711\n",
      "[140]\tvalid_0's l2: 0.0481181\tvalid_0's binary_logloss: 0.192624\n",
      "[141]\tvalid_0's l2: 0.0481739\tvalid_0's binary_logloss: 0.192455\n",
      "[142]\tvalid_0's l2: 0.0481495\tvalid_0's binary_logloss: 0.192146\n",
      "[143]\tvalid_0's l2: 0.048036\tvalid_0's binary_logloss: 0.193078\n",
      "[144]\tvalid_0's l2: 0.0480689\tvalid_0's binary_logloss: 0.192942\n",
      "[145]\tvalid_0's l2: 0.0486948\tvalid_0's binary_logloss: 0.196447\n",
      "[146]\tvalid_0's l2: 0.0486397\tvalid_0's binary_logloss: 0.195797\n",
      "[147]\tvalid_0's l2: 0.0486836\tvalid_0's binary_logloss: 0.195484\n",
      "[148]\tvalid_0's l2: 0.0487053\tvalid_0's binary_logloss: 0.195447\n",
      "[149]\tvalid_0's l2: 0.0488453\tvalid_0's binary_logloss: 0.196831\n",
      "[150]\tvalid_0's l2: 0.0490434\tvalid_0's binary_logloss: 0.19831\n",
      "[151]\tvalid_0's l2: 0.0490467\tvalid_0's binary_logloss: 0.197884\n",
      "[152]\tvalid_0's l2: 0.0490739\tvalid_0's binary_logloss: 0.197645\n",
      "[153]\tvalid_0's l2: 0.0488987\tvalid_0's binary_logloss: 0.196412\n",
      "[154]\tvalid_0's l2: 0.048935\tvalid_0's binary_logloss: 0.196284\n",
      "[155]\tvalid_0's l2: 0.0489289\tvalid_0's binary_logloss: 0.196732\n",
      "[156]\tvalid_0's l2: 0.0489156\tvalid_0's binary_logloss: 0.196259\n",
      "[157]\tvalid_0's l2: 0.0487873\tvalid_0's binary_logloss: 0.19552\n",
      "[158]\tvalid_0's l2: 0.0487974\tvalid_0's binary_logloss: 0.195281\n",
      "[159]\tvalid_0's l2: 0.0488362\tvalid_0's binary_logloss: 0.195045\n",
      "[160]\tvalid_0's l2: 0.0488581\tvalid_0's binary_logloss: 0.194858\n",
      "[161]\tvalid_0's l2: 0.0481546\tvalid_0's binary_logloss: 0.193825\n",
      "[162]\tvalid_0's l2: 0.0482261\tvalid_0's binary_logloss: 0.194039\n",
      "[163]\tvalid_0's l2: 0.0480041\tvalid_0's binary_logloss: 0.194138\n",
      "---- Train error ----\n",
      "0.0025378074288013182\n",
      "---- CV error ----\n",
      "0.04727024685547668\n",
      "---- leaderboard stats ----\n",
      "0.004542706591190493\n",
      "0.05315720683920307\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2177  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.233   \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1951  \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.1857  \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1888  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2097  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.229   \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2448  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1872  \u001b[0m | \u001b[0m 0.6773  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 8.366   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 231.3   \u001b[0m | \u001b[0m 86.77   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 0.2893  \u001b[0m | \u001b[0m 0.9537  \u001b[0m | \u001b[0m 0.8583  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1987  \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 0.1184  \u001b[0m | \u001b[0m 14.03   \u001b[0m | \u001b[0m 77.84   \u001b[0m | \u001b[0m 450.4   \u001b[0m | \u001b[0m 163.5   \u001b[0m | \u001b[0m 23.09   \u001b[0m | \u001b[0m 0.08503 \u001b[0m | \u001b[0m 0.6847  \u001b[0m | \u001b[0m 0.8547  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1866  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.1837  \u001b[0m | \u001b[95m 0.8499  \u001b[0m | \u001b[95m 0.1405  \u001b[0m | \u001b[95m 10.97   \u001b[0m | \u001b[95m 13.55   \u001b[0m | \u001b[95m 498.3   \u001b[0m | \u001b[95m 101.9   \u001b[0m | \u001b[95m 28.24   \u001b[0m | \u001b[95m 0.5572  \u001b[0m | \u001b[95m 0.6208  \u001b[0m | \u001b[95m 0.574   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1992  \u001b[0m | \u001b[0m 0.9346  \u001b[0m | \u001b[0m 0.03904 \u001b[0m | \u001b[0m 7.231   \u001b[0m | \u001b[0m 11.85   \u001b[0m | \u001b[0m 499.2   \u001b[0m | \u001b[0m 94.7    \u001b[0m | \u001b[0m 26.17   \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 0.492   \u001b[0m | \u001b[0m 0.9129  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1832  \u001b[0m | \u001b[95m 0.8676  \u001b[0m | \u001b[95m 0.1613  \u001b[0m | \u001b[95m 14.41   \u001b[0m | \u001b[95m 13.97   \u001b[0m | \u001b[95m 472.8   \u001b[0m | \u001b[95m 123.9   \u001b[0m | \u001b[95m 29.08   \u001b[0m | \u001b[95m 0.5245  \u001b[0m | \u001b[95m 0.9207  \u001b[0m | \u001b[95m 0.6058  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2194  \u001b[0m | \u001b[0m 0.5463  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 2.422   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 78.7    \u001b[0m | \u001b[0m 15.77   \u001b[0m | \u001b[0m 0.3688  \u001b[0m | \u001b[0m 0.1773  \u001b[0m | \u001b[0m 0.8557  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1894  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2029  \u001b[0m | \u001b[0m 0.8056  \u001b[0m | \u001b[0m 0.04307 \u001b[0m | \u001b[0m 6.217   \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 228.3   \u001b[0m | \u001b[0m 82.94   \u001b[0m | \u001b[0m 25.62   \u001b[0m | \u001b[0m 0.1261  \u001b[0m | \u001b[0m 0.3898  \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2331  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2354  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.183   \u001b[0m | \u001b[95m 0.7273  \u001b[0m | \u001b[95m 0.1974  \u001b[0m | \u001b[95m 9.822   \u001b[0m | \u001b[95m 14.51   \u001b[0m | \u001b[95m 493.2   \u001b[0m | \u001b[95m 110.4   \u001b[0m | \u001b[95m 25.7    \u001b[0m | \u001b[95m 0.5391  \u001b[0m | \u001b[95m 0.6971  \u001b[0m | \u001b[95m 0.5694  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.1830303226315921, 'params': {'colsample_bytree': 0.7272814048314897, 'learning_rate': 0.19743811005355721, 'max_depth': 9.822447390041646, 'min_child_samples': 14.51286322367331, 'n_estimators': 493.2196426813407, 'num_iteration': 110.4227901821076, 'num_leaves': 25.70452117611649, 'reg_alpha': 0.539053674091004, 'reg_lambda': 0.6971236255441822, 'subsample': 0.5693663005698526}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=110, num_iteration=110 will be ignored. Current value: num_iterations=110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.239215\tvalid_0's binary_logloss: 0.671271\n",
      "[2]\tvalid_0's l2: 0.229989\tvalid_0's binary_logloss: 0.652191\n",
      "[3]\tvalid_0's l2: 0.227566\tvalid_0's binary_logloss: 0.646553\n",
      "[4]\tvalid_0's l2: 0.227117\tvalid_0's binary_logloss: 0.64475\n",
      "[5]\tvalid_0's l2: 0.219246\tvalid_0's binary_logloss: 0.628301\n",
      "[6]\tvalid_0's l2: 0.212807\tvalid_0's binary_logloss: 0.614406\n",
      "[7]\tvalid_0's l2: 0.207795\tvalid_0's binary_logloss: 0.604323\n",
      "[8]\tvalid_0's l2: 0.210239\tvalid_0's binary_logloss: 0.60974\n",
      "[9]\tvalid_0's l2: 0.208312\tvalid_0's binary_logloss: 0.605209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10]\tvalid_0's l2: 0.200512\tvalid_0's binary_logloss: 0.588141\n",
      "[11]\tvalid_0's l2: 0.197684\tvalid_0's binary_logloss: 0.580827\n",
      "[12]\tvalid_0's l2: 0.196725\tvalid_0's binary_logloss: 0.579384\n",
      "[13]\tvalid_0's l2: 0.191566\tvalid_0's binary_logloss: 0.568209\n",
      "[14]\tvalid_0's l2: 0.189067\tvalid_0's binary_logloss: 0.561858\n",
      "[15]\tvalid_0's l2: 0.18596\tvalid_0's binary_logloss: 0.55384\n",
      "[16]\tvalid_0's l2: 0.187686\tvalid_0's binary_logloss: 0.556836\n",
      "[17]\tvalid_0's l2: 0.1871\tvalid_0's binary_logloss: 0.554754\n",
      "[18]\tvalid_0's l2: 0.183839\tvalid_0's binary_logloss: 0.548162\n",
      "[19]\tvalid_0's l2: 0.181795\tvalid_0's binary_logloss: 0.543169\n",
      "[20]\tvalid_0's l2: 0.180738\tvalid_0's binary_logloss: 0.54171\n",
      "[21]\tvalid_0's l2: 0.180215\tvalid_0's binary_logloss: 0.540635\n",
      "[22]\tvalid_0's l2: 0.18061\tvalid_0's binary_logloss: 0.541834\n",
      "[23]\tvalid_0's l2: 0.18177\tvalid_0's binary_logloss: 0.545067\n",
      "[24]\tvalid_0's l2: 0.182703\tvalid_0's binary_logloss: 0.54572\n",
      "[25]\tvalid_0's l2: 0.181199\tvalid_0's binary_logloss: 0.543306\n",
      "[26]\tvalid_0's l2: 0.180493\tvalid_0's binary_logloss: 0.542708\n",
      "[27]\tvalid_0's l2: 0.180411\tvalid_0's binary_logloss: 0.542797\n",
      "[28]\tvalid_0's l2: 0.180719\tvalid_0's binary_logloss: 0.543691\n",
      "[29]\tvalid_0's l2: 0.178495\tvalid_0's binary_logloss: 0.53815\n",
      "[30]\tvalid_0's l2: 0.177193\tvalid_0's binary_logloss: 0.534471\n",
      "[31]\tvalid_0's l2: 0.176468\tvalid_0's binary_logloss: 0.53361\n",
      "[32]\tvalid_0's l2: 0.176151\tvalid_0's binary_logloss: 0.533917\n",
      "[33]\tvalid_0's l2: 0.17561\tvalid_0's binary_logloss: 0.534488\n",
      "[34]\tvalid_0's l2: 0.175457\tvalid_0's binary_logloss: 0.534997\n",
      "[35]\tvalid_0's l2: 0.175196\tvalid_0's binary_logloss: 0.533725\n",
      "[36]\tvalid_0's l2: 0.174399\tvalid_0's binary_logloss: 0.531199\n",
      "[37]\tvalid_0's l2: 0.173461\tvalid_0's binary_logloss: 0.52976\n",
      "[38]\tvalid_0's l2: 0.171412\tvalid_0's binary_logloss: 0.524879\n",
      "[39]\tvalid_0's l2: 0.169161\tvalid_0's binary_logloss: 0.519238\n",
      "[40]\tvalid_0's l2: 0.168707\tvalid_0's binary_logloss: 0.518329\n",
      "[41]\tvalid_0's l2: 0.168948\tvalid_0's binary_logloss: 0.518429\n",
      "[42]\tvalid_0's l2: 0.168841\tvalid_0's binary_logloss: 0.520414\n",
      "[43]\tvalid_0's l2: 0.168295\tvalid_0's binary_logloss: 0.518728\n",
      "[44]\tvalid_0's l2: 0.16766\tvalid_0's binary_logloss: 0.516947\n",
      "[45]\tvalid_0's l2: 0.167658\tvalid_0's binary_logloss: 0.516194\n",
      "[46]\tvalid_0's l2: 0.167583\tvalid_0's binary_logloss: 0.515515\n",
      "[47]\tvalid_0's l2: 0.165915\tvalid_0's binary_logloss: 0.511445\n",
      "[48]\tvalid_0's l2: 0.165685\tvalid_0's binary_logloss: 0.511131\n",
      "[49]\tvalid_0's l2: 0.165549\tvalid_0's binary_logloss: 0.510512\n",
      "[50]\tvalid_0's l2: 0.165973\tvalid_0's binary_logloss: 0.511022\n",
      "[51]\tvalid_0's l2: 0.164657\tvalid_0's binary_logloss: 0.506823\n",
      "[52]\tvalid_0's l2: 0.165226\tvalid_0's binary_logloss: 0.508953\n",
      "[53]\tvalid_0's l2: 0.165618\tvalid_0's binary_logloss: 0.50933\n",
      "[54]\tvalid_0's l2: 0.165302\tvalid_0's binary_logloss: 0.510248\n",
      "[55]\tvalid_0's l2: 0.164451\tvalid_0's binary_logloss: 0.509811\n",
      "[56]\tvalid_0's l2: 0.164136\tvalid_0's binary_logloss: 0.508574\n",
      "[57]\tvalid_0's l2: 0.164499\tvalid_0's binary_logloss: 0.509338\n",
      "[58]\tvalid_0's l2: 0.16441\tvalid_0's binary_logloss: 0.508725\n",
      "[59]\tvalid_0's l2: 0.16375\tvalid_0's binary_logloss: 0.506718\n",
      "[60]\tvalid_0's l2: 0.164883\tvalid_0's binary_logloss: 0.510793\n",
      "[61]\tvalid_0's l2: 0.164836\tvalid_0's binary_logloss: 0.510488\n",
      "[62]\tvalid_0's l2: 0.164574\tvalid_0's binary_logloss: 0.510624\n",
      "[63]\tvalid_0's l2: 0.162991\tvalid_0's binary_logloss: 0.505795\n",
      "[64]\tvalid_0's l2: 0.163319\tvalid_0's binary_logloss: 0.506307\n",
      "[65]\tvalid_0's l2: 0.163455\tvalid_0's binary_logloss: 0.506268\n",
      "[66]\tvalid_0's l2: 0.162679\tvalid_0's binary_logloss: 0.504809\n",
      "[67]\tvalid_0's l2: 0.16375\tvalid_0's binary_logloss: 0.508258\n",
      "[68]\tvalid_0's l2: 0.165261\tvalid_0's binary_logloss: 0.513838\n",
      "[69]\tvalid_0's l2: 0.165262\tvalid_0's binary_logloss: 0.512812\n",
      "[70]\tvalid_0's l2: 0.16517\tvalid_0's binary_logloss: 0.512165\n",
      "[71]\tvalid_0's l2: 0.164585\tvalid_0's binary_logloss: 0.509816\n",
      "[72]\tvalid_0's l2: 0.163873\tvalid_0's binary_logloss: 0.507687\n",
      "[73]\tvalid_0's l2: 0.163822\tvalid_0's binary_logloss: 0.50866\n",
      "[74]\tvalid_0's l2: 0.16387\tvalid_0's binary_logloss: 0.508455\n",
      "[75]\tvalid_0's l2: 0.163423\tvalid_0's binary_logloss: 0.50865\n",
      "[76]\tvalid_0's l2: 0.163421\tvalid_0's binary_logloss: 0.508958\n",
      "[77]\tvalid_0's l2: 0.163478\tvalid_0's binary_logloss: 0.508718\n",
      "[78]\tvalid_0's l2: 0.163711\tvalid_0's binary_logloss: 0.509368\n",
      "[79]\tvalid_0's l2: 0.163022\tvalid_0's binary_logloss: 0.508248\n",
      "[80]\tvalid_0's l2: 0.164414\tvalid_0's binary_logloss: 0.51305\n",
      "[81]\tvalid_0's l2: 0.164355\tvalid_0's binary_logloss: 0.512645\n",
      "[82]\tvalid_0's l2: 0.164727\tvalid_0's binary_logloss: 0.514119\n",
      "[83]\tvalid_0's l2: 0.164729\tvalid_0's binary_logloss: 0.513398\n",
      "[84]\tvalid_0's l2: 0.164002\tvalid_0's binary_logloss: 0.511161\n",
      "[85]\tvalid_0's l2: 0.164125\tvalid_0's binary_logloss: 0.511092\n",
      "[86]\tvalid_0's l2: 0.164744\tvalid_0's binary_logloss: 0.513572\n",
      "[87]\tvalid_0's l2: 0.164171\tvalid_0's binary_logloss: 0.513704\n",
      "[88]\tvalid_0's l2: 0.163864\tvalid_0's binary_logloss: 0.512445\n",
      "[89]\tvalid_0's l2: 0.163601\tvalid_0's binary_logloss: 0.511117\n",
      "[90]\tvalid_0's l2: 0.163592\tvalid_0's binary_logloss: 0.510517\n",
      "[91]\tvalid_0's l2: 0.163797\tvalid_0's binary_logloss: 0.510959\n",
      "[92]\tvalid_0's l2: 0.163361\tvalid_0's binary_logloss: 0.51073\n",
      "[93]\tvalid_0's l2: 0.162692\tvalid_0's binary_logloss: 0.509497\n",
      "[94]\tvalid_0's l2: 0.162546\tvalid_0's binary_logloss: 0.508823\n",
      "[95]\tvalid_0's l2: 0.162615\tvalid_0's binary_logloss: 0.508362\n",
      "[96]\tvalid_0's l2: 0.162753\tvalid_0's binary_logloss: 0.508357\n",
      "[97]\tvalid_0's l2: 0.161876\tvalid_0's binary_logloss: 0.506068\n",
      "[98]\tvalid_0's l2: 0.161479\tvalid_0's binary_logloss: 0.504425\n",
      "[99]\tvalid_0's l2: 0.161719\tvalid_0's binary_logloss: 0.505568\n",
      "[100]\tvalid_0's l2: 0.161115\tvalid_0's binary_logloss: 0.504899\n",
      "[101]\tvalid_0's l2: 0.160946\tvalid_0's binary_logloss: 0.504113\n",
      "[102]\tvalid_0's l2: 0.160851\tvalid_0's binary_logloss: 0.503628\n",
      "[103]\tvalid_0's l2: 0.160889\tvalid_0's binary_logloss: 0.503508\n",
      "[104]\tvalid_0's l2: 0.161606\tvalid_0's binary_logloss: 0.506929\n",
      "[105]\tvalid_0's l2: 0.161632\tvalid_0's binary_logloss: 0.506617\n",
      "[106]\tvalid_0's l2: 0.161343\tvalid_0's binary_logloss: 0.505527\n",
      "[107]\tvalid_0's l2: 0.161369\tvalid_0's binary_logloss: 0.505372\n",
      "[108]\tvalid_0's l2: 0.161342\tvalid_0's binary_logloss: 0.50556\n",
      "[109]\tvalid_0's l2: 0.161295\tvalid_0's binary_logloss: 0.505213\n",
      "[110]\tvalid_0's l2: 0.161346\tvalid_0's binary_logloss: 0.504873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.239215\tvalid_0's binary_logloss: 0.671271\n",
      "[2]\tvalid_0's l2: 0.229989\tvalid_0's binary_logloss: 0.652191\n",
      "[3]\tvalid_0's l2: 0.227566\tvalid_0's binary_logloss: 0.646553\n",
      "[4]\tvalid_0's l2: 0.227117\tvalid_0's binary_logloss: 0.64475\n",
      "[5]\tvalid_0's l2: 0.219246\tvalid_0's binary_logloss: 0.628301\n",
      "[6]\tvalid_0's l2: 0.212807\tvalid_0's binary_logloss: 0.614406\n",
      "[7]\tvalid_0's l2: 0.207795\tvalid_0's binary_logloss: 0.604323\n",
      "[8]\tvalid_0's l2: 0.210239\tvalid_0's binary_logloss: 0.60974\n",
      "[9]\tvalid_0's l2: 0.208312\tvalid_0's binary_logloss: 0.605209\n",
      "[10]\tvalid_0's l2: 0.200512\tvalid_0's binary_logloss: 0.588141\n",
      "[11]\tvalid_0's l2: 0.197684\tvalid_0's binary_logloss: 0.580827\n",
      "[12]\tvalid_0's l2: 0.196725\tvalid_0's binary_logloss: 0.579384\n",
      "[13]\tvalid_0's l2: 0.191566\tvalid_0's binary_logloss: 0.568209\n",
      "[14]\tvalid_0's l2: 0.189067\tvalid_0's binary_logloss: 0.561858\n",
      "[15]\tvalid_0's l2: 0.18596\tvalid_0's binary_logloss: 0.55384\n",
      "[16]\tvalid_0's l2: 0.187686\tvalid_0's binary_logloss: 0.556836\n",
      "[17]\tvalid_0's l2: 0.1871\tvalid_0's binary_logloss: 0.554754\n",
      "[18]\tvalid_0's l2: 0.183839\tvalid_0's binary_logloss: 0.548162\n",
      "[19]\tvalid_0's l2: 0.181795\tvalid_0's binary_logloss: 0.543169\n",
      "[20]\tvalid_0's l2: 0.180738\tvalid_0's binary_logloss: 0.54171\n",
      "[21]\tvalid_0's l2: 0.180215\tvalid_0's binary_logloss: 0.540635\n",
      "[22]\tvalid_0's l2: 0.18061\tvalid_0's binary_logloss: 0.541834\n",
      "[23]\tvalid_0's l2: 0.18177\tvalid_0's binary_logloss: 0.545067\n",
      "[24]\tvalid_0's l2: 0.182703\tvalid_0's binary_logloss: 0.54572\n",
      "[25]\tvalid_0's l2: 0.181199\tvalid_0's binary_logloss: 0.543306\n",
      "[26]\tvalid_0's l2: 0.180493\tvalid_0's binary_logloss: 0.542708\n",
      "[27]\tvalid_0's l2: 0.180411\tvalid_0's binary_logloss: 0.542797\n",
      "[28]\tvalid_0's l2: 0.180719\tvalid_0's binary_logloss: 0.543691\n",
      "[29]\tvalid_0's l2: 0.178495\tvalid_0's binary_logloss: 0.53815\n",
      "[30]\tvalid_0's l2: 0.177193\tvalid_0's binary_logloss: 0.534471\n",
      "[31]\tvalid_0's l2: 0.176468\tvalid_0's binary_logloss: 0.53361\n",
      "[32]\tvalid_0's l2: 0.176151\tvalid_0's binary_logloss: 0.533917\n",
      "[33]\tvalid_0's l2: 0.17561\tvalid_0's binary_logloss: 0.534488\n",
      "[34]\tvalid_0's l2: 0.175457\tvalid_0's binary_logloss: 0.534997\n",
      "[35]\tvalid_0's l2: 0.175196\tvalid_0's binary_logloss: 0.533725\n",
      "[36]\tvalid_0's l2: 0.174399\tvalid_0's binary_logloss: 0.531199\n",
      "[37]\tvalid_0's l2: 0.173461\tvalid_0's binary_logloss: 0.52976\n",
      "[38]\tvalid_0's l2: 0.171412\tvalid_0's binary_logloss: 0.524879\n",
      "[39]\tvalid_0's l2: 0.169161\tvalid_0's binary_logloss: 0.519238\n",
      "[40]\tvalid_0's l2: 0.168707\tvalid_0's binary_logloss: 0.518329\n",
      "[41]\tvalid_0's l2: 0.168948\tvalid_0's binary_logloss: 0.518429\n",
      "[42]\tvalid_0's l2: 0.168841\tvalid_0's binary_logloss: 0.520414\n",
      "[43]\tvalid_0's l2: 0.168295\tvalid_0's binary_logloss: 0.518728\n",
      "[44]\tvalid_0's l2: 0.16766\tvalid_0's binary_logloss: 0.516947\n",
      "[45]\tvalid_0's l2: 0.167658\tvalid_0's binary_logloss: 0.516194\n",
      "[46]\tvalid_0's l2: 0.167583\tvalid_0's binary_logloss: 0.515515\n",
      "[47]\tvalid_0's l2: 0.165915\tvalid_0's binary_logloss: 0.511445\n",
      "[48]\tvalid_0's l2: 0.165685\tvalid_0's binary_logloss: 0.511131\n",
      "[49]\tvalid_0's l2: 0.165549\tvalid_0's binary_logloss: 0.510512\n",
      "[50]\tvalid_0's l2: 0.165973\tvalid_0's binary_logloss: 0.511022\n",
      "[51]\tvalid_0's l2: 0.164657\tvalid_0's binary_logloss: 0.506823\n",
      "[52]\tvalid_0's l2: 0.165226\tvalid_0's binary_logloss: 0.508953\n",
      "[53]\tvalid_0's l2: 0.165618\tvalid_0's binary_logloss: 0.50933\n",
      "[54]\tvalid_0's l2: 0.165302\tvalid_0's binary_logloss: 0.510248\n",
      "[55]\tvalid_0's l2: 0.164451\tvalid_0's binary_logloss: 0.509811\n",
      "[56]\tvalid_0's l2: 0.164136\tvalid_0's binary_logloss: 0.508574\n",
      "[57]\tvalid_0's l2: 0.164499\tvalid_0's binary_logloss: 0.509338\n",
      "[58]\tvalid_0's l2: 0.16441\tvalid_0's binary_logloss: 0.508725\n",
      "[59]\tvalid_0's l2: 0.16375\tvalid_0's binary_logloss: 0.506718\n",
      "[60]\tvalid_0's l2: 0.164883\tvalid_0's binary_logloss: 0.510793\n",
      "[61]\tvalid_0's l2: 0.164836\tvalid_0's binary_logloss: 0.510488\n",
      "[62]\tvalid_0's l2: 0.164574\tvalid_0's binary_logloss: 0.510624\n",
      "[63]\tvalid_0's l2: 0.162991\tvalid_0's binary_logloss: 0.505795\n",
      "[64]\tvalid_0's l2: 0.163319\tvalid_0's binary_logloss: 0.506307\n",
      "[65]\tvalid_0's l2: 0.163455\tvalid_0's binary_logloss: 0.506268\n",
      "[66]\tvalid_0's l2: 0.162679\tvalid_0's binary_logloss: 0.504809\n",
      "[67]\tvalid_0's l2: 0.16375\tvalid_0's binary_logloss: 0.508258\n",
      "[68]\tvalid_0's l2: 0.165261\tvalid_0's binary_logloss: 0.513838\n",
      "[69]\tvalid_0's l2: 0.165262\tvalid_0's binary_logloss: 0.512812\n",
      "[70]\tvalid_0's l2: 0.16517\tvalid_0's binary_logloss: 0.512165\n",
      "[71]\tvalid_0's l2: 0.164585\tvalid_0's binary_logloss: 0.509816\n",
      "[72]\tvalid_0's l2: 0.163873\tvalid_0's binary_logloss: 0.507687\n",
      "[73]\tvalid_0's l2: 0.163822\tvalid_0's binary_logloss: 0.50866\n",
      "[74]\tvalid_0's l2: 0.16387\tvalid_0's binary_logloss: 0.508455\n",
      "[75]\tvalid_0's l2: 0.163423\tvalid_0's binary_logloss: 0.50865\n",
      "[76]\tvalid_0's l2: 0.163421\tvalid_0's binary_logloss: 0.508958\n",
      "[77]\tvalid_0's l2: 0.163478\tvalid_0's binary_logloss: 0.508718\n",
      "[78]\tvalid_0's l2: 0.163711\tvalid_0's binary_logloss: 0.509368\n",
      "[79]\tvalid_0's l2: 0.163022\tvalid_0's binary_logloss: 0.508248\n",
      "[80]\tvalid_0's l2: 0.164414\tvalid_0's binary_logloss: 0.51305\n",
      "[81]\tvalid_0's l2: 0.164355\tvalid_0's binary_logloss: 0.512645\n",
      "[82]\tvalid_0's l2: 0.164727\tvalid_0's binary_logloss: 0.514119\n",
      "[83]\tvalid_0's l2: 0.164729\tvalid_0's binary_logloss: 0.513398\n",
      "[84]\tvalid_0's l2: 0.164002\tvalid_0's binary_logloss: 0.511161\n",
      "[85]\tvalid_0's l2: 0.164125\tvalid_0's binary_logloss: 0.511092\n",
      "[86]\tvalid_0's l2: 0.164744\tvalid_0's binary_logloss: 0.513572\n",
      "[87]\tvalid_0's l2: 0.164171\tvalid_0's binary_logloss: 0.513704\n",
      "[88]\tvalid_0's l2: 0.163864\tvalid_0's binary_logloss: 0.512445\n",
      "[89]\tvalid_0's l2: 0.163601\tvalid_0's binary_logloss: 0.511117\n",
      "[90]\tvalid_0's l2: 0.163592\tvalid_0's binary_logloss: 0.510517\n",
      "[91]\tvalid_0's l2: 0.163797\tvalid_0's binary_logloss: 0.510959\n",
      "[92]\tvalid_0's l2: 0.163361\tvalid_0's binary_logloss: 0.51073\n",
      "[93]\tvalid_0's l2: 0.162692\tvalid_0's binary_logloss: 0.509497\n",
      "[94]\tvalid_0's l2: 0.162546\tvalid_0's binary_logloss: 0.508823\n",
      "[95]\tvalid_0's l2: 0.162615\tvalid_0's binary_logloss: 0.508362\n",
      "[96]\tvalid_0's l2: 0.162753\tvalid_0's binary_logloss: 0.508357\n",
      "[97]\tvalid_0's l2: 0.161876\tvalid_0's binary_logloss: 0.506068\n",
      "[98]\tvalid_0's l2: 0.161479\tvalid_0's binary_logloss: 0.504425\n",
      "[99]\tvalid_0's l2: 0.161719\tvalid_0's binary_logloss: 0.505568\n",
      "[100]\tvalid_0's l2: 0.161115\tvalid_0's binary_logloss: 0.504899\n",
      "[101]\tvalid_0's l2: 0.160946\tvalid_0's binary_logloss: 0.504113\n",
      "[102]\tvalid_0's l2: 0.160851\tvalid_0's binary_logloss: 0.503628\n",
      "---- Train error ----\n",
      "0.07286091124338825\n",
      "---- CV error ----\n",
      "0.1519919403016198\n",
      "---- leaderboard stats ----\n",
      "-0.014501161849378663\n",
      "0.17664021831573956\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2104  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2261  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1908  \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.1858  \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1868  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2055  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2247  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2412  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1849  \u001b[0m | \u001b[95m 0.6773  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 8.366   \u001b[0m | \u001b[95m 25.0    \u001b[0m | \u001b[95m 231.3   \u001b[0m | \u001b[95m 86.77   \u001b[0m | \u001b[95m 21.76   \u001b[0m | \u001b[95m 0.2893  \u001b[0m | \u001b[95m 0.9537  \u001b[0m | \u001b[95m 0.8583  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1986  \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 0.1184  \u001b[0m | \u001b[0m 14.03   \u001b[0m | \u001b[0m 77.84   \u001b[0m | \u001b[0m 450.4   \u001b[0m | \u001b[0m 163.5   \u001b[0m | \u001b[0m 23.09   \u001b[0m | \u001b[0m 0.08503 \u001b[0m | \u001b[0m 0.6847  \u001b[0m | \u001b[0m 0.8547  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1872  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.1803  \u001b[0m | \u001b[95m 0.8499  \u001b[0m | \u001b[95m 0.1405  \u001b[0m | \u001b[95m 10.97   \u001b[0m | \u001b[95m 13.55   \u001b[0m | \u001b[95m 498.3   \u001b[0m | \u001b[95m 101.9   \u001b[0m | \u001b[95m 28.24   \u001b[0m | \u001b[95m 0.5572  \u001b[0m | \u001b[95m 0.6208  \u001b[0m | \u001b[95m 0.574   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1957  \u001b[0m | \u001b[0m 0.9346  \u001b[0m | \u001b[0m 0.03904 \u001b[0m | \u001b[0m 7.231   \u001b[0m | \u001b[0m 11.85   \u001b[0m | \u001b[0m 499.2   \u001b[0m | \u001b[0m 94.7    \u001b[0m | \u001b[0m 26.17   \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 0.492   \u001b[0m | \u001b[0m 0.9129  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1859  \u001b[0m | \u001b[0m 0.8676  \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 14.41   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 472.8   \u001b[0m | \u001b[0m 123.9   \u001b[0m | \u001b[0m 29.08   \u001b[0m | \u001b[0m 0.5245  \u001b[0m | \u001b[0m 0.9207  \u001b[0m | \u001b[0m 0.6058  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2179  \u001b[0m | \u001b[0m 0.5463  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 2.422   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 78.7    \u001b[0m | \u001b[0m 15.77   \u001b[0m | \u001b[0m 0.3688  \u001b[0m | \u001b[0m 0.1773  \u001b[0m | \u001b[0m 0.8557  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1901  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1982  \u001b[0m | \u001b[0m 0.8056  \u001b[0m | \u001b[0m 0.04307 \u001b[0m | \u001b[0m 6.217   \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 228.3   \u001b[0m | \u001b[0m 82.94   \u001b[0m | \u001b[0m 25.62   \u001b[0m | \u001b[0m 0.1261  \u001b[0m | \u001b[0m 0.3898  \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2279  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2299  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1844  \u001b[0m | \u001b[0m 0.7273  \u001b[0m | \u001b[0m 0.1974  \u001b[0m | \u001b[0m 9.822   \u001b[0m | \u001b[0m 14.51   \u001b[0m | \u001b[0m 493.2   \u001b[0m | \u001b[0m 110.4   \u001b[0m | \u001b[0m 25.7    \u001b[0m | \u001b[0m 0.5391  \u001b[0m | \u001b[0m 0.6971  \u001b[0m | \u001b[0m 0.5694  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.180335100512401, 'params': {'colsample_bytree': 0.8499371966590277, 'learning_rate': 0.14051583579820578, 'max_depth': 10.971506287585683, 'min_child_samples': 13.554375045709467, 'n_estimators': 498.2859816970736, 'num_iteration': 101.90310144018423, 'num_leaves': 28.244477092489824, 'reg_alpha': 0.5572348326010869, 'reg_lambda': 0.6207796995788415, 'subsample': 0.573997001366945}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.242196\tvalid_0's binary_logloss: 0.67746\n",
      "[2]\tvalid_0's l2: 0.230647\tvalid_0's binary_logloss: 0.654032\n",
      "[3]\tvalid_0's l2: 0.226672\tvalid_0's binary_logloss: 0.645641\n",
      "[4]\tvalid_0's l2: 0.22246\tvalid_0's binary_logloss: 0.636656\n",
      "[5]\tvalid_0's l2: 0.218525\tvalid_0's binary_logloss: 0.628344\n",
      "[6]\tvalid_0's l2: 0.213842\tvalid_0's binary_logloss: 0.618447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:182: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7]\tvalid_0's l2: 0.210662\tvalid_0's binary_logloss: 0.611071\n",
      "[8]\tvalid_0's l2: 0.212075\tvalid_0's binary_logloss: 0.614402\n",
      "[9]\tvalid_0's l2: 0.207554\tvalid_0's binary_logloss: 0.604769\n",
      "[10]\tvalid_0's l2: 0.20383\tvalid_0's binary_logloss: 0.596043\n",
      "[11]\tvalid_0's l2: 0.199534\tvalid_0's binary_logloss: 0.586442\n",
      "[12]\tvalid_0's l2: 0.199917\tvalid_0's binary_logloss: 0.587303\n",
      "[13]\tvalid_0's l2: 0.197079\tvalid_0's binary_logloss: 0.580255\n",
      "[14]\tvalid_0's l2: 0.196729\tvalid_0's binary_logloss: 0.579208\n",
      "[15]\tvalid_0's l2: 0.193741\tvalid_0's binary_logloss: 0.572818\n",
      "[16]\tvalid_0's l2: 0.190902\tvalid_0's binary_logloss: 0.566285\n",
      "[17]\tvalid_0's l2: 0.189549\tvalid_0's binary_logloss: 0.562375\n",
      "[18]\tvalid_0's l2: 0.188065\tvalid_0's binary_logloss: 0.558755\n",
      "[19]\tvalid_0's l2: 0.187298\tvalid_0's binary_logloss: 0.556983\n",
      "[20]\tvalid_0's l2: 0.18803\tvalid_0's binary_logloss: 0.558454\n",
      "[21]\tvalid_0's l2: 0.187225\tvalid_0's binary_logloss: 0.556562\n",
      "[22]\tvalid_0's l2: 0.184666\tvalid_0's binary_logloss: 0.550927\n",
      "[23]\tvalid_0's l2: 0.185413\tvalid_0's binary_logloss: 0.552799\n",
      "[24]\tvalid_0's l2: 0.185286\tvalid_0's binary_logloss: 0.552892\n",
      "[25]\tvalid_0's l2: 0.184447\tvalid_0's binary_logloss: 0.550946\n",
      "[26]\tvalid_0's l2: 0.185002\tvalid_0's binary_logloss: 0.552416\n",
      "[27]\tvalid_0's l2: 0.183277\tvalid_0's binary_logloss: 0.548733\n",
      "[28]\tvalid_0's l2: 0.183451\tvalid_0's binary_logloss: 0.549069\n",
      "[29]\tvalid_0's l2: 0.184378\tvalid_0's binary_logloss: 0.551147\n",
      "[30]\tvalid_0's l2: 0.182528\tvalid_0's binary_logloss: 0.54677\n",
      "[31]\tvalid_0's l2: 0.182645\tvalid_0's binary_logloss: 0.546673\n",
      "[32]\tvalid_0's l2: 0.182192\tvalid_0's binary_logloss: 0.545854\n",
      "[33]\tvalid_0's l2: 0.180681\tvalid_0's binary_logloss: 0.542189\n",
      "[34]\tvalid_0's l2: 0.18024\tvalid_0's binary_logloss: 0.541874\n",
      "[35]\tvalid_0's l2: 0.180573\tvalid_0's binary_logloss: 0.542829\n",
      "[36]\tvalid_0's l2: 0.179915\tvalid_0's binary_logloss: 0.541113\n",
      "[37]\tvalid_0's l2: 0.177763\tvalid_0's binary_logloss: 0.536209\n",
      "[38]\tvalid_0's l2: 0.177636\tvalid_0's binary_logloss: 0.536815\n",
      "[39]\tvalid_0's l2: 0.176121\tvalid_0's binary_logloss: 0.533854\n",
      "[40]\tvalid_0's l2: 0.176104\tvalid_0's binary_logloss: 0.533977\n",
      "[41]\tvalid_0's l2: 0.176043\tvalid_0's binary_logloss: 0.533369\n",
      "[42]\tvalid_0's l2: 0.175984\tvalid_0's binary_logloss: 0.534505\n",
      "[43]\tvalid_0's l2: 0.176088\tvalid_0's binary_logloss: 0.534606\n",
      "[44]\tvalid_0's l2: 0.176555\tvalid_0's binary_logloss: 0.536155\n",
      "[45]\tvalid_0's l2: 0.177306\tvalid_0's binary_logloss: 0.53881\n",
      "[46]\tvalid_0's l2: 0.177264\tvalid_0's binary_logloss: 0.538149\n",
      "[47]\tvalid_0's l2: 0.176597\tvalid_0's binary_logloss: 0.535951\n",
      "[48]\tvalid_0's l2: 0.177051\tvalid_0's binary_logloss: 0.53715\n",
      "[49]\tvalid_0's l2: 0.17677\tvalid_0's binary_logloss: 0.53639\n",
      "[50]\tvalid_0's l2: 0.176856\tvalid_0's binary_logloss: 0.536721\n",
      "[51]\tvalid_0's l2: 0.17751\tvalid_0's binary_logloss: 0.537797\n",
      "[52]\tvalid_0's l2: 0.175708\tvalid_0's binary_logloss: 0.533738\n",
      "[53]\tvalid_0's l2: 0.17572\tvalid_0's binary_logloss: 0.533745\n",
      "[54]\tvalid_0's l2: 0.17548\tvalid_0's binary_logloss: 0.533159\n",
      "[55]\tvalid_0's l2: 0.175623\tvalid_0's binary_logloss: 0.534714\n",
      "[56]\tvalid_0's l2: 0.175702\tvalid_0's binary_logloss: 0.534653\n",
      "[57]\tvalid_0's l2: 0.176096\tvalid_0's binary_logloss: 0.536594\n",
      "[58]\tvalid_0's l2: 0.175672\tvalid_0's binary_logloss: 0.535038\n",
      "[59]\tvalid_0's l2: 0.175399\tvalid_0's binary_logloss: 0.534074\n",
      "[60]\tvalid_0's l2: 0.17643\tvalid_0's binary_logloss: 0.536909\n",
      "[61]\tvalid_0's l2: 0.176063\tvalid_0's binary_logloss: 0.535628\n",
      "[62]\tvalid_0's l2: 0.175902\tvalid_0's binary_logloss: 0.535854\n",
      "[63]\tvalid_0's l2: 0.175516\tvalid_0's binary_logloss: 0.534864\n",
      "[64]\tvalid_0's l2: 0.175877\tvalid_0's binary_logloss: 0.53536\n",
      "[65]\tvalid_0's l2: 0.176397\tvalid_0's binary_logloss: 0.536273\n",
      "[66]\tvalid_0's l2: 0.176875\tvalid_0's binary_logloss: 0.53646\n",
      "[67]\tvalid_0's l2: 0.176683\tvalid_0's binary_logloss: 0.536276\n",
      "[68]\tvalid_0's l2: 0.176426\tvalid_0's binary_logloss: 0.536002\n",
      "[69]\tvalid_0's l2: 0.176491\tvalid_0's binary_logloss: 0.53569\n",
      "[70]\tvalid_0's l2: 0.176392\tvalid_0's binary_logloss: 0.535642\n",
      "[71]\tvalid_0's l2: 0.176394\tvalid_0's binary_logloss: 0.535321\n",
      "[72]\tvalid_0's l2: 0.175527\tvalid_0's binary_logloss: 0.53389\n",
      "[73]\tvalid_0's l2: 0.174895\tvalid_0's binary_logloss: 0.532287\n",
      "[74]\tvalid_0's l2: 0.174656\tvalid_0's binary_logloss: 0.531478\n",
      "[75]\tvalid_0's l2: 0.174757\tvalid_0's binary_logloss: 0.532047\n",
      "[76]\tvalid_0's l2: 0.174956\tvalid_0's binary_logloss: 0.532453\n",
      "[77]\tvalid_0's l2: 0.175171\tvalid_0's binary_logloss: 0.532711\n",
      "[78]\tvalid_0's l2: 0.175386\tvalid_0's binary_logloss: 0.533152\n",
      "[79]\tvalid_0's l2: 0.174249\tvalid_0's binary_logloss: 0.530318\n",
      "[80]\tvalid_0's l2: 0.17425\tvalid_0's binary_logloss: 0.531602\n",
      "[81]\tvalid_0's l2: 0.17402\tvalid_0's binary_logloss: 0.530802\n",
      "[82]\tvalid_0's l2: 0.173746\tvalid_0's binary_logloss: 0.531061\n",
      "[83]\tvalid_0's l2: 0.173619\tvalid_0's binary_logloss: 0.530549\n",
      "[84]\tvalid_0's l2: 0.173252\tvalid_0's binary_logloss: 0.528921\n",
      "[85]\tvalid_0's l2: 0.173108\tvalid_0's binary_logloss: 0.528245\n",
      "[86]\tvalid_0's l2: 0.172481\tvalid_0's binary_logloss: 0.527398\n",
      "[87]\tvalid_0's l2: 0.172089\tvalid_0's binary_logloss: 0.526821\n",
      "[88]\tvalid_0's l2: 0.172046\tvalid_0's binary_logloss: 0.526424\n",
      "[89]\tvalid_0's l2: 0.171977\tvalid_0's binary_logloss: 0.525825\n",
      "[90]\tvalid_0's l2: 0.171933\tvalid_0's binary_logloss: 0.525632\n",
      "[91]\tvalid_0's l2: 0.171718\tvalid_0's binary_logloss: 0.524837\n",
      "[92]\tvalid_0's l2: 0.17073\tvalid_0's binary_logloss: 0.52261\n",
      "[93]\tvalid_0's l2: 0.170775\tvalid_0's binary_logloss: 0.523478\n",
      "[94]\tvalid_0's l2: 0.170958\tvalid_0's binary_logloss: 0.523709\n",
      "[95]\tvalid_0's l2: 0.170873\tvalid_0's binary_logloss: 0.523405\n",
      "[96]\tvalid_0's l2: 0.170618\tvalid_0's binary_logloss: 0.522387\n",
      "[97]\tvalid_0's l2: 0.171498\tvalid_0's binary_logloss: 0.524273\n",
      "[98]\tvalid_0's l2: 0.171119\tvalid_0's binary_logloss: 0.523011\n",
      "[99]\tvalid_0's l2: 0.171754\tvalid_0's binary_logloss: 0.525375\n",
      "[100]\tvalid_0's l2: 0.170496\tvalid_0's binary_logloss: 0.52334\n",
      "[101]\tvalid_0's l2: 0.170326\tvalid_0's binary_logloss: 0.522484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.242196\tvalid_0's binary_logloss: 0.67746\n",
      "[2]\tvalid_0's l2: 0.230647\tvalid_0's binary_logloss: 0.654032\n",
      "[3]\tvalid_0's l2: 0.226672\tvalid_0's binary_logloss: 0.645641\n",
      "[4]\tvalid_0's l2: 0.22246\tvalid_0's binary_logloss: 0.636656\n",
      "[5]\tvalid_0's l2: 0.218525\tvalid_0's binary_logloss: 0.628344\n",
      "[6]\tvalid_0's l2: 0.213842\tvalid_0's binary_logloss: 0.618447\n",
      "[7]\tvalid_0's l2: 0.210662\tvalid_0's binary_logloss: 0.611071\n",
      "[8]\tvalid_0's l2: 0.212075\tvalid_0's binary_logloss: 0.614402\n",
      "[9]\tvalid_0's l2: 0.207554\tvalid_0's binary_logloss: 0.604769\n",
      "[10]\tvalid_0's l2: 0.20383\tvalid_0's binary_logloss: 0.596043\n",
      "[11]\tvalid_0's l2: 0.199534\tvalid_0's binary_logloss: 0.586442\n",
      "[12]\tvalid_0's l2: 0.199917\tvalid_0's binary_logloss: 0.587303\n",
      "[13]\tvalid_0's l2: 0.197079\tvalid_0's binary_logloss: 0.580255\n",
      "[14]\tvalid_0's l2: 0.196729\tvalid_0's binary_logloss: 0.579208\n",
      "[15]\tvalid_0's l2: 0.193741\tvalid_0's binary_logloss: 0.572818\n",
      "[16]\tvalid_0's l2: 0.190902\tvalid_0's binary_logloss: 0.566285\n",
      "[17]\tvalid_0's l2: 0.189549\tvalid_0's binary_logloss: 0.562375\n",
      "[18]\tvalid_0's l2: 0.188065\tvalid_0's binary_logloss: 0.558755\n",
      "[19]\tvalid_0's l2: 0.187298\tvalid_0's binary_logloss: 0.556983\n",
      "[20]\tvalid_0's l2: 0.18803\tvalid_0's binary_logloss: 0.558454\n",
      "[21]\tvalid_0's l2: 0.187225\tvalid_0's binary_logloss: 0.556562\n",
      "[22]\tvalid_0's l2: 0.184666\tvalid_0's binary_logloss: 0.550927\n",
      "[23]\tvalid_0's l2: 0.185413\tvalid_0's binary_logloss: 0.552799\n",
      "[24]\tvalid_0's l2: 0.185286\tvalid_0's binary_logloss: 0.552892\n",
      "[25]\tvalid_0's l2: 0.184447\tvalid_0's binary_logloss: 0.550946\n",
      "[26]\tvalid_0's l2: 0.185002\tvalid_0's binary_logloss: 0.552416\n",
      "[27]\tvalid_0's l2: 0.183277\tvalid_0's binary_logloss: 0.548733\n",
      "[28]\tvalid_0's l2: 0.183451\tvalid_0's binary_logloss: 0.549069\n",
      "[29]\tvalid_0's l2: 0.184378\tvalid_0's binary_logloss: 0.551147\n",
      "[30]\tvalid_0's l2: 0.182528\tvalid_0's binary_logloss: 0.54677\n",
      "[31]\tvalid_0's l2: 0.182645\tvalid_0's binary_logloss: 0.546673\n",
      "[32]\tvalid_0's l2: 0.182192\tvalid_0's binary_logloss: 0.545854\n",
      "[33]\tvalid_0's l2: 0.180681\tvalid_0's binary_logloss: 0.542189\n",
      "[34]\tvalid_0's l2: 0.18024\tvalid_0's binary_logloss: 0.541874\n",
      "[35]\tvalid_0's l2: 0.180573\tvalid_0's binary_logloss: 0.542829\n",
      "[36]\tvalid_0's l2: 0.179915\tvalid_0's binary_logloss: 0.541113\n",
      "[37]\tvalid_0's l2: 0.177763\tvalid_0's binary_logloss: 0.536209\n",
      "[38]\tvalid_0's l2: 0.177636\tvalid_0's binary_logloss: 0.536815\n",
      "[39]\tvalid_0's l2: 0.176121\tvalid_0's binary_logloss: 0.533854\n",
      "[40]\tvalid_0's l2: 0.176104\tvalid_0's binary_logloss: 0.533977\n",
      "[41]\tvalid_0's l2: 0.176043\tvalid_0's binary_logloss: 0.533369\n",
      "[42]\tvalid_0's l2: 0.175984\tvalid_0's binary_logloss: 0.534505\n",
      "[43]\tvalid_0's l2: 0.176088\tvalid_0's binary_logloss: 0.534606\n",
      "[44]\tvalid_0's l2: 0.176555\tvalid_0's binary_logloss: 0.536155\n",
      "[45]\tvalid_0's l2: 0.177306\tvalid_0's binary_logloss: 0.53881\n",
      "[46]\tvalid_0's l2: 0.177264\tvalid_0's binary_logloss: 0.538149\n",
      "[47]\tvalid_0's l2: 0.176597\tvalid_0's binary_logloss: 0.535951\n",
      "[48]\tvalid_0's l2: 0.177051\tvalid_0's binary_logloss: 0.53715\n",
      "[49]\tvalid_0's l2: 0.17677\tvalid_0's binary_logloss: 0.53639\n",
      "[50]\tvalid_0's l2: 0.176856\tvalid_0's binary_logloss: 0.536721\n",
      "[51]\tvalid_0's l2: 0.17751\tvalid_0's binary_logloss: 0.537797\n",
      "[52]\tvalid_0's l2: 0.175708\tvalid_0's binary_logloss: 0.533738\n",
      "[53]\tvalid_0's l2: 0.17572\tvalid_0's binary_logloss: 0.533745\n",
      "[54]\tvalid_0's l2: 0.17548\tvalid_0's binary_logloss: 0.533159\n",
      "[55]\tvalid_0's l2: 0.175623\tvalid_0's binary_logloss: 0.534714\n",
      "[56]\tvalid_0's l2: 0.175702\tvalid_0's binary_logloss: 0.534653\n",
      "[57]\tvalid_0's l2: 0.176096\tvalid_0's binary_logloss: 0.536594\n",
      "[58]\tvalid_0's l2: 0.175672\tvalid_0's binary_logloss: 0.535038\n",
      "[59]\tvalid_0's l2: 0.175399\tvalid_0's binary_logloss: 0.534074\n",
      "[60]\tvalid_0's l2: 0.17643\tvalid_0's binary_logloss: 0.536909\n",
      "[61]\tvalid_0's l2: 0.176063\tvalid_0's binary_logloss: 0.535628\n",
      "[62]\tvalid_0's l2: 0.175902\tvalid_0's binary_logloss: 0.535854\n",
      "[63]\tvalid_0's l2: 0.175516\tvalid_0's binary_logloss: 0.534864\n",
      "[64]\tvalid_0's l2: 0.175877\tvalid_0's binary_logloss: 0.53536\n",
      "[65]\tvalid_0's l2: 0.176397\tvalid_0's binary_logloss: 0.536273\n",
      "[66]\tvalid_0's l2: 0.176875\tvalid_0's binary_logloss: 0.53646\n",
      "[67]\tvalid_0's l2: 0.176683\tvalid_0's binary_logloss: 0.536276\n",
      "[68]\tvalid_0's l2: 0.176426\tvalid_0's binary_logloss: 0.536002\n",
      "[69]\tvalid_0's l2: 0.176491\tvalid_0's binary_logloss: 0.53569\n",
      "[70]\tvalid_0's l2: 0.176392\tvalid_0's binary_logloss: 0.535642\n",
      "[71]\tvalid_0's l2: 0.176394\tvalid_0's binary_logloss: 0.535321\n",
      "[72]\tvalid_0's l2: 0.175527\tvalid_0's binary_logloss: 0.53389\n",
      "[73]\tvalid_0's l2: 0.174895\tvalid_0's binary_logloss: 0.532287\n",
      "[74]\tvalid_0's l2: 0.174656\tvalid_0's binary_logloss: 0.531478\n",
      "[75]\tvalid_0's l2: 0.174757\tvalid_0's binary_logloss: 0.532047\n",
      "[76]\tvalid_0's l2: 0.174956\tvalid_0's binary_logloss: 0.532453\n",
      "[77]\tvalid_0's l2: 0.175171\tvalid_0's binary_logloss: 0.532711\n",
      "[78]\tvalid_0's l2: 0.175386\tvalid_0's binary_logloss: 0.533152\n",
      "[79]\tvalid_0's l2: 0.174249\tvalid_0's binary_logloss: 0.530318\n",
      "[80]\tvalid_0's l2: 0.17425\tvalid_0's binary_logloss: 0.531602\n",
      "[81]\tvalid_0's l2: 0.17402\tvalid_0's binary_logloss: 0.530802\n",
      "[82]\tvalid_0's l2: 0.173746\tvalid_0's binary_logloss: 0.531061\n",
      "[83]\tvalid_0's l2: 0.173619\tvalid_0's binary_logloss: 0.530549\n",
      "[84]\tvalid_0's l2: 0.173252\tvalid_0's binary_logloss: 0.528921\n",
      "[85]\tvalid_0's l2: 0.173108\tvalid_0's binary_logloss: 0.528245\n",
      "[86]\tvalid_0's l2: 0.172481\tvalid_0's binary_logloss: 0.527398\n",
      "[87]\tvalid_0's l2: 0.172089\tvalid_0's binary_logloss: 0.526821\n",
      "[88]\tvalid_0's l2: 0.172046\tvalid_0's binary_logloss: 0.526424\n",
      "[89]\tvalid_0's l2: 0.171977\tvalid_0's binary_logloss: 0.525825\n",
      "[90]\tvalid_0's l2: 0.171933\tvalid_0's binary_logloss: 0.525632\n",
      "[91]\tvalid_0's l2: 0.171718\tvalid_0's binary_logloss: 0.524837\n",
      "[92]\tvalid_0's l2: 0.17073\tvalid_0's binary_logloss: 0.52261\n",
      "[93]\tvalid_0's l2: 0.170775\tvalid_0's binary_logloss: 0.523478\n",
      "[94]\tvalid_0's l2: 0.170958\tvalid_0's binary_logloss: 0.523709\n",
      "[95]\tvalid_0's l2: 0.170873\tvalid_0's binary_logloss: 0.523405\n",
      "[96]\tvalid_0's l2: 0.170618\tvalid_0's binary_logloss: 0.522387\n",
      "[97]\tvalid_0's l2: 0.171498\tvalid_0's binary_logloss: 0.524273\n",
      "[98]\tvalid_0's l2: 0.171119\tvalid_0's binary_logloss: 0.523011\n",
      "[99]\tvalid_0's l2: 0.171754\tvalid_0's binary_logloss: 0.525375\n",
      "[100]\tvalid_0's l2: 0.170496\tvalid_0's binary_logloss: 0.52334\n",
      "[101]\tvalid_0's l2: 0.170326\tvalid_0's binary_logloss: 0.522484\n",
      "---- Train error ----\n",
      "0.03811321235268954\n",
      "---- CV error ----\n",
      "0.1664027888801432\n",
      "---- leaderboard stats ----\n",
      "-0.05673905790968914\n",
      "0.2118030106777266\n",
      "0:03:22.282122\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "-------------  goss  --------------\n",
      "\n",
      "\n",
      "eviction\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.06882 \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.07797 \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.06731 \u001b[0m | \u001b[95m 0.8212  \u001b[0m | \u001b[95m 0.1463  \u001b[0m | \u001b[95m 7.546   \u001b[0m | \u001b[95m 71.86   \u001b[0m | \u001b[95m 445.2   \u001b[0m | \u001b[95m 159.5   \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 0.6769  \u001b[0m | \u001b[95m 0.7908  \u001b[0m | \u001b[95m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.05887 \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.05909 \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.06781 \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1956  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.07329 \u001b[0m | \u001b[0m 0.669   \u001b[0m | \u001b[0m 0.0485  \u001b[0m | \u001b[0m 9.27    \u001b[0m | \u001b[0m 10.75   \u001b[0m | \u001b[0m 423.1   \u001b[0m | \u001b[0m 52.54   \u001b[0m | \u001b[0m 17.0    \u001b[0m | \u001b[0m 0.6929  \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.8697  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.05782 \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 15.0    \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 549.9   \u001b[0m | \u001b[95m 50.0    \u001b[0m | \u001b[95m 30.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.08616 \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.03687 \u001b[0m | \u001b[0m 4.354   \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 697.7   \u001b[0m | \u001b[0m 60.88   \u001b[0m | \u001b[0m 27.37   \u001b[0m | \u001b[0m 0.6349  \u001b[0m | \u001b[0m 0.982   \u001b[0m | \u001b[0m 0.9576  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2025  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 379.9   \u001b[0m | \u001b[0m 197.2   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1963  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 195.3   \u001b[0m | \u001b[0m 645.8   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5414  \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.0578  \u001b[0m | \u001b[95m 0.561   \u001b[0m | \u001b[95m 0.1179  \u001b[0m | \u001b[95m 4.555   \u001b[0m | \u001b[95m 25.01   \u001b[0m | \u001b[95m 307.8   \u001b[0m | \u001b[95m 149.7   \u001b[0m | \u001b[95m 18.67   \u001b[0m | \u001b[95m 0.01987 \u001b[0m | \u001b[95m 0.9257  \u001b[0m | \u001b[95m 0.8376  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1983  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 366.5   \u001b[0m | \u001b[0m 150.3   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.9811  \u001b[0m | \u001b[0m 0.5164  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.05879 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 13.08   \u001b[0m | \u001b[0m 17.92   \u001b[0m | \u001b[0m 535.5   \u001b[0m | \u001b[0m 98.87   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9372  \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.05727 \u001b[0m | \u001b[95m 0.6682  \u001b[0m | \u001b[95m 0.08424 \u001b[0m | \u001b[95m 13.61   \u001b[0m | \u001b[95m 11.81   \u001b[0m | \u001b[95m 266.6   \u001b[0m | \u001b[95m 142.5   \u001b[0m | \u001b[95m 5.268   \u001b[0m | \u001b[95m 0.2846  \u001b[0m | \u001b[95m 0.4092  \u001b[0m | \u001b[95m 0.8462  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.05841 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 488.5   \u001b[0m | \u001b[0m 68.59   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.05884 \u001b[0m | \u001b[0m 0.7703  \u001b[0m | \u001b[0m 0.1946  \u001b[0m | \u001b[0m 4.028   \u001b[0m | \u001b[0m 12.64   \u001b[0m | \u001b[0m 698.7   \u001b[0m | \u001b[0m 54.77   \u001b[0m | \u001b[0m 21.61   \u001b[0m | \u001b[0m 0.1536  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.7452  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.06825 \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 8.224   \u001b[0m | \u001b[0m 71.92   \u001b[0m | \u001b[0m 447.5   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 27.69   \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 0.8824  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.05816 \u001b[0m | \u001b[0m 0.6651  \u001b[0m | \u001b[0m 0.1413  \u001b[0m | \u001b[0m 14.57   \u001b[0m | \u001b[0m 14.05   \u001b[0m | \u001b[0m 286.0   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 9.539   \u001b[0m | \u001b[0m 0.6146  \u001b[0m | \u001b[0m 0.3814  \u001b[0m | \u001b[0m 0.768   \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.05727216853857862, 'params': {'colsample_bytree': 0.6681715263312068, 'learning_rate': 0.08423913878371198, 'max_depth': 13.614865979614436, 'min_child_samples': 11.81490757015909, 'n_estimators': 266.6077009296996, 'num_iteration': 142.45258695983534, 'num_leaves': 5.2676890414846635, 'reg_alpha': 0.28456779712107594, 'reg_lambda': 0.40921399051375085, 'subsample': 0.8462159981959478}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=142, num_iteration=142 will be ignored. Current value: num_iterations=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.238991\tvalid_0's binary_logloss: 0.671065\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.227768\tvalid_0's binary_logloss: 0.648318\n",
      "[3]\tvalid_0's l2: 0.218474\tvalid_0's binary_logloss: 0.629025\n",
      "[4]\tvalid_0's l2: 0.209854\tvalid_0's binary_logloss: 0.610995\n",
      "[5]\tvalid_0's l2: 0.205295\tvalid_0's binary_logloss: 0.601279\n",
      "[6]\tvalid_0's l2: 0.200619\tvalid_0's binary_logloss: 0.591214\n",
      "[7]\tvalid_0's l2: 0.194947\tvalid_0's binary_logloss: 0.579028\n",
      "[8]\tvalid_0's l2: 0.186722\tvalid_0's binary_logloss: 0.561079\n",
      "[9]\tvalid_0's l2: 0.179853\tvalid_0's binary_logloss: 0.54572\n",
      "[10]\tvalid_0's l2: 0.176105\tvalid_0's binary_logloss: 0.536974\n",
      "[11]\tvalid_0's l2: 0.172306\tvalid_0's binary_logloss: 0.528337\n",
      "[12]\tvalid_0's l2: 0.171163\tvalid_0's binary_logloss: 0.525414\n",
      "[13]\tvalid_0's l2: 0.167764\tvalid_0's binary_logloss: 0.517788\n",
      "[14]\tvalid_0's l2: 0.166181\tvalid_0's binary_logloss: 0.513851\n",
      "[15]\tvalid_0's l2: 0.165007\tvalid_0's binary_logloss: 0.510892\n",
      "[16]\tvalid_0's l2: 0.159942\tvalid_0's binary_logloss: 0.499516\n",
      "[17]\tvalid_0's l2: 0.157007\tvalid_0's binary_logloss: 0.492464\n",
      "[18]\tvalid_0's l2: 0.155702\tvalid_0's binary_logloss: 0.489278\n",
      "[19]\tvalid_0's l2: 0.151888\tvalid_0's binary_logloss: 0.479987\n",
      "[20]\tvalid_0's l2: 0.14903\tvalid_0's binary_logloss: 0.473022\n",
      "[21]\tvalid_0's l2: 0.148726\tvalid_0's binary_logloss: 0.471392\n",
      "[22]\tvalid_0's l2: 0.146809\tvalid_0's binary_logloss: 0.466883\n",
      "[23]\tvalid_0's l2: 0.144395\tvalid_0's binary_logloss: 0.460829\n",
      "[24]\tvalid_0's l2: 0.144269\tvalid_0's binary_logloss: 0.459888\n",
      "[25]\tvalid_0's l2: 0.141288\tvalid_0's binary_logloss: 0.452503\n",
      "[26]\tvalid_0's l2: 0.140421\tvalid_0's binary_logloss: 0.450074\n",
      "[27]\tvalid_0's l2: 0.139424\tvalid_0's binary_logloss: 0.447527\n",
      "[28]\tvalid_0's l2: 0.136505\tvalid_0's binary_logloss: 0.440854\n",
      "[29]\tvalid_0's l2: 0.134135\tvalid_0's binary_logloss: 0.434702\n",
      "[30]\tvalid_0's l2: 0.131207\tvalid_0's binary_logloss: 0.427259\n",
      "[31]\tvalid_0's l2: 0.129011\tvalid_0's binary_logloss: 0.421788\n",
      "[32]\tvalid_0's l2: 0.128051\tvalid_0's binary_logloss: 0.419158\n",
      "[33]\tvalid_0's l2: 0.126494\tvalid_0's binary_logloss: 0.415423\n",
      "[34]\tvalid_0's l2: 0.124111\tvalid_0's binary_logloss: 0.409812\n",
      "[35]\tvalid_0's l2: 0.122198\tvalid_0's binary_logloss: 0.404832\n",
      "[36]\tvalid_0's l2: 0.120675\tvalid_0's binary_logloss: 0.400368\n",
      "[37]\tvalid_0's l2: 0.11969\tvalid_0's binary_logloss: 0.39765\n",
      "[38]\tvalid_0's l2: 0.118304\tvalid_0's binary_logloss: 0.394004\n",
      "[39]\tvalid_0's l2: 0.115717\tvalid_0's binary_logloss: 0.387622\n",
      "[40]\tvalid_0's l2: 0.112893\tvalid_0's binary_logloss: 0.379588\n",
      "[41]\tvalid_0's l2: 0.110691\tvalid_0's binary_logloss: 0.373739\n",
      "[42]\tvalid_0's l2: 0.108404\tvalid_0's binary_logloss: 0.367795\n",
      "[43]\tvalid_0's l2: 0.107508\tvalid_0's binary_logloss: 0.364998\n",
      "[44]\tvalid_0's l2: 0.106336\tvalid_0's binary_logloss: 0.361751\n",
      "[45]\tvalid_0's l2: 0.104577\tvalid_0's binary_logloss: 0.357264\n",
      "[46]\tvalid_0's l2: 0.103578\tvalid_0's binary_logloss: 0.354429\n",
      "[47]\tvalid_0's l2: 0.10365\tvalid_0's binary_logloss: 0.354557\n",
      "[48]\tvalid_0's l2: 0.102157\tvalid_0's binary_logloss: 0.350082\n",
      "[49]\tvalid_0's l2: 0.099476\tvalid_0's binary_logloss: 0.343027\n",
      "[50]\tvalid_0's l2: 0.0981272\tvalid_0's binary_logloss: 0.339297\n",
      "[51]\tvalid_0's l2: 0.0961988\tvalid_0's binary_logloss: 0.333984\n",
      "[52]\tvalid_0's l2: 0.0956574\tvalid_0's binary_logloss: 0.332748\n",
      "[53]\tvalid_0's l2: 0.0946195\tvalid_0's binary_logloss: 0.329697\n",
      "[54]\tvalid_0's l2: 0.0928838\tvalid_0's binary_logloss: 0.324335\n",
      "[55]\tvalid_0's l2: 0.0920192\tvalid_0's binary_logloss: 0.322443\n",
      "[56]\tvalid_0's l2: 0.0913491\tvalid_0's binary_logloss: 0.320513\n",
      "[57]\tvalid_0's l2: 0.090466\tvalid_0's binary_logloss: 0.318168\n",
      "[58]\tvalid_0's l2: 0.0892814\tvalid_0's binary_logloss: 0.315226\n",
      "[59]\tvalid_0's l2: 0.0877443\tvalid_0's binary_logloss: 0.310671\n",
      "[60]\tvalid_0's l2: 0.0868359\tvalid_0's binary_logloss: 0.308453\n",
      "[61]\tvalid_0's l2: 0.0854425\tvalid_0's binary_logloss: 0.304892\n",
      "[62]\tvalid_0's l2: 0.0841567\tvalid_0's binary_logloss: 0.301173\n",
      "[63]\tvalid_0's l2: 0.0826577\tvalid_0's binary_logloss: 0.296996\n",
      "[64]\tvalid_0's l2: 0.0820495\tvalid_0's binary_logloss: 0.294936\n",
      "[65]\tvalid_0's l2: 0.0804146\tvalid_0's binary_logloss: 0.290356\n",
      "[66]\tvalid_0's l2: 0.0795442\tvalid_0's binary_logloss: 0.287566\n",
      "[67]\tvalid_0's l2: 0.0791211\tvalid_0's binary_logloss: 0.285661\n",
      "[68]\tvalid_0's l2: 0.0777656\tvalid_0's binary_logloss: 0.28259\n",
      "[69]\tvalid_0's l2: 0.0775779\tvalid_0's binary_logloss: 0.281698\n",
      "[70]\tvalid_0's l2: 0.0772885\tvalid_0's binary_logloss: 0.27994\n",
      "[71]\tvalid_0's l2: 0.0758468\tvalid_0's binary_logloss: 0.276149\n",
      "[72]\tvalid_0's l2: 0.0749727\tvalid_0's binary_logloss: 0.273484\n",
      "[73]\tvalid_0's l2: 0.0738112\tvalid_0's binary_logloss: 0.270132\n",
      "[74]\tvalid_0's l2: 0.0729472\tvalid_0's binary_logloss: 0.267323\n",
      "[75]\tvalid_0's l2: 0.0721462\tvalid_0's binary_logloss: 0.265054\n",
      "[76]\tvalid_0's l2: 0.0708325\tvalid_0's binary_logloss: 0.260831\n",
      "[77]\tvalid_0's l2: 0.0701848\tvalid_0's binary_logloss: 0.258573\n",
      "[78]\tvalid_0's l2: 0.0694837\tvalid_0's binary_logloss: 0.256179\n",
      "[79]\tvalid_0's l2: 0.0692293\tvalid_0's binary_logloss: 0.256076\n",
      "[80]\tvalid_0's l2: 0.0688737\tvalid_0's binary_logloss: 0.25508\n",
      "[81]\tvalid_0's l2: 0.0681495\tvalid_0's binary_logloss: 0.253086\n",
      "[82]\tvalid_0's l2: 0.0672284\tvalid_0's binary_logloss: 0.250448\n",
      "[83]\tvalid_0's l2: 0.0668094\tvalid_0's binary_logloss: 0.248923\n",
      "[84]\tvalid_0's l2: 0.0667686\tvalid_0's binary_logloss: 0.248041\n",
      "[85]\tvalid_0's l2: 0.0661447\tvalid_0's binary_logloss: 0.246523\n",
      "[86]\tvalid_0's l2: 0.0659037\tvalid_0's binary_logloss: 0.245023\n",
      "[87]\tvalid_0's l2: 0.0652802\tvalid_0's binary_logloss: 0.243253\n",
      "[88]\tvalid_0's l2: 0.0648545\tvalid_0's binary_logloss: 0.242208\n",
      "[89]\tvalid_0's l2: 0.0637055\tvalid_0's binary_logloss: 0.239167\n",
      "[90]\tvalid_0's l2: 0.0628194\tvalid_0's binary_logloss: 0.236594\n",
      "[91]\tvalid_0's l2: 0.0627807\tvalid_0's binary_logloss: 0.236335\n",
      "[92]\tvalid_0's l2: 0.0627387\tvalid_0's binary_logloss: 0.236082\n",
      "[93]\tvalid_0's l2: 0.0620009\tvalid_0's binary_logloss: 0.234217\n",
      "[94]\tvalid_0's l2: 0.0618984\tvalid_0's binary_logloss: 0.233464\n",
      "[95]\tvalid_0's l2: 0.0610315\tvalid_0's binary_logloss: 0.230809\n",
      "[96]\tvalid_0's l2: 0.0604337\tvalid_0's binary_logloss: 0.228983\n",
      "[97]\tvalid_0's l2: 0.0599691\tvalid_0's binary_logloss: 0.227672\n",
      "[98]\tvalid_0's l2: 0.0597105\tvalid_0's binary_logloss: 0.227489\n",
      "[99]\tvalid_0's l2: 0.0597064\tvalid_0's binary_logloss: 0.227018\n",
      "[100]\tvalid_0's l2: 0.0596292\tvalid_0's binary_logloss: 0.225991\n",
      "[101]\tvalid_0's l2: 0.0586654\tvalid_0's binary_logloss: 0.223647\n",
      "[102]\tvalid_0's l2: 0.058776\tvalid_0's binary_logloss: 0.223818\n",
      "[103]\tvalid_0's l2: 0.0579046\tvalid_0's binary_logloss: 0.221162\n",
      "[104]\tvalid_0's l2: 0.0576397\tvalid_0's binary_logloss: 0.220494\n",
      "[105]\tvalid_0's l2: 0.0569622\tvalid_0's binary_logloss: 0.21889\n",
      "[106]\tvalid_0's l2: 0.0569061\tvalid_0's binary_logloss: 0.218434\n",
      "[107]\tvalid_0's l2: 0.0572645\tvalid_0's binary_logloss: 0.218967\n",
      "[108]\tvalid_0's l2: 0.0568525\tvalid_0's binary_logloss: 0.217852\n",
      "[109]\tvalid_0's l2: 0.0566875\tvalid_0's binary_logloss: 0.217413\n",
      "[110]\tvalid_0's l2: 0.0563078\tvalid_0's binary_logloss: 0.216322\n",
      "[111]\tvalid_0's l2: 0.0559827\tvalid_0's binary_logloss: 0.21534\n",
      "[112]\tvalid_0's l2: 0.0556392\tvalid_0's binary_logloss: 0.214629\n",
      "[113]\tvalid_0's l2: 0.0553434\tvalid_0's binary_logloss: 0.21342\n",
      "[114]\tvalid_0's l2: 0.055293\tvalid_0's binary_logloss: 0.213462\n",
      "[115]\tvalid_0's l2: 0.0553493\tvalid_0's binary_logloss: 0.21315\n",
      "[116]\tvalid_0's l2: 0.0547469\tvalid_0's binary_logloss: 0.211834\n",
      "[117]\tvalid_0's l2: 0.0550417\tvalid_0's binary_logloss: 0.212236\n",
      "[118]\tvalid_0's l2: 0.0543368\tvalid_0's binary_logloss: 0.210864\n",
      "[119]\tvalid_0's l2: 0.0538791\tvalid_0's binary_logloss: 0.209813\n",
      "[120]\tvalid_0's l2: 0.0533531\tvalid_0's binary_logloss: 0.207991\n",
      "[121]\tvalid_0's l2: 0.0529502\tvalid_0's binary_logloss: 0.206744\n",
      "[122]\tvalid_0's l2: 0.0530762\tvalid_0's binary_logloss: 0.207203\n",
      "[123]\tvalid_0's l2: 0.0529183\tvalid_0's binary_logloss: 0.206509\n",
      "[124]\tvalid_0's l2: 0.0528167\tvalid_0's binary_logloss: 0.205888\n",
      "[125]\tvalid_0's l2: 0.0525037\tvalid_0's binary_logloss: 0.204939\n",
      "[126]\tvalid_0's l2: 0.0523224\tvalid_0's binary_logloss: 0.204272\n",
      "[127]\tvalid_0's l2: 0.0519681\tvalid_0's binary_logloss: 0.203289\n",
      "[128]\tvalid_0's l2: 0.0519793\tvalid_0's binary_logloss: 0.203404\n",
      "[129]\tvalid_0's l2: 0.0518126\tvalid_0's binary_logloss: 0.202578\n",
      "[130]\tvalid_0's l2: 0.0515384\tvalid_0's binary_logloss: 0.201714\n",
      "[131]\tvalid_0's l2: 0.0514572\tvalid_0's binary_logloss: 0.201635\n",
      "[132]\tvalid_0's l2: 0.0510603\tvalid_0's binary_logloss: 0.200208\n",
      "[133]\tvalid_0's l2: 0.0510051\tvalid_0's binary_logloss: 0.19984\n",
      "[134]\tvalid_0's l2: 0.050907\tvalid_0's binary_logloss: 0.199508\n",
      "[135]\tvalid_0's l2: 0.0506542\tvalid_0's binary_logloss: 0.198758\n",
      "[136]\tvalid_0's l2: 0.050722\tvalid_0's binary_logloss: 0.198716\n",
      "[137]\tvalid_0's l2: 0.0507984\tvalid_0's binary_logloss: 0.198495\n",
      "[138]\tvalid_0's l2: 0.0505568\tvalid_0's binary_logloss: 0.197748\n",
      "[139]\tvalid_0's l2: 0.0503443\tvalid_0's binary_logloss: 0.196771\n",
      "[140]\tvalid_0's l2: 0.0503541\tvalid_0's binary_logloss: 0.196782\n",
      "[141]\tvalid_0's l2: 0.0503418\tvalid_0's binary_logloss: 0.196664\n",
      "[142]\tvalid_0's l2: 0.0500026\tvalid_0's binary_logloss: 0.195519\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[142]\tvalid_0's l2: 0.0500026\tvalid_0's binary_logloss: 0.195519\n",
      "---- Train error ----\n",
      "0.003205381403498127\n",
      "---- CV error ----\n",
      "0.044581943835140324\n",
      "---- leaderboard stats ----\n",
      "0.025066052608001432\n",
      "0.052061264545674536\n",
      "layoff\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2322  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2483  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2349  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.2042  \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2153  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2311  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2447  \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 7.045   \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 94.36   \u001b[0m | \u001b[0m 53.73   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2412  \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.0116  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 91.92   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.2637  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2091  \u001b[0m | \u001b[0m 0.6773  \u001b[0m | \u001b[0m 0.1621  \u001b[0m | \u001b[0m 8.366   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 231.3   \u001b[0m | \u001b[0m 86.77   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 0.2893  \u001b[0m | \u001b[0m 0.9537  \u001b[0m | \u001b[0m 0.8583  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2247  \u001b[0m | \u001b[0m 0.5771  \u001b[0m | \u001b[0m 0.01695 \u001b[0m | \u001b[0m 12.56   \u001b[0m | \u001b[0m 16.64   \u001b[0m | \u001b[0m 240.2   \u001b[0m | \u001b[0m 81.68   \u001b[0m | \u001b[0m 16.35   \u001b[0m | \u001b[0m 0.9114  \u001b[0m | \u001b[0m 0.9276  \u001b[0m | \u001b[0m 0.6021  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2155  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.231   \u001b[0m | \u001b[0m 0.934   \u001b[0m | \u001b[0m 0.03723 \u001b[0m | \u001b[0m 6.055   \u001b[0m | \u001b[0m 33.86   \u001b[0m | \u001b[0m 234.0   \u001b[0m | \u001b[0m 90.27   \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 0.8599  \u001b[0m | \u001b[0m 0.3031  \u001b[0m | \u001b[0m 0.8424  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2128  \u001b[0m | \u001b[0m 0.5317  \u001b[0m | \u001b[0m 0.1254  \u001b[0m | \u001b[0m 5.05    \u001b[0m | \u001b[0m 16.5    \u001b[0m | \u001b[0m 229.2   \u001b[0m | \u001b[0m 83.18   \u001b[0m | \u001b[0m 20.61   \u001b[0m | \u001b[0m 0.7069  \u001b[0m | \u001b[0m 0.8976  \u001b[0m | \u001b[0m 0.9449  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1971  \u001b[0m | \u001b[95m 0.5367  \u001b[0m | \u001b[95m 0.1061  \u001b[0m | \u001b[95m 11.11   \u001b[0m | \u001b[95m 11.14   \u001b[0m | \u001b[95m 499.9   \u001b[0m | \u001b[95m 138.3   \u001b[0m | \u001b[95m 24.8    \u001b[0m | \u001b[95m 0.3749  \u001b[0m | \u001b[95m 0.02774 \u001b[0m | \u001b[95m 0.7442  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2371  \u001b[0m | \u001b[0m 0.5463  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 2.422   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 78.7    \u001b[0m | \u001b[0m 15.77   \u001b[0m | \u001b[0m 0.3688  \u001b[0m | \u001b[0m 0.1773  \u001b[0m | \u001b[0m 0.8557  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2143  \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.1763  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 43.6    \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.5202  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2098  \u001b[0m | \u001b[0m 0.6069  \u001b[0m | \u001b[0m 0.1788  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 490.5   \u001b[0m | \u001b[0m 149.8   \u001b[0m | \u001b[0m 26.38   \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 0.9548  \u001b[0m | \u001b[0m 0.5631  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2445  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 76.97   \u001b[0m | \u001b[0m 25.06   \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.5669  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2443  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 60.09   \u001b[0m | \u001b[0m 3.761   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 0.6729  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2028  \u001b[0m | \u001b[0m 0.8877  \u001b[0m | \u001b[0m 0.08897 \u001b[0m | \u001b[0m 6.866   \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 506.8   \u001b[0m | \u001b[0m 128.7   \u001b[0m | \u001b[0m 16.53   \u001b[0m | \u001b[0m 0.4127  \u001b[0m | \u001b[0m 0.6478  \u001b[0m | \u001b[0m 0.9965  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.19706273935848428, 'params': {'colsample_bytree': 0.5367415234202666, 'learning_rate': 0.10605584804946408, 'max_depth': 11.10991397998832, 'min_child_samples': 11.14379557932675, 'n_estimators': 499.8887747801077, 'num_iteration': 138.2849196133095, 'num_leaves': 24.79570152957461, 'reg_alpha': 0.3748725813696111, 'reg_lambda': 0.02773570615897558, 'subsample': 0.7441738354482741}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=138, num_iteration=138 will be ignored. Current value: num_iterations=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.247972\tvalid_0's binary_logloss: 0.689062\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.240837\tvalid_0's binary_logloss: 0.674676\n",
      "[3]\tvalid_0's l2: 0.2399\tvalid_0's binary_logloss: 0.672653\n",
      "[4]\tvalid_0's l2: 0.236051\tvalid_0's binary_logloss: 0.664889\n",
      "[5]\tvalid_0's l2: 0.231613\tvalid_0's binary_logloss: 0.655764\n",
      "[6]\tvalid_0's l2: 0.227722\tvalid_0's binary_logloss: 0.647446\n",
      "[7]\tvalid_0's l2: 0.223672\tvalid_0's binary_logloss: 0.639138\n",
      "[8]\tvalid_0's l2: 0.222018\tvalid_0's binary_logloss: 0.635341\n",
      "[9]\tvalid_0's l2: 0.221701\tvalid_0's binary_logloss: 0.634902\n",
      "[10]\tvalid_0's l2: 0.227426\tvalid_0's binary_logloss: 0.646666\n",
      "[11]\tvalid_0's l2: 0.234005\tvalid_0's binary_logloss: 0.660216\n",
      "[12]\tvalid_0's l2: 0.237167\tvalid_0's binary_logloss: 0.666965\n",
      "[13]\tvalid_0's l2: 0.241224\tvalid_0's binary_logloss: 0.675662\n",
      "[14]\tvalid_0's l2: 0.246094\tvalid_0's binary_logloss: 0.68642\n",
      "[15]\tvalid_0's l2: 0.250488\tvalid_0's binary_logloss: 0.696419\n",
      "[16]\tvalid_0's l2: 0.25385\tvalid_0's binary_logloss: 0.703632\n",
      "[17]\tvalid_0's l2: 0.257748\tvalid_0's binary_logloss: 0.712159\n",
      "[18]\tvalid_0's l2: 0.258429\tvalid_0's binary_logloss: 0.713578\n",
      "[19]\tvalid_0's l2: 0.257698\tvalid_0's binary_logloss: 0.712217\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l2: 0.221701\tvalid_0's binary_logloss: 0.634902\n",
      "---- Train error ----\n",
      "0.18211240884118746\n",
      "---- CV error ----\n",
      "0.15387776339393686\n",
      "---- leaderboard stats ----\n",
      "-0.01181678999824376\n",
      "0.17617282798869383\n",
      "jobTraining\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_it... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2233  \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.07011 \u001b[0m | \u001b[0m 3.575   \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 572.0   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 29.01   \u001b[0m | \u001b[0m 0.6532  \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2373  \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1926  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 0.8722  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2297  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 7.546   \u001b[0m | \u001b[0m 71.86   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 0.6769  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.5855  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.2101  \u001b[0m | \u001b[95m 0.5134  \u001b[0m | \u001b[95m 0.1621  \u001b[0m | \u001b[95m 13.65   \u001b[0m | \u001b[95m 14.69   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 18.7    \u001b[0m | \u001b[95m 0.05196 \u001b[0m | \u001b[95m 0.8951  \u001b[0m | \u001b[95m 0.8641  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2116  \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 28.23   \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 88.81   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.7095  \u001b[0m | \u001b[0m 0.589   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2189  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.02932 \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 20.96   \u001b[0m | \u001b[0m 497.1   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.8302  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.2085  \u001b[0m | \u001b[95m 0.6993  \u001b[0m | \u001b[95m 0.1586  \u001b[0m | \u001b[95m 8.776   \u001b[0m | \u001b[95m 16.65   \u001b[0m | \u001b[95m 500.2   \u001b[0m | \u001b[95m 138.2   \u001b[0m | \u001b[95m 16.77   \u001b[0m | \u001b[95m 0.1568  \u001b[0m | \u001b[95m 0.9366  \u001b[0m | \u001b[95m 0.651   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2192  \u001b[0m | \u001b[0m 0.5792  \u001b[0m | \u001b[0m 0.05888 \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 33.19   \u001b[0m | \u001b[0m 227.7   \u001b[0m | \u001b[0m 85.05   \u001b[0m | \u001b[0m 15.06   \u001b[0m | \u001b[0m 0.007282\u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 0.7998  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2272  \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 0.1251  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 35.67   \u001b[0m | \u001b[0m 225.3   \u001b[0m | \u001b[0m 89.75   \u001b[0m | \u001b[0m 9.125   \u001b[0m | \u001b[0m 0.5762  \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 0.9434  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.22    \u001b[0m | \u001b[0m 0.5025  \u001b[0m | \u001b[0m 0.1081  \u001b[0m | \u001b[0m 11.7    \u001b[0m | \u001b[0m 33.74   \u001b[0m | \u001b[0m 225.3   \u001b[0m | \u001b[0m 74.11   \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 0.004225\u001b[0m | \u001b[0m 0.8625  \u001b[0m | \u001b[0m 0.6048  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2271  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.1867  \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 30.59   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 82.38   \u001b[0m | \u001b[0m 15.29   \u001b[0m | \u001b[0m 0.04618 \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 0.815   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2213  \u001b[0m | \u001b[0m 0.6149  \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 3.013   \u001b[0m | \u001b[0m 14.46   \u001b[0m | \u001b[0m 496.2   \u001b[0m | \u001b[0m 122.7   \u001b[0m | \u001b[0m 16.68   \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 0.9731  \u001b[0m | \u001b[0m 0.8386  \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.2078  \u001b[0m | \u001b[95m 0.8897  \u001b[0m | \u001b[95m 0.02947 \u001b[0m | \u001b[95m 12.31   \u001b[0m | \u001b[95m 23.18   \u001b[0m | \u001b[95m 810.2   \u001b[0m | \u001b[95m 186.3   \u001b[0m | \u001b[95m 24.33   \u001b[0m | \u001b[95m 0.7597  \u001b[0m | \u001b[95m 0.4758  \u001b[0m | \u001b[95m 0.5351  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2341  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02365 \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 0.7359  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2356  \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 59.18   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 0.005392\u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.5095  \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.2024  \u001b[0m | \u001b[95m 0.7688  \u001b[0m | \u001b[95m 0.06383 \u001b[0m | \u001b[95m 11.45   \u001b[0m | \u001b[95m 18.61   \u001b[0m | \u001b[95m 499.5   \u001b[0m | \u001b[95m 143.8   \u001b[0m | \u001b[95m 18.45   \u001b[0m | \u001b[95m 0.6559  \u001b[0m | \u001b[95m 0.8434  \u001b[0m | \u001b[95m 0.7452  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2106  \u001b[0m | \u001b[0m 0.6069  \u001b[0m | \u001b[0m 0.1788  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 490.5   \u001b[0m | \u001b[0m 149.8   \u001b[0m | \u001b[0m 26.38   \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 0.9548  \u001b[0m | \u001b[0m 0.5631  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2181  \u001b[0m | \u001b[0m 0.6865  \u001b[0m | \u001b[0m 0.06955 \u001b[0m | \u001b[0m 2.185   \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 492.1   \u001b[0m | \u001b[0m 145.3   \u001b[0m | \u001b[0m 24.82   \u001b[0m | \u001b[0m 0.4801  \u001b[0m | \u001b[0m 0.9108  \u001b[0m | \u001b[0m 0.6386  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2115  \u001b[0m | \u001b[0m 0.7471  \u001b[0m | \u001b[0m 0.1265  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 509.3   \u001b[0m | \u001b[0m 148.7   \u001b[0m | \u001b[0m 25.29   \u001b[0m | \u001b[0m 0.6609  \u001b[0m | \u001b[0m 0.5852  \u001b[0m | \u001b[0m 0.9806  \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.1971  \u001b[0m | \u001b[95m 0.6515  \u001b[0m | \u001b[95m 0.1012  \u001b[0m | \u001b[95m 14.95   \u001b[0m | \u001b[95m 13.37   \u001b[0m | \u001b[95m 815.3   \u001b[0m | \u001b[95m 179.7   \u001b[0m | \u001b[95m 21.87   \u001b[0m | \u001b[95m 0.3049  \u001b[0m | \u001b[95m 0.5677  \u001b[0m | \u001b[95m 0.8964  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Final result: {'target': -0.1971428793748994, 'params': {'colsample_bytree': 0.6515262483898663, 'learning_rate': 0.10121813420310026, 'max_depth': 14.953472273593446, 'min_child_samples': 13.365082703959914, 'n_estimators': 815.3014451919936, 'num_iteration': 179.6500595267883, 'num_leaves': 21.87000792548246, 'reg_alpha': 0.30492641977726453, 'reg_lambda': 0.5677061700423077, 'subsample': 0.8963657633071224}}\n",
      "0\n",
      "[LightGBM] [Warning] num_iterations is set=179, num_iteration=179 will be ignored. Current value: num_iterations=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.245308\tvalid_0's binary_logloss: 0.683734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.238096\tvalid_0's binary_logloss: 0.669196\n",
      "[3]\tvalid_0's l2: 0.231505\tvalid_0's binary_logloss: 0.655743\n",
      "[4]\tvalid_0's l2: 0.226697\tvalid_0's binary_logloss: 0.645817\n",
      "[5]\tvalid_0's l2: 0.223452\tvalid_0's binary_logloss: 0.638997\n",
      "[6]\tvalid_0's l2: 0.219753\tvalid_0's binary_logloss: 0.631204\n",
      "[7]\tvalid_0's l2: 0.215409\tvalid_0's binary_logloss: 0.622165\n",
      "[8]\tvalid_0's l2: 0.213482\tvalid_0's binary_logloss: 0.618025\n",
      "[9]\tvalid_0's l2: 0.211757\tvalid_0's binary_logloss: 0.61416\n",
      "[10]\tvalid_0's l2: 0.21688\tvalid_0's binary_logloss: 0.624879\n",
      "[11]\tvalid_0's l2: 0.218807\tvalid_0's binary_logloss: 0.628717\n",
      "[12]\tvalid_0's l2: 0.22171\tvalid_0's binary_logloss: 0.634949\n",
      "[13]\tvalid_0's l2: 0.223636\tvalid_0's binary_logloss: 0.638757\n",
      "[14]\tvalid_0's l2: 0.22591\tvalid_0's binary_logloss: 0.64348\n",
      "[15]\tvalid_0's l2: 0.223654\tvalid_0's binary_logloss: 0.638227\n",
      "[16]\tvalid_0's l2: 0.225583\tvalid_0's binary_logloss: 0.642235\n",
      "[17]\tvalid_0's l2: 0.226355\tvalid_0's binary_logloss: 0.643975\n",
      "[18]\tvalid_0's l2: 0.225932\tvalid_0's binary_logloss: 0.642895\n",
      "[19]\tvalid_0's l2: 0.228707\tvalid_0's binary_logloss: 0.649239\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l2: 0.211757\tvalid_0's binary_logloss: 0.61416\n",
      "---- Train error ----\n",
      "0.11907888637392658\n",
      "---- CV error ----\n",
      "0.1691143552729957\n",
      "---- leaderboard stats ----\n",
      "-0.018496452270450048\n",
      "0.20413801623096692\n",
      "0:02:53.553030\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RepeatedKFold,RepeatedStratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "variables = test.columns.to_list()\n",
    "\n",
    "\n",
    "prediction = pd.read_csv('FFChallenge_v5/prediction.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "def optimize_gbm_regressor(data, targets,boosting_type):\n",
    "    \"\"\"Apply Bayesian Optimization to GBM parameters.\"\"\"\n",
    "\n",
    "    def gbm_crossval(num_leaves, max_depth, learning_rate,\n",
    "                     n_estimators,num_iteration,subsample,min_child_samples,\n",
    "                    colsample_bytree,reg_alpha,reg_lambda,):\n",
    "        \"\"\"GB cross validation.\n",
    "        \"\"\"\n",
    "        clf = LGBMRegressor(\n",
    "            num_leaves=int(num_leaves),\n",
    "            max_depth=int(max_depth),\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=int(n_estimators),\n",
    "            num_iteration=int(num_iteration),\n",
    "            boosting_type = boosting_type,\n",
    "            subsample = subsample,\n",
    "            min_child_samples = int(min_child_samples),\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha = reg_alpha,\n",
    "            reg_lambda = reg_lambda,\n",
    "        )\n",
    "        cv = RepeatedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "        cval = cross_val_score(clf, data, targets, scoring='neg_mean_squared_error', cv=cv,n_jobs=-1)\n",
    "        print(cval)\n",
    "        return cval.mean()\n",
    "    \n",
    "    # Set up the BO\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=gbm_crossval,\n",
    "        pbounds={\n",
    "            'num_leaves': (2, 30),\n",
    "            'max_depth': (1, 15),\n",
    "            'learning_rate': (0.01, 0.2),\n",
    "            'n_estimators': (10,1000),\n",
    "            'num_iteration':(50,200),\n",
    "            'subsample': (0.5,1.0),\n",
    "            'min_child_samples' : (10, 200),\n",
    "            'colsample_bytree':(0.5,1),\n",
    "            'reg_alpha': (0.0, 1.0),\n",
    "            'reg_lambda': (0.0, 1.0),\n",
    "        },\n",
    "        random_state=12345,\n",
    "        verbose=3\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=5)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "    return optimizer.max\n",
    "\n",
    "\n",
    "\n",
    "def optimize_gbm_classifier(data, targets,boosting_type):\n",
    "    \"\"\"Apply Bayesian Optimization to GBM parameters.\"\"\"\n",
    "#     self.boosting_type = boosting_type\n",
    "\n",
    "    def gbm_crossval(num_leaves, max_depth, learning_rate,\n",
    "                     n_estimators,num_iteration,subsample,min_child_samples,\n",
    "                    colsample_bytree,reg_alpha,reg_lambda,):\n",
    "        \"\"\"GB cross validation.\n",
    "        \"\"\"\n",
    "        clf = LGBMClassifier(\n",
    "        num_leaves=int(num_leaves),\n",
    "        max_depth=int(max_depth),\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        num_iteration=int(num_iteration),\n",
    "        boosting_type = boosting_type,\n",
    "        subsample = subsample,\n",
    "        min_child_samples = int(min_child_samples),\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha = reg_alpha,\n",
    "        reg_lambda = reg_lambda,\n",
    "        class_weight = 'balanced',\n",
    "        )\n",
    "        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=123)\n",
    "        cval = cross_val_score(clf, data, targets, scoring='neg_brier_score', cv=cv,n_jobs=-1)\n",
    "#         print(cval)\n",
    "        return cval.mean()\n",
    "    \n",
    "    # Set up the BO\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=gbm_crossval,\n",
    "        pbounds={\n",
    "            'num_leaves': (2, 30),\n",
    "            'max_depth': (1, 15),\n",
    "            'learning_rate': (0.01, 0.2),\n",
    "            'n_estimators': (10,1000),\n",
    "            'num_iteration':(50,200),\n",
    "            'subsample': (0.5,1.0),\n",
    "            'min_child_samples' : (10, 200),\n",
    "            'colsample_bytree':(0.5,1),\n",
    "            'reg_alpha': (0.0, 1.0),\n",
    "            'reg_lambda': (0.0, 1.0),\n",
    "        },\n",
    "        random_state=12345,\n",
    "#         verbose=1\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=5)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "    return optimizer.max\n",
    "\n",
    "\n",
    "classification_vars = ['eviction','layoff','jobTraining']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "boosting_types = ['gbdt','dart','goss']\n",
    "\n",
    "best_params_each_model = dict()\n",
    "\n",
    "accuracies_each_model = dict()\n",
    "for boosting_type in boosting_types:\n",
    "    print('------------- ',boosting_type, ' --------------')\n",
    "    print('\\n')\n",
    "    lgbm_accuracies = dict()\n",
    "    for variable in variables[3:]: # Run for the three categorical outcomes\n",
    "#     for variable in ['grit','layoff']:\n",
    "    # variable = 'eviction'\n",
    "        print(variable)\n",
    "        start=datetime.now()\n",
    "        # Let's drop instances where the response is NA\n",
    "        y_train_no_na = y_train[variable].dropna()\n",
    "        X_train_no_na = X_train.loc[y_train_no_na.index.values]\n",
    "\n",
    "        y_CV_no_na = y_CV[variable].dropna()\n",
    "        X_CV_no_na = X_CV.loc[y_CV_no_na.index.values]\n",
    "\n",
    "        mask = leaderboard[variable].isna()\n",
    "        y_leaderboard = leaderboard[variable]\n",
    "\n",
    "        ###### model = Lasso(alpha=1000.0,max_iter=10000)\n",
    "        # model.fit(X_train, y_train_trans)\n",
    "        # from imblearn.over_sampling import SMOTE\n",
    "\n",
    "        # train_data=lgb.Dataset(X_train,label=y_train_trans)\n",
    "        #setting parameters for lightgbm\n",
    "        # param = {'num_leaves':50, 'objective':'binary','max_depth':7,'learning_rate':.2,'max_bin':200}\n",
    "        # param['metric'] = ['auc', 'binary_logloss']\n",
    "\n",
    "        #training our model using light gbm\n",
    "\n",
    "        # specify parameters and distributions to sample from\n",
    "\n",
    "        if variable not in classification_vars:\n",
    "            print(variable)\n",
    "            params = optimize_gbm_regressor(X_train_no_na, y_train_no_na,boosting_type)\n",
    "            best_params = params['params']  \n",
    "            print(1)\n",
    "\n",
    "            # Validation accuracy \n",
    "            lgbm=LGBMRegressor(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                   n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                        num_iteration = int(best_params['num_iteration']),\n",
    "                        boosting_type=boosting_type, \n",
    "                        subsample = best_params['subsample'],\n",
    "                        min_child_samples = int(best_params['min_child_samples']),\n",
    "                        colsample_bytree=best_params['colsample_bytree'],\n",
    "                        reg_alpha = best_params['reg_alpha'],\n",
    "                        reg_lambda = best_params['reg_lambda'],\n",
    "                               silent = True)\n",
    "\n",
    "            # I used early stopping to help prevent overfitting the model on the training set (stops the model once it's performance doesn't\n",
    "            # improve for 5 iterations on the validation set)\n",
    "            lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2',\n",
    "             early_stopping_rounds = 5)\n",
    "\n",
    "            \n",
    "            # For early stopping (i.e. early stopping at 10 rounds with no improvement to cv)\n",
    "            # The model that displayed the score 10 rounds ago does not exist anymore (a few trees have been dropped).\n",
    "            # To get the best score you got 20 rounds ago, you have no option but to retrain a model with the appropriate number of iterations.\n",
    "#             https://www.kaggle.com/c/microsoft-malware-prediction/discussion/78253\n",
    "            if boosting_type=='dart':\n",
    "        \n",
    "                evaluation_score = lgbm.evals_result_\n",
    "\n",
    "                dart_best_iteration = evaluation_score['valid_0']['l2'].index(min(evaluation_score['valid_0']['l2']))\n",
    "\n",
    "                lgbm=LGBMRegressor(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                           n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                                num_iteration = dart_best_iteration,\n",
    "                                boosting_type='dart', \n",
    "                                subsample = best_params['subsample'],\n",
    "                                min_child_samples = int(best_params['min_child_samples']),\n",
    "                                colsample_bytree=best_params['colsample_bytree'],\n",
    "                                reg_alpha = best_params['reg_alpha'],\n",
    "                                reg_lambda = best_params['reg_lambda'],\n",
    "                                       silent = True)\n",
    "                lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2')\n",
    "\n",
    "\n",
    "            y_pred_train = lgbm.predict(X_train_no_na)\n",
    "            y_pred_all = lgbm.predict(x_leaderboard)\n",
    "            cv_preds = lgbm.predict(X_CV_no_na)\n",
    "            # Save predictions of best model for leaderboard submition\n",
    "            pred_all_backgrounds = lgbm.predict(background_imputed_tot)\n",
    "\n",
    "        else:\n",
    "            #         'gbdt', 'goss', 'dart', 'rf'\n",
    "            params = optimize_gbm_classifier(X_train_no_na, y_train_no_na,boosting_type)\n",
    "            best_params = params['params']  \n",
    "            print(0)\n",
    "            # Validation accuracy\n",
    "\n",
    "            lgbm=LGBMClassifier(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                       n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                        num_iteration = int(best_params['num_iteration']),\n",
    "                        boosting_type=boosting_type,\n",
    "                        subsample = best_params['subsample'],\n",
    "                        min_child_samples = int(best_params['min_child_samples']),\n",
    "                        colsample_bytree=best_params['colsample_bytree'],\n",
    "                        reg_alpha = best_params['reg_alpha'],\n",
    "                        reg_lambda = best_params['reg_lambda'],\n",
    "                        class_weight = 'balanced',\n",
    "                        silent = True)\n",
    "    #         lgbm.fit(X_train_no_na, y_train_no_na,eval_metric='l1')\n",
    "            lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2',\n",
    "                 early_stopping_rounds = 10)\n",
    "        \n",
    "            if boosting_type=='dart':\n",
    "                \n",
    "                evaluation_score = lgbm.evals_result_\n",
    "\n",
    "                dart_best_iteration = evaluation_score['valid_0']['l2'].index(min(evaluation_score['valid_0']['l2'])) + 1\n",
    "\n",
    "                lgbm=LGBMClassifier(learning_rate = best_params['learning_rate'], max_depth =  int(best_params['max_depth']),\n",
    "                           n_estimators = int(best_params['n_estimators']), num_leaves = int(best_params['num_leaves']),\n",
    "                                num_iteration = dart_best_iteration,\n",
    "                                boosting_type='dart', \n",
    "                                subsample = best_params['subsample'],\n",
    "                                min_child_samples = int(best_params['min_child_samples']),\n",
    "                                colsample_bytree=best_params['colsample_bytree'],\n",
    "                                reg_alpha = best_params['reg_alpha'],\n",
    "                                reg_lambda = best_params['reg_lambda'],\n",
    "                                class_weight = 'balanced',\n",
    "                                       silent = True)\n",
    "                lgbm.fit(X_train_no_na, y_train_no_na,eval_set = (X_CV_no_na,y_CV_no_na), eval_metric='l2')\n",
    "            \n",
    "            \n",
    "            # Calibrate after training the model on the best parameters using a sigmoid calibration function\n",
    "            calibrated = CalibratedClassifierCV(lgbm, cv='prefit', method='sigmoid')\n",
    "            calibrated.fit(X_CV_no_na, y_CV_no_na)\n",
    "\n",
    "            y_pred_train = calibrated.predict_proba(X_train_no_na)[:,1]\n",
    "            y_pred_all = calibrated.predict_proba(x_leaderboard)[:,1]\n",
    "            cv_preds = calibrated.predict_proba(X_CV_no_na)[:,1]\n",
    "                        # Save predictions of best model for leaderboard submition\n",
    "            pred_all_backgrounds =calibrated.predict_proba(background_imputed_tot)[:,1]\n",
    "\n",
    "\n",
    "#             y_pred_train = lgbm.predict_proba(X_train_no_na)[:,1]\n",
    "#             y_pred_all = lgbm.predict_proba(x_leaderboard)[:,1]\n",
    "#             cv_preds = lgbm.predict_proba(X_CV_no_na)[:,1]\n",
    "#             # Save predictions of best model for leaderboard submition\n",
    "#             pred_all_backgrounds = lgbm.predict_proba(background_imputed_tot)[:,1]\n",
    "\n",
    "        best_params_lgbm[variable] = best_params\n",
    "\n",
    "\n",
    "        # Can use mean square error as performance metric for both, since for 1 output, the mean square error and brier loss are the same.\n",
    "        \n",
    "        error_types = dict()  \n",
    "        print('---- Train error ----')\n",
    "        error_types['train'] = mean_squared_error(y_train_no_na,y_pred_train)\n",
    "        print(mean_squared_error(y_train_no_na,y_pred_train))\n",
    "        print('---- CV error ----')\n",
    "        error_types['CV'] = mean_squared_error(y_CV_no_na,cv_preds)\n",
    "        print(mean_squared_error(y_CV_no_na,cv_preds))\n",
    "\n",
    "        print('---- leaderboard stats ----')\n",
    "        print(r2_score(y_leaderboard[~mask],y_pred_all[~mask]))\n",
    "        \n",
    "        error_types['leaderboard'] = mean_squared_error(y_leaderboard[~mask],y_pred_all[~mask])\n",
    "        print(mean_squared_error(y_leaderboard[~mask],y_pred_all[~mask]))\n",
    "        \n",
    "        lgbm_accuracies[variable] = error_types\n",
    "\n",
    "        # lgbm=LGBMClassifier(learning_rate = 0.05, n_estimators = len(background.columns), num_leaves = 32)\n",
    "\n",
    "\n",
    "        # Save predictions of best model for leaderboard submition\n",
    "\n",
    "        prediction[variable] = pred_all_backgrounds\n",
    "\n",
    "\n",
    "    best_params_each_model[boosting_type] = best_params_lgbm\n",
    "    accuracies_each_model[boosting_type] = lgbm_accuracies\n",
    "    #     print(pred_all_backgrounds==cv_preds)\n",
    "\n",
    "\n",
    "    prediction.to_csv('lgbm_preds_' + boosting_type + '.csv')\n",
    "    print(datetime.now()-start)\n",
    "    print('\\n\\n\\n------------------------------------------')\n",
    "best_params_each_model_weighted_copy = best_params_each_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save models and params and accuracies\n",
    "with open('best_params_trees_weighted.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_params_each_model_weighted_copy, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('best_accs_trees_weighted.pickle', 'wb') as handle:\n",
    "    pickle.dump(accuracies_each_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# best_params_each_model_no_sampling_copy\n",
    "# accuracies_each_model_no_sampling_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eviction dart 0.05315720683920307',\n",
       " 'eviction gbdt 0.05256860701916669',\n",
       " 'eviction goss 0.052061264545674536',\n",
       " 'jobTraining dart 0.2118030106777266',\n",
       " 'jobTraining gbdt 0.21187664440564227',\n",
       " 'jobTraining goss 0.20413801623096692',\n",
       " 'layoff dart 0.17664021831573956',\n",
       " 'layoff gbdt 0.17505472493917246',\n",
       " 'layoff goss 0.17617282798869383']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lst_leader_board_accs = list()\n",
    "for model_name in accuracies_each_model:\n",
    "    for var_name in accuracies_each_model[model_name]:\n",
    "        lst_leader_board_accs.append(var_name + ' ' + model_name + ' ' +  str(accuracies_each_model[model_name][var_name]['leaderboard']))\n",
    "\n",
    "sorted(lst_leader_board_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
